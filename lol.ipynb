{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 12:07:34.726345: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-02 12:07:34.740967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740906454.757640  637778 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740906454.762625  637778 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-02 12:07:34.781171: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from lib import Models\n",
    "\n",
    "model, tokenizer = Models.LoadLLM(\"meta-llama/Llama-3.2-1B-Instruct\", 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_corda.Config import get_peft_model, SCorDAConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SCorDAConfig(r=8, alpha=2, target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'down_proj'], init_strategy='lora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting adapter at model.layers.0.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.0.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.0.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.0.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.0.mlp.up_proj layer\n",
      "Setting adapter at model.layers.0.mlp.down_proj layer\n",
      "Setting adapter at model.layers.1.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.1.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.1.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.1.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.1.mlp.up_proj layer\n",
      "Setting adapter at model.layers.1.mlp.down_proj layer\n",
      "Setting adapter at model.layers.2.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.2.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.2.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.2.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.2.mlp.up_proj layer\n",
      "Setting adapter at model.layers.2.mlp.down_proj layer\n",
      "Setting adapter at model.layers.3.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.3.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.3.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.3.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.3.mlp.up_proj layer\n",
      "Setting adapter at model.layers.3.mlp.down_proj layer\n",
      "Setting adapter at model.layers.4.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.4.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.4.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.4.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.4.mlp.up_proj layer\n",
      "Setting adapter at model.layers.4.mlp.down_proj layer\n",
      "Setting adapter at model.layers.5.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.5.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.5.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.5.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.5.mlp.up_proj layer\n",
      "Setting adapter at model.layers.5.mlp.down_proj layer\n",
      "Setting adapter at model.layers.6.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.6.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.6.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.6.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.6.mlp.up_proj layer\n",
      "Setting adapter at model.layers.6.mlp.down_proj layer\n",
      "Setting adapter at model.layers.7.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.7.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.7.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.7.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.7.mlp.up_proj layer\n",
      "Setting adapter at model.layers.7.mlp.down_proj layer\n",
      "Setting adapter at model.layers.8.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.8.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.8.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.8.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.8.mlp.up_proj layer\n",
      "Setting adapter at model.layers.8.mlp.down_proj layer\n",
      "Setting adapter at model.layers.9.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.9.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.9.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.9.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.9.mlp.up_proj layer\n",
      "Setting adapter at model.layers.9.mlp.down_proj layer\n",
      "Setting adapter at model.layers.10.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.10.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.10.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.10.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.10.mlp.up_proj layer\n",
      "Setting adapter at model.layers.10.mlp.down_proj layer\n",
      "Setting adapter at model.layers.11.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.11.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.11.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.11.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.11.mlp.up_proj layer\n",
      "Setting adapter at model.layers.11.mlp.down_proj layer\n",
      "Setting adapter at model.layers.12.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.12.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.12.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.12.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.12.mlp.up_proj layer\n",
      "Setting adapter at model.layers.12.mlp.down_proj layer\n",
      "Setting adapter at model.layers.13.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.13.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.13.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.13.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.13.mlp.up_proj layer\n",
      "Setting adapter at model.layers.13.mlp.down_proj layer\n",
      "Setting adapter at model.layers.14.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.14.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.14.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.14.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.14.mlp.up_proj layer\n",
      "Setting adapter at model.layers.14.mlp.down_proj layer\n",
      "Setting adapter at model.layers.15.self_attn.q_proj layer\n",
      "Setting adapter at model.layers.15.self_attn.k_proj layer\n",
      "Setting adapter at model.layers.15.self_attn.v_proj layer\n",
      "Setting adapter at model.layers.15.self_attn.o_proj layer\n",
      "Setting adapter at model.layers.15.mlp.up_proj layer\n",
      "Setting adapter at model.layers.15.mlp.down_proj layer\n",
      "trainable: 4325376  |  total: 1240139776  |  trainable(%): 0.348781\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./test_/tokenizer_config.json',\n",
       " './test_/special_tokens_map.json',\n",
       " './test_/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './test_'\n",
    "import torch\n",
    "\n",
    "# torch.save((model, tokenizer), path)\n",
    "model.save_pretrained(path)\n",
    "tokenizer.save_pretrained(path)\n",
    "# model.config.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): SCorDALinear(\n",
      "            (pre_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "            (adapter): SCorDAInitialization(\n",
      "              adapter_A=Parameter(shape=torch.Size([2048, 8]), dtype=torch.float32, requires_grad=True),\n",
      "              adapter_B=Parameter(shape=torch.Size([8, 2048]), dtype=torch.float32, requires_grad=True),\n",
      "              r=8,\n",
      "              init_strategy='lora'\n",
      "            )\n",
      "          )\n",
      "          (k_proj): SCorDALinear(\n",
      "            (pre_layer): Linear(in_features=2048, out_features=512, bias=False)\n",
      "            (adapter): SCorDAInitialization(\n",
      "              adapter_A=Parameter(shape=torch.Size([2048, 8]), dtype=torch.float32, requires_grad=True),\n",
      "              adapter_B=Parameter(shape=torch.Size([8, 512]), dtype=torch.float32, requires_grad=True),\n",
      "              r=8,\n",
      "              init_strategy='lora'\n",
      "            )\n",
      "          )\n",
      "          (v_proj): SCorDALinear(\n",
      "            (pre_layer): Linear(in_features=2048, out_features=512, bias=False)\n",
      "            (adapter): SCorDAInitialization(\n",
      "              adapter_A=Parameter(shape=torch.Size([2048, 8]), dtype=torch.float32, requires_grad=True),\n",
      "              adapter_B=Parameter(shape=torch.Size([8, 512]), dtype=torch.float32, requires_grad=True),\n",
      "              r=8,\n",
      "              init_strategy='lora'\n",
      "            )\n",
      "          )\n",
      "          (o_proj): SCorDALinear(\n",
      "            (pre_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "            (adapter): SCorDAInitialization(\n",
      "              adapter_A=Parameter(shape=torch.Size([2048, 8]), dtype=torch.float32, requires_grad=True),\n",
      "              adapter_B=Parameter(shape=torch.Size([8, 2048]), dtype=torch.float32, requires_grad=True),\n",
      "              r=8,\n",
      "              init_strategy='lora'\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): SCorDALinear(\n",
      "            (pre_layer): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "            (adapter): SCorDAInitialization(\n",
      "              adapter_A=Parameter(shape=torch.Size([2048, 8]), dtype=torch.float32, requires_grad=True),\n",
      "              adapter_B=Parameter(shape=torch.Size([8, 8192]), dtype=torch.float32, requires_grad=True),\n",
      "              r=8,\n",
      "              init_strategy='lora'\n",
      "            )\n",
      "          )\n",
      "          (down_proj): SCorDALinear(\n",
      "            (pre_layer): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "            (adapter): SCorDAInitialization(\n",
      "              adapter_A=Parameter(shape=torch.Size([8192, 8]), dtype=torch.float32, requires_grad=True),\n",
      "              adapter_B=Parameter(shape=torch.Size([8, 2048]), dtype=torch.float32, requires_grad=True),\n",
      "              r=8,\n",
      "              init_strategy='lora'\n",
      "            )\n",
      "          )\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_637778/1589253683.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2 = torch.load('./test_/testiik/checkpoint-5/pytorch_model.bin')\n"
     ]
    }
   ],
   "source": [
    "# model2, tokenizer2 = Models.LoadLLM(\"./test_/testiik/checkpoint-5\", 'cpu')\n",
    "import torch\n",
    "model2 = torch.load('./test_/testiik/checkpoint-5/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.embed_tokens.weight': tensor([[ 3.1281e-03,  1.7822e-02,  2.0996e-02,  ..., -5.2185e-03,\n",
      "         -4.1992e-02, -3.3447e-02],\n",
      "        [ 2.3682e-02, -2.2949e-02,  1.9897e-02,  ..., -9.4604e-03,\n",
      "         -2.2125e-03, -3.9551e-02],\n",
      "        [ 1.4465e-02,  1.0559e-02,  9.8267e-03,  ...,  6.8359e-03,\n",
      "         -1.1597e-02,  5.7983e-03],\n",
      "        ...,\n",
      "        [-1.0580e-06,  1.0620e-02, -1.9043e-02,  ...,  1.3885e-03,\n",
      "         -1.7700e-03,  9.7046e-03],\n",
      "        [-1.3635e-06,  1.0620e-02, -1.9043e-02,  ...,  1.3885e-03,\n",
      "         -1.7700e-03,  9.7046e-03],\n",
      "        [-1.1921e-06,  1.0620e-02, -1.9043e-02,  ...,  1.3885e-03,\n",
      "         -1.7700e-03,  9.7046e-03]], device='cuda:0'), 'model.layers.0.self_attn.q_proj.pre_layer.weight': tensor([[-0.0179,  0.0066,  0.0247,  ..., -0.0087, -0.0117,  0.0201],\n",
      "        [ 0.0122,  0.0593,  0.0552,  ..., -0.0332, -0.0154,  0.0108],\n",
      "        [ 0.0178,  0.0155,  0.0344,  ..., -0.0386, -0.0386, -0.0276],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0352,  0.0713,  ..., -0.0718, -0.0265, -0.0287],\n",
      "        [ 0.0226, -0.0248,  0.0352,  ..., -0.0120, -0.0287, -0.0148],\n",
      "        [-0.0258, -0.0537, -0.0131,  ...,  0.0542,  0.0096, -0.0028]],\n",
      "       device='cuda:0'), 'model.layers.0.self_attn.q_proj.adapter.adapter_A': tensor([[ 0.7758,  1.0938,  0.6865,  ..., -0.7037, -1.5281,  0.2357],\n",
      "        [-0.8341,  1.0341,  1.2011,  ..., -2.1251,  2.0054,  0.1610],\n",
      "        [ 0.0485,  1.8210, -0.0042,  ..., -0.1250,  0.5850, -0.2656],\n",
      "        ...,\n",
      "        [-0.1487,  0.1845, -0.2815,  ..., -0.9572, -0.3704,  0.2912],\n",
      "        [ 0.5367, -1.9701,  0.0476,  ..., -1.5390,  2.6498,  1.1581],\n",
      "        [ 0.9897,  0.1009,  0.4857,  ...,  0.3801,  0.8482,  1.2373]],\n",
      "       device='cuda:0'), 'model.layers.0.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.0.self_attn.k_proj.pre_layer.weight': tensor([[ 0.0581,  0.1177,  0.0615,  ..., -0.1040, -0.0311,  0.0201],\n",
      "        [-0.0123,  0.0742,  0.0576,  ..., -0.0266, -0.0206, -0.0449],\n",
      "        [-0.0771, -0.0386, -0.0023,  ...,  0.0031, -0.0211,  0.0010],\n",
      "        ...,\n",
      "        [-0.0045,  0.0067,  0.0023,  ...,  0.0023, -0.0272, -0.0048],\n",
      "        [-0.0245, -0.0109,  0.0420,  ...,  0.0322,  0.0200,  0.0080],\n",
      "        [ 0.0188,  0.0239,  0.0136,  ...,  0.0033,  0.0247,  0.0266]],\n",
      "       device='cuda:0'), 'model.layers.0.self_attn.k_proj.adapter.adapter_A': tensor([[ 1.0328,  1.3961, -0.0122,  ...,  0.7828,  0.3970, -1.2972],\n",
      "        [-0.6550,  0.5230, -0.6072,  ...,  0.9807,  1.8216, -0.1956],\n",
      "        [ 2.0627, -1.4603, -0.3697,  ..., -1.2132, -1.8837,  0.7908],\n",
      "        ...,\n",
      "        [-0.4603,  0.5785, -0.0463,  ..., -0.4677,  0.4380,  3.5861],\n",
      "        [ 0.1278, -0.6083,  0.9306,  ...,  0.1528,  0.1130, -0.0636],\n",
      "        [-0.5311,  0.6303, -1.1144,  ...,  0.6378, -0.5334, -2.5993]],\n",
      "       device='cuda:0'), 'model.layers.0.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.0.self_attn.v_proj.pre_layer.weight': tensor([[ 0.0149,  0.0009,  0.0115,  ...,  0.0082, -0.0057, -0.0085],\n",
      "        [ 0.0053, -0.0046, -0.0087,  ...,  0.0021,  0.0075, -0.0053],\n",
      "        [-0.0013,  0.0042, -0.0055,  ...,  0.0016,  0.0028,  0.0058],\n",
      "        ...,\n",
      "        [-0.0056,  0.0011, -0.0009,  ..., -0.0104, -0.0130,  0.0043],\n",
      "        [-0.0070, -0.0089, -0.0019,  ..., -0.0035, -0.0022,  0.0131],\n",
      "        [-0.0164, -0.0038,  0.0009,  ..., -0.0046, -0.0077, -0.0067]],\n",
      "       device='cuda:0'), 'model.layers.0.self_attn.v_proj.adapter.adapter_A': tensor([[-0.7475,  0.6733,  0.4051,  ...,  0.0267, -0.6191,  0.2180],\n",
      "        [-0.0355, -0.0111, -0.3407,  ...,  0.1642, -0.3248, -1.8870],\n",
      "        [ 0.7778,  0.2220, -0.5509,  ...,  0.0149,  1.1980,  1.3020],\n",
      "        ...,\n",
      "        [ 0.1828,  1.2037,  0.9152,  ...,  0.0568,  1.6184, -0.7802],\n",
      "        [ 0.2611,  0.5987, -1.4926,  ..., -0.7123, -0.0873,  0.1746],\n",
      "        [ 0.3915,  0.4213,  0.3415,  ..., -0.1891, -0.4458,  0.7219]],\n",
      "       device='cuda:0'), 'model.layers.0.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.0.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0001,  0.0056,  0.0142,  ..., -0.0089, -0.0020,  0.0118],\n",
      "        [ 0.0084,  0.0076, -0.0078,  ..., -0.0014,  0.0019, -0.0018],\n",
      "        [-0.0063, -0.0496, -0.0193,  ..., -0.0092, -0.0040, -0.0008],\n",
      "        ...,\n",
      "        [ 0.0110, -0.0132,  0.0031,  ...,  0.0093,  0.0023, -0.0090],\n",
      "        [ 0.0011, -0.0247, -0.0007,  ..., -0.0078, -0.0092, -0.0060],\n",
      "        [-0.0038,  0.0109, -0.0119,  ...,  0.0031,  0.0003,  0.0010]],\n",
      "       device='cuda:0'), 'model.layers.0.self_attn.o_proj.adapter.adapter_A': tensor([[-0.0063, -0.0676, -0.4634,  ...,  0.3149, -0.2490, -0.3961],\n",
      "        [-0.5119, -0.6908,  0.4126,  ..., -0.4850,  0.6466,  0.7421],\n",
      "        [ 0.6271, -0.2474,  0.3846,  ..., -0.1458,  0.7543, -1.3332],\n",
      "        ...,\n",
      "        [-0.3961, -0.6530, -0.2825,  ...,  0.3412, -1.1582, -1.5027],\n",
      "        [-1.0683,  2.0051,  0.0493,  ..., -0.7556, -0.7866, -1.3195],\n",
      "        [ 1.4329,  0.4812, -2.0960,  ...,  0.7164,  1.2430,  0.8262]],\n",
      "       device='cuda:0'), 'model.layers.0.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.0.mlp.gate_proj.weight': tensor([[ 0.0260, -0.0123, -0.0140,  ...,  0.0035,  0.0272,  0.0364],\n",
      "        [-0.0096,  0.0225,  0.0015,  ..., -0.0272, -0.0151,  0.0024],\n",
      "        [-0.0261, -0.0095,  0.0002,  ..., -0.0056, -0.0120, -0.0287],\n",
      "        ...,\n",
      "        [ 0.0198, -0.0228, -0.0190,  ...,  0.0289, -0.0427, -0.0137],\n",
      "        [-0.0026, -0.0109,  0.0011,  ..., -0.0037,  0.0061, -0.0140],\n",
      "        [-0.0231,  0.0049,  0.0086,  ..., -0.0120, -0.0069,  0.0070]],\n",
      "       device='cuda:0'), 'model.layers.0.mlp.up_proj.pre_layer.weight': tensor([[-0.0262,  0.0026,  0.0072,  ..., -0.0242,  0.0051, -0.0153],\n",
      "        [ 0.0306, -0.0074, -0.0181,  ...,  0.0058, -0.0378, -0.0165],\n",
      "        [ 0.0432,  0.0094,  0.0221,  ..., -0.0040,  0.0251,  0.0186],\n",
      "        ...,\n",
      "        [ 0.0159, -0.0381,  0.0222,  ..., -0.0071, -0.0071,  0.0273],\n",
      "        [-0.0032, -0.0060, -0.0142,  ...,  0.0142, -0.0086, -0.0048],\n",
      "        [-0.0084,  0.0146,  0.0156,  ...,  0.0037,  0.0030, -0.0076]],\n",
      "       device='cuda:0'), 'model.layers.0.mlp.up_proj.adapter.adapter_A': tensor([[ 1.3766,  0.3696,  1.3810,  ..., -0.0622, -0.0367,  0.5583],\n",
      "        [ 0.4218, -1.3758, -1.2366,  ..., -1.2707,  0.4158,  0.5717],\n",
      "        [-0.4070,  1.0217,  0.0729,  ..., -0.1522, -0.4313,  0.9732],\n",
      "        ...,\n",
      "        [ 2.2361,  0.8778,  1.1445,  ..., -2.6706,  0.1544, -0.7477],\n",
      "        [ 2.3984, -0.6337, -1.4576,  ...,  1.2682, -0.9398, -0.0954],\n",
      "        [ 0.0425, -1.6286,  0.1675,  ..., -0.7879, -0.8238,  0.7763]],\n",
      "       device='cuda:0'), 'model.layers.0.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.0.mlp.down_proj.pre_layer.weight': tensor([[-0.0269,  0.0176, -0.0003,  ..., -0.0194,  0.0115,  0.0058],\n",
      "        [ 0.0156, -0.0057,  0.0072,  ..., -0.0233,  0.0005,  0.0021],\n",
      "        [ 0.0255, -0.0082,  0.0317,  ...,  0.0143, -0.0016,  0.0046],\n",
      "        ...,\n",
      "        [ 0.0015, -0.0183, -0.0078,  ...,  0.0065, -0.0026,  0.0062],\n",
      "        [-0.0009, -0.0317, -0.0072,  ..., -0.0332, -0.0273,  0.0044],\n",
      "        [ 0.0366, -0.0103,  0.0033,  ...,  0.0093,  0.0067, -0.0150]],\n",
      "       device='cuda:0'), 'model.layers.0.mlp.down_proj.adapter.adapter_A': tensor([[-4.9230e-01,  1.2917e+00, -6.1602e-01,  ...,  1.2656e+00,\n",
      "         -1.0903e-02,  2.4215e-01],\n",
      "        [ 9.0861e-01, -1.3934e+00, -2.9446e-01,  ...,  8.5157e-01,\n",
      "         -1.0185e-01,  4.4662e-03],\n",
      "        [ 1.2304e-02,  1.7379e+00,  6.9104e-01,  ..., -7.7304e-01,\n",
      "          4.8709e-01,  8.2611e-01],\n",
      "        ...,\n",
      "        [-5.9454e-01,  1.5290e+00, -1.3713e+00,  ..., -7.5011e-02,\n",
      "          2.6691e+00,  2.2511e+00],\n",
      "        [-4.3027e-01,  1.3820e+00,  5.4889e-02,  ..., -1.9503e-01,\n",
      "          1.5796e-01, -1.2595e-01],\n",
      "        [-6.4618e-01, -4.0691e-01,  7.3708e-01,  ..., -5.1422e-01,\n",
      "         -9.6469e-01,  1.9577e-03]], device='cuda:0'), 'model.layers.0.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.0.input_layernorm.weight': tensor([0.1543, 0.1826, 0.2559,  ..., 0.2168, 0.2080, 0.1494], device='cuda:0'), 'model.layers.0.post_attention_layernorm.weight': tensor([0.1973, 0.1934, 0.1797,  ..., 0.2090, 0.1973, 0.2021], device='cuda:0'), 'model.layers.1.self_attn.q_proj.pre_layer.weight': tensor([[-0.0325,  0.0074, -0.0078,  ..., -0.0020, -0.0181,  0.0021],\n",
      "        [ 0.0089, -0.0016,  0.0027,  ...,  0.0026,  0.0381, -0.0225],\n",
      "        [ 0.0254, -0.0016, -0.0129,  ...,  0.0171, -0.0023,  0.0332],\n",
      "        ...,\n",
      "        [-0.0237,  0.0176,  0.0126,  ..., -0.0265, -0.0023,  0.0253],\n",
      "        [ 0.0009, -0.0095, -0.0119,  ..., -0.0308, -0.0056,  0.0035],\n",
      "        [ 0.0251, -0.0542, -0.0255,  ..., -0.0139,  0.0219, -0.0259]],\n",
      "       device='cuda:0'), 'model.layers.1.self_attn.q_proj.adapter.adapter_A': tensor([[-0.5744, -0.8355,  0.3557,  ..., -2.1672,  0.0482,  0.0616],\n",
      "        [ 1.0095, -1.0436,  0.3500,  ..., -1.0025,  0.8742,  1.5369],\n",
      "        [ 0.2348, -0.8262,  0.3317,  ..., -0.5046,  0.3160,  0.9592],\n",
      "        ...,\n",
      "        [ 0.1250,  0.6850,  0.2689,  ...,  0.9446, -0.2878, -0.2014],\n",
      "        [-1.8583,  0.5291, -0.7166,  ...,  0.5632, -0.1563, -1.0481],\n",
      "        [ 1.4602, -0.3419, -1.7669,  ..., -0.5248, -0.4649, -0.2245]],\n",
      "       device='cuda:0'), 'model.layers.1.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.1.self_attn.k_proj.pre_layer.weight': tensor([[-0.0583,  0.0047,  0.0061,  ..., -0.0260, -0.0903,  0.0295],\n",
      "        [ 0.0311,  0.0146,  0.0104,  ...,  0.0112,  0.0439, -0.0081],\n",
      "        [-0.0037,  0.0227,  0.0659,  ..., -0.0240, -0.0069,  0.0092],\n",
      "        ...,\n",
      "        [-0.0615, -0.0063, -0.0393,  ...,  0.0010, -0.0271,  0.0030],\n",
      "        [ 0.0669,  0.0045, -0.0330,  ...,  0.0330, -0.0173, -0.0303],\n",
      "        [ 0.0140, -0.0003,  0.0142,  ...,  0.0018, -0.0366, -0.0022]],\n",
      "       device='cuda:0'), 'model.layers.1.self_attn.k_proj.adapter.adapter_A': tensor([[-0.0275, -1.4666, -2.5007,  ...,  0.8142, -0.5224, -1.0869],\n",
      "        [-0.7709,  0.1210,  1.4434,  ..., -1.7479,  0.1132,  1.0164],\n",
      "        [-1.2673,  0.0386,  0.5157,  ..., -1.1110,  0.6028, -0.1539],\n",
      "        ...,\n",
      "        [ 0.6578, -0.3385,  1.0273,  ...,  0.7651, -0.1086, -0.0227],\n",
      "        [ 0.2797, -0.6922, -0.2729,  ..., -0.3979,  1.4152, -0.3159],\n",
      "        [-0.9097,  0.6284, -0.4456,  ...,  0.8451, -2.4485,  1.1702]],\n",
      "       device='cuda:0'), 'model.layers.1.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.1.self_attn.v_proj.pre_layer.weight': tensor([[-0.0138, -0.0065,  0.0029,  ..., -0.0002, -0.0065, -0.0132],\n",
      "        [-0.0261, -0.0036,  0.0237,  ..., -0.0008,  0.0060, -0.0057],\n",
      "        [ 0.0008, -0.0048,  0.0014,  ...,  0.0015,  0.0034, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0111, -0.0004, -0.0025,  ...,  0.0081, -0.0037,  0.0102],\n",
      "        [-0.0026,  0.0003,  0.0049,  ...,  0.0168, -0.0034, -0.0128],\n",
      "        [-0.0015, -0.0085,  0.0145,  ...,  0.0058, -0.0142, -0.0111]],\n",
      "       device='cuda:0'), 'model.layers.1.self_attn.v_proj.adapter.adapter_A': tensor([[ 1.5402, -0.5305, -0.0734,  ...,  0.4924,  2.0742,  0.5972],\n",
      "        [ 0.8261,  1.0320,  1.2503,  ..., -0.7363, -0.1937, -1.5421],\n",
      "        [-1.8331, -0.1576, -0.0866,  ..., -0.3588, -0.1151,  1.1267],\n",
      "        ...,\n",
      "        [-1.5276,  1.3196, -2.3251,  ..., -1.2051,  0.6476,  0.1805],\n",
      "        [ 0.7446, -0.5829, -0.5194,  ...,  0.0397,  1.3070, -1.3334],\n",
      "        [ 2.1771,  0.1012,  0.1439,  ..., -0.2588,  1.0734, -0.3936]],\n",
      "       device='cuda:0'), 'model.layers.1.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.1.self_attn.o_proj.pre_layer.weight': tensor([[-0.0140, -0.0209,  0.0090,  ..., -0.0243, -0.0219, -0.0052],\n",
      "        [-0.0110, -0.0199,  0.0209,  ..., -0.0100,  0.0100,  0.0352],\n",
      "        [-0.0014, -0.0089, -0.0150,  ..., -0.0020,  0.0086, -0.0223],\n",
      "        ...,\n",
      "        [-0.0095, -0.0047, -0.0086,  ..., -0.0064, -0.0211,  0.0170],\n",
      "        [ 0.0033,  0.0415, -0.0088,  ...,  0.0094, -0.0099,  0.0087],\n",
      "        [-0.0098, -0.0132,  0.0210,  ..., -0.0004,  0.0050,  0.0041]],\n",
      "       device='cuda:0'), 'model.layers.1.self_attn.o_proj.adapter.adapter_A': tensor([[ 0.2717,  0.1167,  0.8025,  ...,  0.9927,  1.7260,  1.1027],\n",
      "        [-0.0893, -0.6646, -1.1639,  ...,  0.2122, -0.3558,  0.7753],\n",
      "        [-0.5579, -0.0939, -0.1102,  ...,  0.6668,  0.2815,  0.3668],\n",
      "        ...,\n",
      "        [ 1.4791, -0.2370, -1.2043,  ...,  0.3659,  0.5260, -0.8703],\n",
      "        [ 0.0583, -0.5058, -0.9151,  ...,  0.4682,  1.8331, -1.2782],\n",
      "        [-1.6634,  0.8067, -0.8683,  ...,  0.3111, -1.8197, -0.4307]],\n",
      "       device='cuda:0'), 'model.layers.1.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.1.mlp.gate_proj.weight': tensor([[ 0.0080, -0.0156,  0.0088,  ...,  0.0264,  0.0094,  0.0047],\n",
      "        [-0.0188, -0.0134,  0.0140,  ..., -0.0327,  0.0298,  0.0400],\n",
      "        [-0.0088,  0.0061, -0.0007,  ...,  0.0295,  0.0033, -0.0262],\n",
      "        ...,\n",
      "        [ 0.0166, -0.0308, -0.0342,  ...,  0.0087,  0.0164, -0.0215],\n",
      "        [-0.0093,  0.0520, -0.0002,  ..., -0.0018,  0.0121, -0.0417],\n",
      "        [-0.0003, -0.0181,  0.0674,  ...,  0.0840,  0.0420, -0.0123]],\n",
      "       device='cuda:0'), 'model.layers.1.mlp.up_proj.pre_layer.weight': tensor([[-0.0393,  0.0172,  0.0143,  ...,  0.0157,  0.0195, -0.0016],\n",
      "        [-0.0210,  0.0016, -0.0053,  ...,  0.0084,  0.0101, -0.0195],\n",
      "        [-0.0033, -0.0105, -0.0134,  ...,  0.0144,  0.0164, -0.0063],\n",
      "        ...,\n",
      "        [ 0.0057, -0.0125,  0.0106,  ...,  0.0091,  0.0143, -0.0193],\n",
      "        [ 0.0107, -0.0194,  0.0269,  ...,  0.0118, -0.0112,  0.0129],\n",
      "        [ 0.0040, -0.0007, -0.0105,  ..., -0.0082,  0.0050, -0.0240]],\n",
      "       device='cuda:0'), 'model.layers.1.mlp.up_proj.adapter.adapter_A': tensor([[ 0.7920, -0.8322, -0.2347,  ...,  1.9718, -0.9126, -0.5608],\n",
      "        [ 0.1931,  0.8661,  0.8332,  ...,  0.3963, -1.2913, -1.4466],\n",
      "        [-0.0586, -2.8686, -0.2209,  ...,  0.1770,  0.0569, -0.1555],\n",
      "        ...,\n",
      "        [ 0.2112, -0.1518,  1.5069,  ...,  0.3090, -0.2012, -0.2929],\n",
      "        [-0.7406,  0.1990, -0.7156,  ...,  0.4433, -3.0892,  0.5998],\n",
      "        [-0.3141, -1.0386,  1.2406,  ...,  1.8760, -0.6731, -0.0417]],\n",
      "       device='cuda:0'), 'model.layers.1.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.1.mlp.down_proj.pre_layer.weight': tensor([[ 0.0003, -0.0096, -0.0002,  ..., -0.0381,  0.0058,  0.0134],\n",
      "        [-0.0200,  0.0002, -0.0055,  ...,  0.0010, -0.0219,  0.0086],\n",
      "        [ 0.0221,  0.0102, -0.0070,  ..., -0.0137,  0.0089,  0.0031],\n",
      "        ...,\n",
      "        [-0.0103,  0.0247,  0.0024,  ..., -0.0171,  0.0084, -0.0188],\n",
      "        [-0.0024, -0.0021, -0.0234,  ...,  0.0177, -0.0128,  0.0184],\n",
      "        [-0.0138, -0.0039, -0.0229,  ..., -0.0101, -0.0102, -0.0273]],\n",
      "       device='cuda:0'), 'model.layers.1.mlp.down_proj.adapter.adapter_A': tensor([[ 0.3173,  0.0591,  0.4277,  ..., -1.0655, -0.0819,  0.4123],\n",
      "        [ 1.4594,  0.3054,  1.8665,  ...,  0.3235,  0.6086, -0.2303],\n",
      "        [-0.9810, -1.4264,  0.2519,  ...,  0.4281, -1.2654,  0.7852],\n",
      "        ...,\n",
      "        [-0.1128, -0.3585,  0.9392,  ..., -1.6152,  0.0050,  0.6942],\n",
      "        [ 0.3520,  0.5743, -0.2979,  ...,  0.7086, -0.2446, -1.2326],\n",
      "        [-0.5720,  0.4250, -0.9305,  ..., -1.3566,  1.1367, -0.2332]],\n",
      "       device='cuda:0'), 'model.layers.1.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.1.input_layernorm.weight': tensor([0.3164, 0.3379, 0.3457,  ..., 0.3379, 0.5391, 0.2949], device='cuda:0'), 'model.layers.1.post_attention_layernorm.weight': tensor([0.2656, 0.2617, 0.1904,  ..., 0.2676, 0.2168, 0.2695], device='cuda:0'), 'model.layers.2.self_attn.q_proj.pre_layer.weight': tensor([[ 0.0259,  0.0469, -0.0058,  ..., -0.0087,  0.0566, -0.0181],\n",
      "        [-0.0208,  0.0056,  0.0026,  ...,  0.0047, -0.0332, -0.0166],\n",
      "        [ 0.0388,  0.0045, -0.0038,  ...,  0.0270,  0.0138, -0.0118],\n",
      "        ...,\n",
      "        [ 0.0254, -0.0302,  0.0043,  ...,  0.0239,  0.0003, -0.0041],\n",
      "        [-0.0491, -0.0164, -0.0003,  ...,  0.0510, -0.0237,  0.0190],\n",
      "        [ 0.0143, -0.0347,  0.0026,  ..., -0.0154, -0.0170, -0.0087]],\n",
      "       device='cuda:0'), 'model.layers.2.self_attn.q_proj.adapter.adapter_A': tensor([[ 0.9102, -0.5355,  0.1821,  ..., -0.3709,  1.2897,  0.5487],\n",
      "        [ 0.1803,  0.5825,  0.7865,  ..., -0.5389,  0.0705,  0.4265],\n",
      "        [-0.6489, -1.8715,  0.7068,  ...,  1.0538, -1.2818,  0.0325],\n",
      "        ...,\n",
      "        [-0.3542, -0.9961,  0.5853,  ..., -0.1439,  1.5620,  0.7312],\n",
      "        [-0.2641, -1.2345, -0.3177,  ...,  0.1829,  0.7364,  1.5962],\n",
      "        [ 0.4365,  0.5346, -0.9394,  ..., -0.0510,  1.6693,  0.4258]],\n",
      "       device='cuda:0'), 'model.layers.2.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.2.self_attn.k_proj.pre_layer.weight': tensor([[ 5.7129e-02, -1.1414e-02,  4.4434e-02,  ..., -3.7109e-02,\n",
      "          3.9307e-02,  4.1260e-02],\n",
      "        [-2.6611e-02,  6.0730e-03, -5.7617e-02,  ...,  4.5410e-02,\n",
      "         -2.4414e-02,  3.1128e-02],\n",
      "        [-9.5825e-03, -4.1504e-02, -1.8311e-02,  ...,  4.6968e-05,\n",
      "         -1.0864e-02,  4.1260e-02],\n",
      "        ...,\n",
      "        [ 8.7280e-03,  5.9570e-02,  4.4434e-02,  ..., -4.0039e-02,\n",
      "         -7.9102e-02,  2.6855e-02],\n",
      "        [ 8.4961e-02, -1.6357e-02, -1.1621e-01,  ..., -4.8340e-02,\n",
      "         -2.7832e-02, -4.7852e-02],\n",
      "        [-3.6133e-02,  2.0630e-02, -5.7617e-02,  ...,  8.3984e-02,\n",
      "         -1.4404e-02, -6.9336e-02]], device='cuda:0'), 'model.layers.2.self_attn.k_proj.adapter.adapter_A': tensor([[ 0.3445, -0.3392, -0.4693,  ...,  0.4744, -1.4191,  1.3367],\n",
      "        [ 0.7875, -0.3354, -2.2670,  ..., -0.3321,  0.6819,  0.2234],\n",
      "        [ 0.5148, -1.0478,  1.1868,  ...,  1.6794,  0.4404,  0.4957],\n",
      "        ...,\n",
      "        [ 1.9284, -1.0501,  0.2156,  ...,  0.3906, -0.0650, -1.4844],\n",
      "        [ 0.7750,  0.4955,  0.1328,  ..., -0.0866,  1.1564, -0.5417],\n",
      "        [ 2.1648,  0.8244, -0.1109,  ..., -0.3791, -0.9972, -2.0122]],\n",
      "       device='cuda:0'), 'model.layers.2.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.2.self_attn.v_proj.pre_layer.weight': tensor([[ 5.0049e-03,  1.1215e-03, -5.6458e-03,  ..., -1.2817e-02,\n",
      "         -4.9133e-03,  1.0376e-02],\n",
      "        [-2.4048e-02,  3.4180e-03,  6.5918e-03,  ...,  1.6602e-02,\n",
      "          5.5542e-03, -1.8188e-02],\n",
      "        [ 3.0518e-04, -1.4587e-02,  7.9956e-03,  ...,  3.0518e-02,\n",
      "          4.4861e-03,  1.1414e-02],\n",
      "        ...,\n",
      "        [ 3.0518e-03, -3.7994e-03,  3.1128e-03,  ..., -9.7046e-03,\n",
      "          1.7776e-03, -6.7749e-03],\n",
      "        [-5.2795e-03, -2.4414e-02, -2.0905e-03,  ...,  1.8158e-03,\n",
      "          2.6894e-04, -7.1106e-03],\n",
      "        [ 7.1716e-03, -2.0266e-05,  3.2196e-03,  ..., -4.8218e-03,\n",
      "         -7.9346e-03, -3.4180e-02]], device='cuda:0'), 'model.layers.2.self_attn.v_proj.adapter.adapter_A': tensor([[ 1.4805,  0.1282,  0.3978,  ..., -1.6745, -0.2039, -0.9423],\n",
      "        [ 1.3002,  0.6445, -1.8506,  ...,  0.2735,  1.5004,  1.0105],\n",
      "        [ 1.2965, -0.2016, -0.2846,  ..., -1.0428,  0.4058,  0.3935],\n",
      "        ...,\n",
      "        [ 1.5896, -0.7066, -0.5531,  ..., -1.9981,  1.2170,  0.8612],\n",
      "        [-0.6321, -0.2768,  0.5279,  ..., -0.1768, -0.1708,  0.3497],\n",
      "        [-0.0294, -0.1007, -0.4112,  ...,  0.3206,  1.5233,  0.2822]],\n",
      "       device='cuda:0'), 'model.layers.2.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.2.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0104, -0.0132, -0.0055,  ..., -0.0009,  0.0146, -0.0042],\n",
      "        [-0.0281,  0.0055,  0.0004,  ...,  0.0001, -0.0135, -0.0186],\n",
      "        [-0.0048,  0.0059,  0.0125,  ...,  0.0010, -0.0036, -0.0048],\n",
      "        ...,\n",
      "        [ 0.0044, -0.0022, -0.0094,  ...,  0.0013, -0.0096, -0.0005],\n",
      "        [ 0.0066,  0.0065,  0.0090,  ..., -0.0184,  0.0056,  0.0165],\n",
      "        [-0.0173, -0.0016, -0.0249,  ...,  0.0013,  0.0043,  0.0127]],\n",
      "       device='cuda:0'), 'model.layers.2.self_attn.o_proj.adapter.adapter_A': tensor([[ 0.4095,  0.5668,  0.2887,  ...,  0.9769,  1.8270, -0.0595],\n",
      "        [-0.7881, -1.4285,  0.4750,  ..., -1.2085,  0.6248,  0.2864],\n",
      "        [-1.5110,  0.0316, -0.0931,  ...,  2.0232,  1.1443,  1.8470],\n",
      "        ...,\n",
      "        [ 1.4189, -0.8382, -0.4109,  ..., -0.5060,  0.9103,  1.2699],\n",
      "        [-0.0222, -0.8726,  0.3446,  ...,  1.2531, -0.4084,  1.3428],\n",
      "        [ 0.3293,  0.2279, -0.8774,  ..., -0.1461, -1.4847, -0.1077]],\n",
      "       device='cuda:0'), 'model.layers.2.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.2.mlp.gate_proj.weight': tensor([[ 0.0276,  0.0226, -0.0061,  ..., -0.0105,  0.0014, -0.0347],\n",
      "        [ 0.0041, -0.0017, -0.0088,  ...,  0.0058,  0.0244,  0.0088],\n",
      "        [ 0.0137,  0.0004, -0.0091,  ...,  0.0008, -0.0057, -0.0078],\n",
      "        ...,\n",
      "        [ 0.0069,  0.0074, -0.0172,  ..., -0.0115, -0.0101,  0.0332],\n",
      "        [ 0.0093,  0.0267, -0.0195,  ...,  0.0003, -0.0064, -0.0126],\n",
      "        [-0.0162,  0.0036,  0.0081,  ...,  0.0112, -0.0115,  0.0234]],\n",
      "       device='cuda:0'), 'model.layers.2.mlp.up_proj.pre_layer.weight': tensor([[-0.0192, -0.0114,  0.0135,  ..., -0.0352, -0.0168,  0.0079],\n",
      "        [ 0.0254, -0.0153,  0.0173,  ..., -0.0302,  0.0039,  0.0058],\n",
      "        [ 0.0454,  0.0087,  0.0237,  ...,  0.0139,  0.0108, -0.0178],\n",
      "        ...,\n",
      "        [-0.0298,  0.0139,  0.0047,  ...,  0.0200, -0.0244,  0.0288],\n",
      "        [-0.0113, -0.0021, -0.0067,  ..., -0.0093,  0.0057, -0.0176],\n",
      "        [-0.0210, -0.0097, -0.0120,  ..., -0.0043,  0.0006, -0.0018]],\n",
      "       device='cuda:0'), 'model.layers.2.mlp.up_proj.adapter.adapter_A': tensor([[-0.3484, -0.5448,  1.0050,  ...,  2.1056,  0.6273, -1.2031],\n",
      "        [-2.0585, -0.2434,  1.2428,  ..., -1.1106,  0.5107, -0.1100],\n",
      "        [ 1.9688,  1.6100, -0.5327,  ..., -0.8948, -0.4006, -0.1782],\n",
      "        ...,\n",
      "        [-0.0570,  1.4816, -1.0219,  ...,  1.0526, -0.7466, -0.6156],\n",
      "        [ 1.3040,  1.0262,  0.8189,  ..., -0.6546, -0.8596,  0.2705],\n",
      "        [-0.0633, -0.9274,  1.2916,  ..., -0.2753,  1.1296, -0.5620]],\n",
      "       device='cuda:0'), 'model.layers.2.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.2.mlp.down_proj.pre_layer.weight': tensor([[-0.0017,  0.0060,  0.0383,  ...,  0.0249, -0.0179, -0.0151],\n",
      "        [-0.0330,  0.0019,  0.0297,  ...,  0.0017, -0.0330,  0.0262],\n",
      "        [ 0.0122, -0.0041, -0.0033,  ...,  0.0041,  0.0145, -0.0249],\n",
      "        ...,\n",
      "        [ 0.0041, -0.0167, -0.0120,  ..., -0.0302,  0.0099,  0.0018],\n",
      "        [-0.0030, -0.0099, -0.0251,  ..., -0.0205, -0.0303,  0.0200],\n",
      "        [-0.0166, -0.0049,  0.0029,  ...,  0.0064,  0.0214,  0.0337]],\n",
      "       device='cuda:0'), 'model.layers.2.mlp.down_proj.adapter.adapter_A': tensor([[ 2.0310,  0.8267,  1.1002,  ..., -0.4075, -1.2347,  0.4395],\n",
      "        [ 0.6589,  0.0529,  0.7838,  ...,  1.9222,  1.3179, -0.6524],\n",
      "        [ 0.4677, -2.2207,  1.2507,  ..., -0.0387, -1.6670, -0.2897],\n",
      "        ...,\n",
      "        [-1.1858,  0.2226, -1.0458,  ...,  0.2481,  1.3762,  0.2924],\n",
      "        [-0.0265,  1.4616,  2.6116,  ..., -1.1183,  2.5898,  0.8324],\n",
      "        [-0.5114, -0.8379, -1.4498,  ..., -0.2374, -0.8116,  1.6238]],\n",
      "       device='cuda:0'), 'model.layers.2.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.2.input_layernorm.weight': tensor([0.3965, 0.3984, 0.5000,  ..., 0.4062, 0.6953, 0.3750], device='cuda:0'), 'model.layers.2.post_attention_layernorm.weight': tensor([0.3066, 0.3047, 0.2256,  ..., 0.3125, 0.2715, 0.3125], device='cuda:0'), 'model.layers.3.self_attn.q_proj.pre_layer.weight': tensor([[-0.0029, -0.0033,  0.0092,  ...,  0.0067, -0.0087, -0.0004],\n",
      "        [-0.0074, -0.0012,  0.0198,  ...,  0.0050, -0.0048,  0.0184],\n",
      "        [-0.0024, -0.0052,  0.0077,  ...,  0.0034,  0.0027,  0.0095],\n",
      "        ...,\n",
      "        [-0.0149,  0.0413, -0.0173,  ..., -0.0664,  0.0107,  0.0225],\n",
      "        [ 0.0145, -0.0284,  0.0374,  ..., -0.0315,  0.0398, -0.0066],\n",
      "        [ 0.0483,  0.0227, -0.0052,  ...,  0.0254, -0.0199,  0.0332]],\n",
      "       device='cuda:0'), 'model.layers.3.self_attn.q_proj.adapter.adapter_A': tensor([[ 0.3428,  1.5249, -1.3155,  ..., -1.2064,  0.8467,  0.2912],\n",
      "        [ 0.2722,  0.0211,  1.3797,  ...,  1.6326, -0.2881,  1.3830],\n",
      "        [-0.8688,  0.6999, -0.5016,  ..., -0.9061,  2.8468,  0.5985],\n",
      "        ...,\n",
      "        [-0.9996,  1.2852,  0.9689,  ..., -1.8632, -0.6146, -0.6815],\n",
      "        [-0.4486, -0.9360, -0.7828,  ...,  3.0332,  1.2728,  0.8507],\n",
      "        [ 0.2550,  0.5618, -1.6463,  ...,  2.3111, -0.1957,  0.3349]],\n",
      "       device='cuda:0'), 'model.layers.3.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.3.self_attn.k_proj.pre_layer.weight': tensor([[ 0.0581,  0.0222, -0.0125,  ...,  0.0138, -0.0109, -0.0166],\n",
      "        [ 0.0356,  0.0014,  0.0225,  ..., -0.0422, -0.0040, -0.0369],\n",
      "        [-0.0244, -0.0119,  0.0110,  ..., -0.0337,  0.0114,  0.0124],\n",
      "        ...,\n",
      "        [ 0.0298, -0.0320, -0.0003,  ...,  0.0317,  0.0173,  0.0044],\n",
      "        [-0.0188,  0.0654, -0.0601,  ..., -0.0195, -0.0688, -0.0085],\n",
      "        [-0.0352, -0.0403,  0.0645,  ...,  0.0126,  0.0038, -0.0080]],\n",
      "       device='cuda:0'), 'model.layers.3.self_attn.k_proj.adapter.adapter_A': tensor([[ 2.6955,  0.0124,  0.3768,  ...,  0.3993,  1.2364, -2.7269],\n",
      "        [-0.1044,  0.7194,  0.1655,  ...,  0.5063, -0.4266, -0.7789],\n",
      "        [ 0.2261, -0.2830, -0.0384,  ...,  0.3357,  0.7854,  0.8496],\n",
      "        ...,\n",
      "        [-1.8449, -0.8464,  0.2679,  ..., -0.4872, -0.3692, -1.0337],\n",
      "        [ 1.6170, -0.4284, -0.8219,  ...,  1.0863, -1.7873, -0.0884],\n",
      "        [-0.6174, -2.8605,  0.5511,  ...,  0.4062, -1.4528,  1.0228]],\n",
      "       device='cuda:0'), 'model.layers.3.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.3.self_attn.v_proj.pre_layer.weight': tensor([[-0.0118,  0.0031,  0.0186,  ...,  0.0147, -0.0023, -0.0151],\n",
      "        [-0.0023,  0.0162,  0.0109,  ..., -0.0101,  0.0030,  0.0090],\n",
      "        [ 0.0090, -0.0019,  0.0034,  ...,  0.0013, -0.0013,  0.0162],\n",
      "        ...,\n",
      "        [-0.0019, -0.0186, -0.0042,  ..., -0.0032,  0.0038,  0.0135],\n",
      "        [-0.0052,  0.0050, -0.0049,  ..., -0.0028,  0.0059, -0.0166],\n",
      "        [-0.0082,  0.0114,  0.0073,  ..., -0.0011,  0.0006, -0.0212]],\n",
      "       device='cuda:0'), 'model.layers.3.self_attn.v_proj.adapter.adapter_A': tensor([[-0.5900,  0.2898, -1.0734,  ...,  1.7850,  0.4910,  0.8358],\n",
      "        [-0.9409, -1.0177, -0.0756,  ...,  0.4231,  0.2041,  0.8778],\n",
      "        [-0.5342,  0.3927, -1.5936,  ..., -1.9335, -0.6574,  0.4410],\n",
      "        ...,\n",
      "        [ 0.3451, -0.0502, -1.5454,  ...,  3.1103, -0.8503,  0.6301],\n",
      "        [ 0.5769, -0.0583, -1.6271,  ..., -0.6365,  0.5548,  1.3901],\n",
      "        [-1.0010, -0.1753, -0.8718,  ...,  1.7337,  0.2422, -0.7019]],\n",
      "       device='cuda:0'), 'model.layers.3.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.3.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0062, -0.0063,  0.0508,  ...,  0.0088,  0.0021, -0.0155],\n",
      "        [ 0.0025,  0.0303,  0.0115,  ..., -0.0400,  0.0227,  0.0150],\n",
      "        [ 0.0036, -0.0016,  0.0006,  ...,  0.0022, -0.0099, -0.0018],\n",
      "        ...,\n",
      "        [ 0.0122, -0.0273, -0.0142,  ..., -0.0065,  0.0386,  0.0212],\n",
      "        [-0.0256, -0.0249, -0.0109,  ..., -0.0124, -0.0053, -0.0137],\n",
      "        [ 0.0116, -0.0168, -0.0134,  ..., -0.0043, -0.0031,  0.0179]],\n",
      "       device='cuda:0'), 'model.layers.3.self_attn.o_proj.adapter.adapter_A': tensor([[ 0.1993, -1.1363, -1.5370,  ..., -0.2880,  0.4776, -0.5009],\n",
      "        [ 0.9081,  0.3963, -1.1025,  ...,  0.7084, -0.5183, -0.6578],\n",
      "        [ 0.2226,  0.2165,  1.3659,  ...,  0.1021,  0.5129, -0.3904],\n",
      "        ...,\n",
      "        [-1.9037,  1.5499, -0.5734,  ..., -0.6831,  0.8944,  0.2914],\n",
      "        [ 0.4311, -0.3919, -0.6499,  ..., -0.4529,  0.3750,  0.7628],\n",
      "        [-1.2311, -0.6514,  1.4452,  ...,  0.3934,  0.8716,  0.3154]],\n",
      "       device='cuda:0'), 'model.layers.3.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.3.mlp.gate_proj.weight': tensor([[-0.0200, -0.0112, -0.0254,  ...,  0.0150,  0.0104, -0.0197],\n",
      "        [-0.0017,  0.0605,  0.0679,  ...,  0.0227, -0.0294, -0.0703],\n",
      "        [ 0.0322, -0.0017, -0.0035,  ..., -0.0109,  0.0159,  0.0115],\n",
      "        ...,\n",
      "        [-0.0125, -0.0417, -0.0034,  ...,  0.0048,  0.0130, -0.0330],\n",
      "        [-0.0302, -0.0074,  0.0139,  ...,  0.0344, -0.0027, -0.0156],\n",
      "        [-0.0356, -0.0107,  0.0209,  ..., -0.0005,  0.0272, -0.0420]],\n",
      "       device='cuda:0'), 'model.layers.3.mlp.up_proj.pre_layer.weight': tensor([[-0.0332, -0.0195,  0.0143,  ..., -0.0256, -0.0164, -0.0069],\n",
      "        [-0.0059,  0.0444,  0.0037,  ...,  0.0086, -0.0113, -0.0061],\n",
      "        [-0.0204,  0.0189, -0.0019,  ..., -0.0055, -0.0016, -0.0153],\n",
      "        ...,\n",
      "        [ 0.0266,  0.0192, -0.0118,  ...,  0.0097, -0.0018, -0.0227],\n",
      "        [-0.0067,  0.0089, -0.0209,  ...,  0.0189,  0.0075, -0.0227],\n",
      "        [ 0.0288, -0.0007,  0.0264,  ..., -0.0159,  0.0060, -0.0016]],\n",
      "       device='cuda:0'), 'model.layers.3.mlp.up_proj.adapter.adapter_A': tensor([[-2.6041,  1.9216,  0.0512,  ..., -0.3288, -0.4590, -0.4073],\n",
      "        [ 0.9190, -0.0931, -0.1941,  ...,  0.9159,  1.1327, -0.6056],\n",
      "        [ 1.0644, -0.5217, -0.5491,  ...,  0.6396,  1.0273,  0.2561],\n",
      "        ...,\n",
      "        [ 1.0298, -0.1658,  0.0530,  ..., -0.0979,  1.0283, -0.9348],\n",
      "        [-1.2480, -0.9501,  0.0337,  ..., -0.6558,  1.3954,  0.7386],\n",
      "        [-0.6853,  1.4223, -2.1783,  ..., -1.4874, -1.4286, -0.8612]],\n",
      "       device='cuda:0'), 'model.layers.3.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.3.mlp.down_proj.pre_layer.weight': tensor([[ 0.0205, -0.0012,  0.0128,  ...,  0.0046, -0.0209, -0.0095],\n",
      "        [ 0.0381,  0.0308, -0.0143,  ..., -0.0159, -0.0082,  0.0093],\n",
      "        [ 0.0011,  0.0009,  0.0030,  ..., -0.0066,  0.0065,  0.0041],\n",
      "        ...,\n",
      "        [-0.0145, -0.0052, -0.0138,  ...,  0.0173, -0.0476, -0.0056],\n",
      "        [ 0.0077,  0.0166,  0.0082,  ...,  0.0069,  0.0080,  0.0078],\n",
      "        [ 0.0146,  0.0096, -0.0008,  ...,  0.0002, -0.0195,  0.0183]],\n",
      "       device='cuda:0'), 'model.layers.3.mlp.down_proj.adapter.adapter_A': tensor([[-1.1821e-03,  6.9291e-01, -1.4022e+00,  ..., -2.0937e-01,\n",
      "         -9.6348e-02, -1.8293e+00],\n",
      "        [-1.0364e+00, -3.2705e-01,  5.2363e-01,  ..., -5.5069e-01,\n",
      "         -3.0779e-01, -5.3273e-01],\n",
      "        [-1.3541e+00,  7.5000e-01, -1.0064e+00,  ...,  6.9424e-01,\n",
      "         -1.6064e+00, -3.2024e-02],\n",
      "        ...,\n",
      "        [ 5.8323e-01,  1.6403e+00,  5.6402e-01,  ..., -2.1735e+00,\n",
      "          8.0661e-01,  1.0563e+00],\n",
      "        [ 1.2660e+00,  6.9269e-01,  2.5639e+00,  ...,  1.7200e-01,\n",
      "          4.6872e-01,  1.8202e-01],\n",
      "        [-2.8706e-01,  1.0224e+00,  2.1958e+00,  ..., -6.9472e-01,\n",
      "          1.0303e+00, -7.9294e-01]], device='cuda:0'), 'model.layers.3.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.3.input_layernorm.weight': tensor([0.3965, 0.4395, 0.3555,  ..., 0.3711, 0.5977, 0.3633], device='cuda:0'), 'model.layers.3.post_attention_layernorm.weight': tensor([0.3223, 0.3105, 0.2393,  ..., 0.3203, 0.2500, 0.3242], device='cuda:0'), 'model.layers.4.self_attn.q_proj.pre_layer.weight': tensor([[-0.0015,  0.0183,  0.0190,  ..., -0.0093,  0.0052, -0.0405],\n",
      "        [ 0.0137,  0.0057, -0.0038,  ..., -0.0162,  0.0111, -0.0117],\n",
      "        [-0.0080,  0.0099, -0.0033,  ..., -0.0226,  0.0137, -0.0233],\n",
      "        ...,\n",
      "        [-0.0216, -0.0258, -0.0070,  ..., -0.0559, -0.0228, -0.0220],\n",
      "        [ 0.0187, -0.0199,  0.0193,  ...,  0.0522,  0.0081,  0.0240],\n",
      "        [-0.0201, -0.0057, -0.0054,  ...,  0.0188,  0.0016, -0.0214]],\n",
      "       device='cuda:0'), 'model.layers.4.self_attn.q_proj.adapter.adapter_A': tensor([[ 0.0867, -1.6159,  0.1149,  ..., -0.3325, -0.7454, -0.9664],\n",
      "        [-0.2415, -1.5887,  1.0360,  ...,  0.6473, -0.5165,  2.6194],\n",
      "        [ 1.6216, -1.6313, -0.1068,  ..., -1.2575,  0.9048,  0.5493],\n",
      "        ...,\n",
      "        [ 0.1223,  0.5421,  1.1158,  ..., -1.9279, -0.5429,  0.0400],\n",
      "        [-0.7129,  0.5019,  1.1217,  ...,  0.0678, -0.2668, -1.0272],\n",
      "        [-0.4457, -0.9572,  0.7609,  ..., -0.6270, -1.2141,  0.4008]],\n",
      "       device='cuda:0'), 'model.layers.4.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.4.self_attn.k_proj.pre_layer.weight': tensor([[ 0.0171, -0.0090, -0.0012,  ...,  0.0532,  0.0069,  0.0518],\n",
      "        [-0.0166, -0.0056,  0.0148,  ...,  0.0006,  0.0077, -0.0277],\n",
      "        [ 0.0522, -0.0201, -0.0208,  ..., -0.0299, -0.0019,  0.0164],\n",
      "        ...,\n",
      "        [ 0.0518, -0.0101, -0.0035,  ..., -0.0079, -0.0003,  0.0225],\n",
      "        [ 0.1021, -0.0142,  0.0132,  ..., -0.0486,  0.0947,  0.0280],\n",
      "        [ 0.0361, -0.0540,  0.1152,  ...,  0.0011, -0.0518, -0.0061]],\n",
      "       device='cuda:0'), 'model.layers.4.self_attn.k_proj.adapter.adapter_A': tensor([[ 2.6581e+00,  5.9565e-01,  3.1639e-01,  ..., -8.2223e-01,\n",
      "         -2.7540e-01,  9.8360e-01],\n",
      "        [ 1.3051e+00, -1.5371e+00,  2.0958e-01,  ..., -1.9706e-01,\n",
      "         -1.6116e-02,  9.1229e-01],\n",
      "        [ 5.7330e-01, -6.5203e-04,  2.1956e+00,  ...,  1.1505e+00,\n",
      "          1.2293e+00, -7.0209e-01],\n",
      "        ...,\n",
      "        [ 1.0413e+00,  2.0414e+00, -1.7676e+00,  ...,  1.5373e-01,\n",
      "         -2.2242e-01, -4.9590e-01],\n",
      "        [ 8.3552e-01, -1.1559e+00,  6.0281e-02,  ..., -7.7248e-02,\n",
      "         -3.5776e-01,  1.0873e+00],\n",
      "        [ 4.4136e-01, -2.5517e-01,  2.2035e+00,  ...,  7.7416e-01,\n",
      "         -9.0968e-01, -1.4986e+00]], device='cuda:0'), 'model.layers.4.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.4.self_attn.v_proj.pre_layer.weight': tensor([[ 0.0056, -0.0366, -0.0017,  ...,  0.0171,  0.0015,  0.0008],\n",
      "        [-0.0010, -0.0098,  0.0148,  ..., -0.0046, -0.0045,  0.0079],\n",
      "        [ 0.0110,  0.0052,  0.0004,  ..., -0.0118,  0.0053, -0.0239],\n",
      "        ...,\n",
      "        [ 0.0070, -0.0156,  0.0089,  ...,  0.0058,  0.0081, -0.0095],\n",
      "        [ 0.0008,  0.0090, -0.0060,  ..., -0.0056,  0.0027,  0.0269],\n",
      "        [ 0.0278, -0.0104,  0.0036,  ...,  0.0048,  0.0066, -0.0089]],\n",
      "       device='cuda:0'), 'model.layers.4.self_attn.v_proj.adapter.adapter_A': tensor([[-0.5339,  0.0198,  0.3964,  ...,  0.1016, -0.7753, -1.6867],\n",
      "        [ 0.0753,  0.6994,  0.4819,  ..., -1.5876,  0.7735, -1.1218],\n",
      "        [-1.7265,  0.5247,  0.2523,  ..., -0.4971,  0.6105,  0.3482],\n",
      "        ...,\n",
      "        [ 0.7593, -2.6050,  0.6076,  ..., -1.1999,  0.1543,  0.6054],\n",
      "        [ 1.8132, -0.7120,  0.0323,  ...,  0.2346,  2.0925,  0.9204],\n",
      "        [ 0.4303, -0.7939, -0.4418,  ..., -0.8827, -0.3433,  0.5604]],\n",
      "       device='cuda:0'), 'model.layers.4.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.4.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0025, -0.0015, -0.0083,  ...,  0.0143,  0.0420,  0.0103],\n",
      "        [ 0.0270, -0.0122,  0.0018,  ..., -0.0007, -0.0011, -0.0068],\n",
      "        [ 0.0012, -0.0025, -0.0071,  ...,  0.0016, -0.0012,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0112, -0.0165,  0.0062,  ...,  0.0012,  0.0192,  0.0210],\n",
      "        [-0.0310,  0.0317,  0.0228,  ...,  0.0049, -0.0143,  0.0091],\n",
      "        [-0.0076,  0.0026, -0.0009,  ..., -0.0131,  0.0220, -0.0026]],\n",
      "       device='cuda:0'), 'model.layers.4.self_attn.o_proj.adapter.adapter_A': tensor([[-1.7804, -1.0527, -0.6153,  ..., -0.1832, -1.6058, -1.3712],\n",
      "        [-2.6333,  1.5195, -0.5047,  ..., -0.0853, -1.1329, -0.7128],\n",
      "        [ 0.1294,  0.2366,  0.0610,  ...,  0.9619, -1.4770, -0.1481],\n",
      "        ...,\n",
      "        [-1.0617,  0.0993,  0.0988,  ..., -0.6979,  0.6110,  1.2467],\n",
      "        [-1.6813,  0.8231, -0.8197,  ...,  1.1635, -1.0498, -0.3024],\n",
      "        [ 0.4343,  0.2974,  0.3975,  ...,  0.2370,  1.0349,  2.1369]],\n",
      "       device='cuda:0'), 'model.layers.4.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.4.mlp.gate_proj.weight': tensor([[ 0.0042,  0.0505, -0.0103,  ...,  0.0674,  0.0208, -0.0214],\n",
      "        [-0.0109, -0.0284, -0.0200,  ...,  0.0359, -0.0111, -0.0454],\n",
      "        [-0.0170,  0.0170,  0.0006,  ..., -0.0312, -0.0153, -0.0248],\n",
      "        ...,\n",
      "        [-0.0210, -0.0098, -0.0031,  ...,  0.0164, -0.0016,  0.0190],\n",
      "        [-0.0193,  0.0018, -0.0417,  ...,  0.0065,  0.0359, -0.0098],\n",
      "        [-0.0112,  0.0123, -0.0193,  ...,  0.0216, -0.0234, -0.0066]],\n",
      "       device='cuda:0'), 'model.layers.4.mlp.up_proj.pre_layer.weight': tensor([[-0.0004, -0.0027,  0.0004,  ...,  0.0093,  0.0039, -0.0126],\n",
      "        [ 0.0126,  0.0115,  0.0062,  ...,  0.0059, -0.0231,  0.0381],\n",
      "        [ 0.0031,  0.0102,  0.0078,  ...,  0.0042, -0.0159, -0.0051],\n",
      "        ...,\n",
      "        [-0.0132,  0.0040,  0.0149,  ..., -0.0109, -0.0072,  0.0117],\n",
      "        [ 0.0086, -0.0037,  0.0058,  ..., -0.0035, -0.0064, -0.0043],\n",
      "        [-0.0312,  0.0020,  0.0049,  ..., -0.0125,  0.0070,  0.0034]],\n",
      "       device='cuda:0'), 'model.layers.4.mlp.up_proj.adapter.adapter_A': tensor([[ 0.1480, -1.6126,  0.1639,  ...,  0.1681,  0.7825, -0.6146],\n",
      "        [-1.9473,  0.0807,  0.4354,  ..., -0.6330, -0.0532,  0.1789],\n",
      "        [-0.9055,  0.1211, -0.4838,  ...,  0.0533, -0.0137, -0.8645],\n",
      "        ...,\n",
      "        [ 0.7020, -0.4513,  0.2503,  ...,  0.3068,  0.0063, -0.6176],\n",
      "        [-0.0206, -0.4691,  0.1869,  ..., -0.4936,  0.8281,  1.1709],\n",
      "        [-0.5861, -0.0876, -1.0524,  ...,  0.3730,  0.5514,  0.1444]],\n",
      "       device='cuda:0'), 'model.layers.4.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.4.mlp.down_proj.pre_layer.weight': tensor([[-0.0012,  0.0132,  0.0119,  ..., -0.0105,  0.0093, -0.0027],\n",
      "        [-0.0004, -0.0115,  0.0369,  ...,  0.0220, -0.0154, -0.0116],\n",
      "        [-0.0143, -0.0016,  0.0008,  ..., -0.0104, -0.0036,  0.0070],\n",
      "        ...,\n",
      "        [ 0.0159,  0.0080,  0.0025,  ...,  0.0067, -0.0264, -0.0082],\n",
      "        [ 0.0234,  0.0164, -0.0233,  ...,  0.0131,  0.0067, -0.0104],\n",
      "        [-0.0054, -0.0222, -0.0028,  ...,  0.0125,  0.0011,  0.0009]],\n",
      "       device='cuda:0'), 'model.layers.4.mlp.down_proj.adapter.adapter_A': tensor([[-1.5812, -1.4672,  0.2332,  ..., -0.9584, -0.8493, -0.0276],\n",
      "        [ 0.1002,  0.9571,  0.8958,  ..., -0.2153, -0.7084, -0.8381],\n",
      "        [ 0.2860,  0.5357,  0.8441,  ...,  1.1104, -0.4319,  0.4073],\n",
      "        ...,\n",
      "        [ 0.0362,  0.9598,  0.0186,  ...,  0.8868,  1.9921,  1.3690],\n",
      "        [-0.1044, -0.4777,  0.0913,  ..., -0.8230,  1.3127,  0.1325],\n",
      "        [ 1.9534, -0.2481,  0.0437,  ...,  0.7222,  0.7098,  0.6094]],\n",
      "       device='cuda:0'), 'model.layers.4.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.4.input_layernorm.weight': tensor([0.4043, 0.4160, 0.3516,  ..., 0.4102, 0.5859, 0.3750], device='cuda:0'), 'model.layers.4.post_attention_layernorm.weight': tensor([0.3301, 0.3340, 0.2100,  ..., 0.3301, 0.2539, 0.3340], device='cuda:0'), 'model.layers.5.self_attn.q_proj.pre_layer.weight': tensor([[-0.0059,  0.0120,  0.0005,  ..., -0.0125,  0.0045,  0.0137],\n",
      "        [-0.0019, -0.0079, -0.0050,  ...,  0.0141, -0.0003, -0.0211],\n",
      "        [-0.0052,  0.0036, -0.0067,  ...,  0.0016,  0.0132, -0.0171],\n",
      "        ...,\n",
      "        [ 0.0041, -0.0187, -0.0192,  ...,  0.0245,  0.0212, -0.0004],\n",
      "        [-0.0283,  0.0200, -0.0017,  ...,  0.0006, -0.0149,  0.0111],\n",
      "        [-0.0092,  0.0449,  0.0256,  ..., -0.0128,  0.0173,  0.0198]],\n",
      "       device='cuda:0'), 'model.layers.5.self_attn.q_proj.adapter.adapter_A': tensor([[ 0.8890,  0.1877, -0.6464,  ..., -1.2159,  1.8906, -0.2960],\n",
      "        [ 1.1537, -0.9560,  0.1942,  ...,  1.1896, -2.1340,  0.2351],\n",
      "        [-0.2495,  0.8489,  0.2869,  ..., -1.0053, -0.8844, -0.5700],\n",
      "        ...,\n",
      "        [-1.2558,  1.2294, -1.3133,  ..., -0.0203, -0.1365, -1.0009],\n",
      "        [-1.9493, -0.3480, -0.7549,  ..., -0.2706,  1.2595, -1.0941],\n",
      "        [-0.8875,  1.1750,  0.6322,  ...,  0.2332,  1.4342,  0.0087]],\n",
      "       device='cuda:0'), 'model.layers.5.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.5.self_attn.k_proj.pre_layer.weight': tensor([[ 0.0093,  0.0029,  0.0281,  ...,  0.0215,  0.0056,  0.0091],\n",
      "        [ 0.0147,  0.0087, -0.0216,  ..., -0.0272,  0.0015, -0.0170],\n",
      "        [ 0.0128, -0.0215, -0.0532,  ...,  0.0410, -0.0322, -0.0031],\n",
      "        ...,\n",
      "        [-0.0664, -0.0046,  0.0273,  ..., -0.0618,  0.0359, -0.0488],\n",
      "        [ 0.0157, -0.0452, -0.0098,  ...,  0.0396,  0.0386,  0.0177],\n",
      "        [-0.0569, -0.0801,  0.0150,  ..., -0.0177, -0.0101,  0.0674]],\n",
      "       device='cuda:0'), 'model.layers.5.self_attn.k_proj.adapter.adapter_A': tensor([[ 0.1519, -0.0693, -0.1399,  ..., -0.4793, -1.1293,  1.6345],\n",
      "        [ 1.0540,  0.8855,  1.2458,  ..., -2.0696,  0.6841,  0.8887],\n",
      "        [-0.7908, -2.1215,  1.7027,  ...,  0.4826,  0.2227, -2.6429],\n",
      "        ...,\n",
      "        [ 0.0831,  0.5173, -0.2170,  ...,  0.8969, -0.2691, -0.4952],\n",
      "        [ 1.1027,  0.0367, -1.1121,  ...,  1.8327, -0.2667, -2.1988],\n",
      "        [ 1.1348, -0.8708, -1.2157,  ..., -1.9878, -0.5776,  0.0252]],\n",
      "       device='cuda:0'), 'model.layers.5.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.5.self_attn.v_proj.pre_layer.weight': tensor([[ 0.0173, -0.0166, -0.0021,  ...,  0.0300, -0.0177,  0.0012],\n",
      "        [-0.0160, -0.0065,  0.0017,  ..., -0.0031,  0.0098, -0.0220],\n",
      "        [ 0.0140, -0.0005,  0.0035,  ..., -0.0123,  0.0050, -0.0013],\n",
      "        ...,\n",
      "        [-0.0056,  0.0139, -0.0055,  ...,  0.0058,  0.0092,  0.0172],\n",
      "        [ 0.0069,  0.0081,  0.0068,  ..., -0.0075,  0.0089, -0.0106],\n",
      "        [ 0.0087, -0.0332, -0.0019,  ..., -0.0036,  0.0053,  0.0161]],\n",
      "       device='cuda:0'), 'model.layers.5.self_attn.v_proj.adapter.adapter_A': tensor([[ 0.8315, -1.1624, -0.6943,  ..., -0.7350,  1.1921, -2.7231],\n",
      "        [-1.0109,  0.9846,  1.6951,  ...,  1.7671,  1.3951,  0.7837],\n",
      "        [ 0.5558, -0.3375, -0.5562,  ..., -0.7000, -0.1885,  0.6527],\n",
      "        ...,\n",
      "        [-0.5766,  1.1722, -0.3882,  ..., -0.9299, -0.1876, -0.2581],\n",
      "        [ 2.1059,  1.5198,  0.2210,  ...,  0.4652, -0.5096,  1.6622],\n",
      "        [-1.9706, -0.1271,  0.7169,  ..., -1.3245,  0.1739,  0.1346]],\n",
      "       device='cuda:0'), 'model.layers.5.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.5.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0432, -0.0130, -0.0039,  ...,  0.0312,  0.0080,  0.0205],\n",
      "        [ 0.0014,  0.0030,  0.0002,  ...,  0.0220, -0.0071,  0.0141],\n",
      "        [-0.0032, -0.0058,  0.0015,  ...,  0.0057,  0.0025, -0.0073],\n",
      "        ...,\n",
      "        [-0.0200,  0.0025,  0.0187,  ...,  0.0126, -0.0026,  0.0100],\n",
      "        [-0.0096, -0.0269, -0.0143,  ...,  0.0056,  0.0286,  0.0073],\n",
      "        [-0.0078,  0.0002, -0.0198,  ...,  0.0019, -0.0091,  0.0159]],\n",
      "       device='cuda:0'), 'model.layers.5.self_attn.o_proj.adapter.adapter_A': tensor([[ 1.5281, -0.4606,  1.1533,  ..., -1.4874,  1.5573,  1.0254],\n",
      "        [ 1.0972, -0.5043,  1.6238,  ..., -1.2116, -0.4714,  2.3377],\n",
      "        [ 0.7626,  0.3191, -0.0420,  ...,  0.2159, -0.6923,  1.7901],\n",
      "        ...,\n",
      "        [ 0.5158, -0.9346,  1.1402,  ...,  0.8871,  0.4712,  1.2167],\n",
      "        [-0.0928, -0.0870, -1.6107,  ..., -2.7970,  0.2257,  0.6979],\n",
      "        [ 0.5724,  0.3184,  1.7053,  ...,  0.2501,  0.2233,  1.9067]],\n",
      "       device='cuda:0'), 'model.layers.5.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.5.mlp.gate_proj.weight': tensor([[-0.0173,  0.0261, -0.0168,  ..., -0.0160, -0.0009,  0.0086],\n",
      "        [-0.0312, -0.0203,  0.0201,  ..., -0.0190, -0.0242, -0.0432],\n",
      "        [ 0.0161,  0.0112,  0.0109,  ..., -0.0342, -0.0087,  0.0115],\n",
      "        ...,\n",
      "        [-0.0278,  0.0172,  0.0026,  ...,  0.0182,  0.0134, -0.0255],\n",
      "        [ 0.0251,  0.0615,  0.0479,  ...,  0.0559,  0.0347, -0.0231],\n",
      "        [ 0.0173,  0.0153,  0.0063,  ..., -0.0306,  0.0361, -0.0054]],\n",
      "       device='cuda:0'), 'model.layers.5.mlp.up_proj.pre_layer.weight': tensor([[ 0.0175,  0.0020,  0.0089,  ...,  0.0046, -0.0103,  0.0280],\n",
      "        [ 0.0298,  0.0015,  0.0076,  ...,  0.0090,  0.0013, -0.0095],\n",
      "        [-0.0439,  0.0254, -0.0015,  ...,  0.0474, -0.0400, -0.0410],\n",
      "        ...,\n",
      "        [-0.0043,  0.0408, -0.0002,  ...,  0.0077,  0.0029,  0.0084],\n",
      "        [ 0.0068,  0.0041, -0.0009,  ..., -0.0243,  0.0033,  0.0058],\n",
      "        [-0.0190, -0.0103,  0.0255,  ...,  0.0029, -0.0009,  0.0278]],\n",
      "       device='cuda:0'), 'model.layers.5.mlp.up_proj.adapter.adapter_A': tensor([[ 0.7051, -1.0466, -0.6821,  ...,  0.0197,  1.0403,  0.2568],\n",
      "        [-1.1887,  1.1017, -0.6011,  ..., -1.1782, -0.2648,  0.2492],\n",
      "        [-0.0384, -0.6168,  1.7046,  ..., -1.6672,  0.3432,  1.6763],\n",
      "        ...,\n",
      "        [-0.9109, -1.5554,  0.5532,  ...,  1.3358, -0.6581, -0.2168],\n",
      "        [ 0.5382, -0.4927, -1.1064,  ..., -1.6644,  0.5969,  0.6254],\n",
      "        [-0.9284,  0.5669, -1.6362,  ..., -0.9246,  0.9655,  1.5669]],\n",
      "       device='cuda:0'), 'model.layers.5.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.5.mlp.down_proj.pre_layer.weight': tensor([[ 0.0231,  0.0352, -0.0150,  ...,  0.0066, -0.0157, -0.0269],\n",
      "        [ 0.0101, -0.0112,  0.0022,  ...,  0.0197, -0.0057, -0.0144],\n",
      "        [-0.0046,  0.0053, -0.0013,  ..., -0.0070,  0.0104,  0.0114],\n",
      "        ...,\n",
      "        [-0.0342,  0.0004,  0.0250,  ...,  0.0153,  0.0092,  0.0199],\n",
      "        [-0.0081,  0.0055, -0.0093,  ..., -0.0022, -0.0077,  0.0149],\n",
      "        [-0.0152,  0.0106, -0.0237,  ...,  0.0226,  0.0145, -0.0089]],\n",
      "       device='cuda:0'), 'model.layers.5.mlp.down_proj.adapter.adapter_A': tensor([[-0.7836,  1.5840, -0.4472,  ...,  0.3091,  0.8164, -0.9600],\n",
      "        [-0.6420, -1.8244, -0.3985,  ..., -3.0344, -0.7729,  1.1639],\n",
      "        [-0.6096, -1.3905, -1.8688,  ..., -0.5575, -0.4059, -1.3884],\n",
      "        ...,\n",
      "        [ 0.2450, -0.9520, -0.1945,  ..., -0.7070,  0.2663, -0.2315],\n",
      "        [ 1.0014,  0.6058,  0.2730,  ...,  1.7634,  0.3189, -0.5896],\n",
      "        [ 1.2176, -0.4853, -1.5540,  ...,  0.2816,  0.2975, -1.5046]],\n",
      "       device='cuda:0'), 'model.layers.5.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.5.input_layernorm.weight': tensor([0.4727, 0.5078, 0.3477,  ..., 0.4004, 0.5547, 0.4141], device='cuda:0'), 'model.layers.5.post_attention_layernorm.weight': tensor([0.3438, 0.3457, 0.1973,  ..., 0.3535, 0.2676, 0.3496], device='cuda:0'), 'model.layers.6.self_attn.q_proj.pre_layer.weight': tensor([[ 0.0048,  0.0111,  0.0182,  ..., -0.0139, -0.0004,  0.0087],\n",
      "        [ 0.0031,  0.0002, -0.0051,  ...,  0.0102,  0.0108,  0.0021],\n",
      "        [-0.0035, -0.0103, -0.0069,  ..., -0.0115,  0.0297, -0.0160],\n",
      "        ...,\n",
      "        [-0.0008,  0.0449, -0.0061,  ...,  0.0386, -0.0383,  0.0107],\n",
      "        [-0.0023, -0.0004, -0.0181,  ...,  0.0195, -0.0029,  0.0176],\n",
      "        [-0.0143, -0.0065,  0.0269,  ..., -0.0498,  0.0239, -0.0444]],\n",
      "       device='cuda:0'), 'model.layers.6.self_attn.q_proj.adapter.adapter_A': tensor([[ 0.5506,  0.5272,  1.1231,  ..., -0.2370,  0.3975, -2.4586],\n",
      "        [-0.0713,  0.2131, -1.2746,  ..., -0.2094,  0.5068,  0.7830],\n",
      "        [-0.7539, -1.1119, -0.3191,  ..., -0.7284,  0.4851, -0.8838],\n",
      "        ...,\n",
      "        [ 0.2949, -0.2038,  1.3528,  ..., -0.3525,  0.6466,  0.3019],\n",
      "        [-0.7414, -1.0775, -0.3381,  ..., -0.8711,  1.5513, -0.5844],\n",
      "        [ 0.5370, -1.0344,  2.0968,  ...,  0.8455, -0.2304, -1.8512]],\n",
      "       device='cuda:0'), 'model.layers.6.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.6.self_attn.k_proj.pre_layer.weight': tensor([[-0.0198,  0.0227,  0.0168,  ..., -0.0117,  0.0049, -0.0231],\n",
      "        [-0.0369,  0.0068, -0.0254,  ...,  0.0114, -0.0259,  0.0057],\n",
      "        [ 0.0157,  0.0146,  0.0383,  ..., -0.0026,  0.0077, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0255,  0.0986, -0.0708,  ...,  0.0496, -0.0258, -0.0806],\n",
      "        [-0.0605, -0.0222, -0.0188,  ..., -0.0220,  0.0249, -0.0256],\n",
      "        [-0.0051, -0.0405, -0.0952,  ...,  0.0493, -0.0527, -0.0128]],\n",
      "       device='cuda:0'), 'model.layers.6.self_attn.k_proj.adapter.adapter_A': tensor([[-0.8772,  0.0703, -0.2377,  ...,  0.1016, -0.3566,  0.4180],\n",
      "        [ 0.5201, -0.4246,  1.8080,  ..., -0.6724, -0.3443, -0.0623],\n",
      "        [-0.4442, -0.2790,  0.7704,  ...,  0.4849, -1.4235, -0.8252],\n",
      "        ...,\n",
      "        [ 0.2060,  1.4585, -0.6013,  ...,  1.5630,  0.8569,  1.8456],\n",
      "        [-0.4051, -0.1594,  1.3496,  ..., -0.0916, -1.3856,  0.3189],\n",
      "        [-0.2616,  0.1116,  0.6056,  ..., -2.1088, -1.9748, -2.0982]],\n",
      "       device='cuda:0'), 'model.layers.6.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.6.self_attn.v_proj.pre_layer.weight': tensor([[ 0.0056,  0.0071, -0.0024,  ...,  0.0111,  0.0023, -0.0183],\n",
      "        [ 0.0164,  0.0265,  0.0072,  ...,  0.0081,  0.0005,  0.0085],\n",
      "        [ 0.0022, -0.0056, -0.0005,  ...,  0.0107, -0.0072, -0.0079],\n",
      "        ...,\n",
      "        [-0.0119, -0.0238,  0.0062,  ..., -0.0078, -0.0116,  0.0051],\n",
      "        [ 0.0050,  0.0177,  0.0027,  ...,  0.0014, -0.0052, -0.0033],\n",
      "        [ 0.0146, -0.0104,  0.0024,  ..., -0.0027, -0.0020,  0.0118]],\n",
      "       device='cuda:0'), 'model.layers.6.self_attn.v_proj.adapter.adapter_A': tensor([[-2.8652e-01,  1.9873e-01,  3.3108e-01,  ...,  4.1093e-04,\n",
      "          5.3593e-01, -1.3706e+00],\n",
      "        [-2.6014e-01,  8.0419e-01,  1.6726e+00,  ...,  1.6479e+00,\n",
      "         -3.6471e-01,  2.0772e+00],\n",
      "        [ 4.7446e-01,  1.8684e-01, -2.1389e+00,  ..., -6.2097e-01,\n",
      "         -1.3829e+00,  4.4030e-02],\n",
      "        ...,\n",
      "        [ 4.0499e-01, -1.0205e+00,  8.1419e-01,  ..., -4.1666e-01,\n",
      "         -8.4116e-01,  4.6482e-01],\n",
      "        [ 3.4272e-01, -2.1452e-01, -2.4789e-01,  ...,  1.4224e+00,\n",
      "         -3.0120e-01,  3.3582e-01],\n",
      "        [-2.0823e+00, -1.3877e-01,  6.2850e-01,  ..., -6.0108e-02,\n",
      "          1.1784e+00, -3.4270e-01]], device='cuda:0'), 'model.layers.6.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.6.self_attn.o_proj.pre_layer.weight': tensor([[-0.0151,  0.0216,  0.0103,  ..., -0.0024,  0.0152, -0.0089],\n",
      "        [-0.0071,  0.0085, -0.0032,  ...,  0.0044,  0.0013, -0.0229],\n",
      "        [-0.0002, -0.0030, -0.0031,  ...,  0.0056,  0.0038,  0.0017],\n",
      "        ...,\n",
      "        [-0.0026,  0.0104,  0.0150,  ...,  0.0011,  0.0023,  0.0001],\n",
      "        [ 0.0061,  0.0019, -0.0160,  ...,  0.0078, -0.0141,  0.0159],\n",
      "        [ 0.0204,  0.0053, -0.0025,  ...,  0.0048, -0.0159, -0.0079]],\n",
      "       device='cuda:0'), 'model.layers.6.self_attn.o_proj.adapter.adapter_A': tensor([[-0.5265,  0.8621,  0.2400,  ..., -1.5969, -0.6159, -0.0680],\n",
      "        [-0.8317,  0.5112,  1.1777,  ..., -0.4323, -0.2039, -1.4003],\n",
      "        [-1.7411,  0.5715, -1.9096,  ..., -1.0658,  0.4315, -0.4092],\n",
      "        ...,\n",
      "        [ 0.6232,  0.3678,  0.6941,  ..., -0.4381, -0.6035,  1.1694],\n",
      "        [ 0.6165,  0.2591,  0.9031,  ..., -0.5312,  1.0238, -0.9543],\n",
      "        [ 0.2035, -0.3868,  0.8885,  ..., -1.1870, -1.7526, -0.8471]],\n",
      "       device='cuda:0'), 'model.layers.6.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.6.mlp.gate_proj.weight': tensor([[ 0.0029,  0.0160,  0.0029,  ...,  0.0049,  0.0021,  0.0015],\n",
      "        [-0.0021,  0.0032, -0.0047,  ...,  0.0107, -0.0042,  0.0036],\n",
      "        [-0.0076,  0.0011,  0.0162,  ..., -0.0011, -0.0031, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0058,  0.0080,  0.0070,  ..., -0.0146, -0.0137,  0.0278],\n",
      "        [-0.0019, -0.0200,  0.0288,  ...,  0.0010, -0.0115, -0.0498],\n",
      "        [ 0.0200, -0.0270,  0.0117,  ..., -0.0181, -0.0115,  0.0173]],\n",
      "       device='cuda:0'), 'model.layers.6.mlp.up_proj.pre_layer.weight': tensor([[ 0.0087, -0.0214, -0.0004,  ..., -0.0009, -0.0249, -0.0073],\n",
      "        [-0.0270, -0.0002, -0.0042,  ...,  0.0014,  0.0114,  0.0193],\n",
      "        [ 0.0060,  0.0014, -0.0020,  ...,  0.0025,  0.0055,  0.0060],\n",
      "        ...,\n",
      "        [-0.0299, -0.0009, -0.0132,  ...,  0.0103, -0.0056, -0.0030],\n",
      "        [ 0.0130,  0.0287,  0.0095,  ..., -0.0162, -0.0291,  0.0107],\n",
      "        [-0.0154,  0.0110,  0.0089,  ...,  0.0006, -0.0089, -0.0159]],\n",
      "       device='cuda:0'), 'model.layers.6.mlp.up_proj.adapter.adapter_A': tensor([[ 1.2408,  1.3156,  1.0253,  ..., -1.0485,  0.4889, -0.4827],\n",
      "        [-2.1012, -0.2969, -1.6793,  ..., -2.1624,  1.7840,  1.8085],\n",
      "        [ 1.0608, -0.9014, -1.8736,  ...,  0.4780,  0.5175, -0.4298],\n",
      "        ...,\n",
      "        [ 1.4158,  0.4431, -0.8651,  ..., -0.6642,  0.4895, -0.5058],\n",
      "        [-1.0285,  0.5051, -0.2170,  ..., -1.0564,  0.1535, -0.6228],\n",
      "        [-0.1315,  0.4829,  0.1491,  ...,  0.5910, -0.6524,  0.5351]],\n",
      "       device='cuda:0'), 'model.layers.6.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.6.mlp.down_proj.pre_layer.weight': tensor([[-3.6621e-04,  7.8964e-04,  1.4038e-02,  ..., -1.4893e-02,\n",
      "          2.2949e-02, -1.3306e-02],\n",
      "        [-1.6113e-02, -1.8677e-02,  7.2956e-05,  ..., -2.5146e-02,\n",
      "          3.7384e-04,  8.1787e-03],\n",
      "        [ 2.2736e-03,  1.4099e-02, -7.0190e-04,  ...,  9.0332e-03,\n",
      "          9.9182e-04, -4.6997e-03],\n",
      "        ...,\n",
      "        [ 2.1362e-03,  2.0142e-03,  6.9275e-03,  ..., -4.3945e-03,\n",
      "         -3.7994e-03, -1.3184e-02],\n",
      "        [-3.4943e-03, -6.5308e-03,  2.4872e-03,  ..., -9.0332e-03,\n",
      "         -2.3804e-02, -1.1841e-02],\n",
      "        [-9.8877e-03,  1.2939e-02, -1.2512e-02,  ...,  4.8523e-03,\n",
      "          3.9101e-04, -1.4709e-02]], device='cuda:0'), 'model.layers.6.mlp.down_proj.adapter.adapter_A': tensor([[ 1.2302,  1.0395, -1.7091,  ...,  0.5656, -1.6744,  0.2955],\n",
      "        [ 0.9220, -0.8512, -0.4862,  ...,  0.4626,  1.6144,  0.0629],\n",
      "        [-0.3191,  0.0967, -1.0863,  ...,  0.0335, -1.9292, -0.4988],\n",
      "        ...,\n",
      "        [-0.9669, -0.4308, -0.7326,  ..., -1.2055,  0.6598,  0.7049],\n",
      "        [-0.4667, -1.9821,  0.2332,  ...,  0.6804,  0.5317, -0.6028],\n",
      "        [ 0.3444, -2.1858, -0.5112,  ..., -0.1960, -0.6859,  1.6094]],\n",
      "       device='cuda:0'), 'model.layers.6.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.6.input_layernorm.weight': tensor([0.4590, 0.5117, 0.3340,  ..., 0.4980, 0.4355, 0.4238], device='cuda:0'), 'model.layers.6.post_attention_layernorm.weight': tensor([0.3438, 0.3457, 0.1963,  ..., 0.3340, 0.3066, 0.3438], device='cuda:0'), 'model.layers.7.self_attn.q_proj.pre_layer.weight': tensor([[-0.0070,  0.0004, -0.0189,  ...,  0.0238, -0.0160, -0.0160],\n",
      "        [ 0.0303, -0.0209, -0.0085,  ..., -0.0089,  0.0371,  0.0209],\n",
      "        [-0.0128, -0.0117,  0.0009,  ..., -0.0092, -0.0118, -0.0278],\n",
      "        ...,\n",
      "        [-0.0084, -0.0200,  0.0212,  ..., -0.0093,  0.0030, -0.0177],\n",
      "        [-0.0131,  0.0160, -0.0212,  ...,  0.0152,  0.0025,  0.0164],\n",
      "        [ 0.0022, -0.0046, -0.0159,  ..., -0.0015, -0.0010, -0.0010]],\n",
      "       device='cuda:0'), 'model.layers.7.self_attn.q_proj.adapter.adapter_A': tensor([[ 1.2462,  1.7852,  1.7603,  ...,  1.2590,  0.1068, -1.0588],\n",
      "        [-0.8355, -0.2881, -0.8358,  ...,  1.1785,  0.2907, -1.9933],\n",
      "        [ 0.8826, -1.4051,  0.2738,  ..., -0.9411, -0.6910,  1.8087],\n",
      "        ...,\n",
      "        [-0.9971, -0.3485, -0.2559,  ...,  0.5320,  0.3670,  0.3603],\n",
      "        [ 0.4237, -1.4279,  0.2535,  ...,  0.4460, -0.3783, -0.0648],\n",
      "        [ 0.5232,  1.0634, -1.4418,  ..., -1.5249,  0.5155, -1.0998]],\n",
      "       device='cuda:0'), 'model.layers.7.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.7.self_attn.k_proj.pre_layer.weight': tensor([[ 1.3428e-02, -7.6294e-03, -2.1118e-02,  ...,  1.1292e-02,\n",
      "          1.7578e-02,  7.1411e-03],\n",
      "        [ 5.4626e-03,  6.8359e-03,  3.4180e-02,  ..., -2.7710e-02,\n",
      "          2.5269e-02,  1.2756e-02],\n",
      "        [-2.2217e-02,  1.3245e-02,  1.3428e-02,  ..., -2.5635e-02,\n",
      "          6.9336e-02,  4.3945e-02],\n",
      "        ...,\n",
      "        [-6.3477e-02, -2.6367e-02, -2.8931e-02,  ..., -3.4912e-02,\n",
      "          6.4941e-02,  8.8867e-02],\n",
      "        [ 5.1880e-03,  2.2531e-05,  1.6113e-02,  ...,  3.2959e-02,\n",
      "          1.7578e-02, -9.1309e-02],\n",
      "        [ 1.4038e-02,  3.6133e-02, -3.2959e-02,  ..., -5.1758e-02,\n",
      "         -7.0801e-03,  2.2736e-03]], device='cuda:0'), 'model.layers.7.self_attn.k_proj.adapter.adapter_A': tensor([[-1.3064, -0.6943,  0.3005,  ..., -0.7649,  0.6918,  0.4628],\n",
      "        [-2.1784,  1.7389,  1.0325,  ...,  1.4396,  0.2978,  0.9298],\n",
      "        [-0.1446,  0.9365, -2.5572,  ...,  0.4289,  1.1003,  1.0711],\n",
      "        ...,\n",
      "        [ 1.2786, -0.8138, -1.4130,  ..., -0.0710,  1.9531,  2.0694],\n",
      "        [-0.0952, -0.3083, -0.2697,  ...,  1.1930, -1.0115, -0.2771],\n",
      "        [-0.2182, -0.7340,  0.1770,  ..., -0.4893, -0.3402,  1.7687]],\n",
      "       device='cuda:0'), 'model.layers.7.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.7.self_attn.v_proj.pre_layer.weight': tensor([[-0.0138,  0.0123,  0.0125,  ...,  0.0063, -0.0156, -0.0002],\n",
      "        [ 0.0120, -0.0125,  0.0133,  ..., -0.0030,  0.0038,  0.0069],\n",
      "        [-0.0259, -0.0056,  0.0026,  ...,  0.0203, -0.0003,  0.0168],\n",
      "        ...,\n",
      "        [-0.0081, -0.0009, -0.0199,  ..., -0.0107, -0.0271,  0.0082],\n",
      "        [ 0.0287,  0.0156,  0.0005,  ..., -0.0178,  0.0138, -0.0157],\n",
      "        [ 0.0096,  0.0106, -0.0101,  ...,  0.0179, -0.0040,  0.0057]],\n",
      "       device='cuda:0'), 'model.layers.7.self_attn.v_proj.adapter.adapter_A': tensor([[ 1.6290,  1.8701, -0.5420,  ...,  1.1667,  0.9266,  1.2906],\n",
      "        [-1.3139, -0.1194,  1.0525,  ..., -1.3310,  0.0781, -1.2185],\n",
      "        [-0.0900,  0.0762, -0.2875,  ...,  2.3192,  1.1612, -1.1024],\n",
      "        ...,\n",
      "        [-1.8022,  1.0426,  1.2121,  ...,  1.1004,  0.4529, -0.6890],\n",
      "        [-0.8396, -0.2356,  0.3235,  ..., -0.5981, -0.6684,  0.3162],\n",
      "        [-1.3116, -1.6244,  1.1875,  ..., -0.1695,  1.8406,  0.3664]],\n",
      "       device='cuda:0'), 'model.layers.7.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.7.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0006, -0.0129, -0.0070,  ...,  0.0059,  0.0166,  0.0111],\n",
      "        [ 0.0129, -0.0161,  0.0020,  ...,  0.0125, -0.0072,  0.0103],\n",
      "        [ 0.0036,  0.0004, -0.0020,  ..., -0.0044,  0.0075,  0.0041],\n",
      "        ...,\n",
      "        [ 0.0090, -0.0369,  0.0240,  ...,  0.0075, -0.0143,  0.0074],\n",
      "        [ 0.0056,  0.0013,  0.0259,  ...,  0.0082, -0.0016, -0.0007],\n",
      "        [-0.0103, -0.0011,  0.0129,  ...,  0.0026, -0.0087,  0.0010]],\n",
      "       device='cuda:0'), 'model.layers.7.self_attn.o_proj.adapter.adapter_A': tensor([[ 0.4475,  0.0208,  0.1772,  ...,  0.3332, -0.5457,  0.3062],\n",
      "        [-0.2064, -1.6572,  2.3634,  ...,  0.5574, -0.7217,  1.0604],\n",
      "        [-0.0942,  1.2421,  2.2834,  ...,  0.5337,  1.2343, -1.2613],\n",
      "        ...,\n",
      "        [-0.9805,  0.8108, -1.3005,  ...,  1.3857,  1.6722,  0.3653],\n",
      "        [-1.0524,  0.4434,  0.0071,  ...,  0.3119, -0.8508,  0.8443],\n",
      "        [ 0.7230,  1.3809, -0.3351,  ..., -1.1555,  1.5825, -0.0267]],\n",
      "       device='cuda:0'), 'model.layers.7.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.7.mlp.gate_proj.weight': tensor([[ 0.0378,  0.0125, -0.0008,  ..., -0.0067, -0.0278, -0.0010],\n",
      "        [ 0.0063,  0.0011, -0.0008,  ..., -0.0242,  0.0094,  0.0154],\n",
      "        [ 0.0378, -0.0298,  0.0322,  ...,  0.0118,  0.0042, -0.0165],\n",
      "        ...,\n",
      "        [-0.0275, -0.0015,  0.0095,  ...,  0.0195, -0.0232,  0.0273],\n",
      "        [ 0.0262,  0.0102, -0.0092,  ..., -0.0176, -0.0026, -0.0031],\n",
      "        [ 0.0096, -0.0070, -0.0059,  ...,  0.0104,  0.0311, -0.0040]],\n",
      "       device='cuda:0'), 'model.layers.7.mlp.up_proj.pre_layer.weight': tensor([[ 0.0081,  0.0113,  0.0032,  ..., -0.0028, -0.0203, -0.0068],\n",
      "        [-0.0322,  0.0067, -0.0092,  ..., -0.0261,  0.0133, -0.0084],\n",
      "        [ 0.0064, -0.0093,  0.0251,  ..., -0.0170,  0.0016, -0.0101],\n",
      "        ...,\n",
      "        [-0.0009,  0.0078, -0.0205,  ...,  0.0049,  0.0044, -0.0278],\n",
      "        [-0.0238,  0.0025, -0.0063,  ..., -0.0222, -0.0184,  0.0164],\n",
      "        [-0.0148, -0.0017,  0.0020,  ...,  0.0097,  0.0085, -0.0327]],\n",
      "       device='cuda:0'), 'model.layers.7.mlp.up_proj.adapter.adapter_A': tensor([[-0.2090,  1.0126,  0.1805,  ..., -0.5740,  0.9048,  1.3710],\n",
      "        [ 0.3426, -0.4165, -0.7009,  ..., -1.2602, -0.8458, -2.6742],\n",
      "        [ 0.7871, -0.3971,  0.4457,  ..., -0.3975, -0.3407,  0.0999],\n",
      "        ...,\n",
      "        [ 0.2137,  0.9495, -0.0629,  ...,  0.9262,  0.7842,  1.9817],\n",
      "        [ 0.0197, -0.3018, -0.7486,  ...,  0.4970, -0.2563, -0.6644],\n",
      "        [ 0.2492,  0.0489, -0.6978,  ..., -0.1479,  1.2144,  0.8270]],\n",
      "       device='cuda:0'), 'model.layers.7.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.7.mlp.down_proj.pre_layer.weight': tensor([[-0.0098, -0.0154,  0.0025,  ...,  0.0109,  0.0047, -0.0038],\n",
      "        [-0.0044, -0.0042, -0.0114,  ...,  0.0022,  0.0126, -0.0130],\n",
      "        [ 0.0110, -0.0072,  0.0021,  ...,  0.0057, -0.0089,  0.0057],\n",
      "        ...,\n",
      "        [-0.0145, -0.0032, -0.0165,  ...,  0.0080, -0.0322,  0.0145],\n",
      "        [-0.0167, -0.0139,  0.0087,  ...,  0.0117,  0.0006,  0.0129],\n",
      "        [-0.0131, -0.0131,  0.0120,  ...,  0.0244,  0.0226, -0.0304]],\n",
      "       device='cuda:0'), 'model.layers.7.mlp.down_proj.adapter.adapter_A': tensor([[-1.3624,  0.1910,  0.0993,  ...,  1.5591, -1.2028, -1.2410],\n",
      "        [ 0.1097,  2.3788, -0.0673,  ..., -0.1631, -1.1524,  1.2774],\n",
      "        [ 1.2036, -0.1108,  1.2050,  ...,  0.1444,  2.1963, -1.1025],\n",
      "        ...,\n",
      "        [-1.8778, -0.2123, -0.3034,  ...,  2.4651, -1.4458,  1.8125],\n",
      "        [ 0.0887,  1.5181,  0.2239,  ...,  1.8614,  0.5644,  0.3503],\n",
      "        [ 1.2559, -0.2948,  1.9235,  ..., -0.4282,  1.9124,  2.0564]],\n",
      "       device='cuda:0'), 'model.layers.7.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.7.input_layernorm.weight': tensor([0.4707, 0.5312, 0.2148,  ..., 0.4785, 0.4473, 0.4434], device='cuda:0'), 'model.layers.7.post_attention_layernorm.weight': tensor([0.3516, 0.3340, 0.2236,  ..., 0.3379, 0.3145, 0.3418], device='cuda:0'), 'model.layers.8.self_attn.q_proj.pre_layer.weight': tensor([[ 0.0020,  0.0153, -0.0022,  ..., -0.0132, -0.0221, -0.0294],\n",
      "        [ 0.0058,  0.0016, -0.0120,  ...,  0.0012, -0.0354, -0.0503],\n",
      "        [-0.0125, -0.0176,  0.0122,  ..., -0.0008,  0.0308,  0.0210],\n",
      "        ...,\n",
      "        [-0.0077, -0.0576, -0.0052,  ..., -0.0017, -0.0742, -0.0510],\n",
      "        [ 0.0013,  0.0075,  0.0061,  ...,  0.0017,  0.0205, -0.0295],\n",
      "        [ 0.0081, -0.0256, -0.0214,  ...,  0.0537, -0.0266, -0.0270]],\n",
      "       device='cuda:0'), 'model.layers.8.self_attn.q_proj.adapter.adapter_A': tensor([[-3.0004,  0.6868,  0.7785,  ...,  1.2188, -0.9708, -2.1570],\n",
      "        [ 0.2766, -0.5034,  0.2109,  ..., -0.1922,  0.8693,  1.3517],\n",
      "        [ 0.3713,  1.2088, -1.0728,  ...,  1.4901, -1.1726,  1.3965],\n",
      "        ...,\n",
      "        [ 1.3734,  0.7892,  0.3618,  ...,  1.2349, -1.2066,  0.9489],\n",
      "        [-1.7466, -0.2971,  0.6851,  ..., -0.4505, -0.1609,  0.7826],\n",
      "        [-0.3501, -1.0143,  1.0507,  ...,  0.6388, -0.5851,  1.5751]],\n",
      "       device='cuda:0'), 'model.layers.8.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.8.self_attn.k_proj.pre_layer.weight': tensor([[-0.0082, -0.0106, -0.0140,  ...,  0.0294,  0.0068,  0.0165],\n",
      "        [-0.0060,  0.0035, -0.0305,  ..., -0.0052,  0.0171,  0.0239],\n",
      "        [-0.0047,  0.0052, -0.0173,  ...,  0.0168,  0.0305, -0.0205],\n",
      "        ...,\n",
      "        [-0.0605,  0.0791, -0.0322,  ...,  0.0228,  0.0223,  0.0047],\n",
      "        [-0.0522, -0.0510, -0.0068,  ...,  0.0233,  0.0299,  0.0593],\n",
      "        [ 0.0281, -0.0398,  0.0187,  ..., -0.0029,  0.0127,  0.0165]],\n",
      "       device='cuda:0'), 'model.layers.8.self_attn.k_proj.adapter.adapter_A': tensor([[ 1.2807, -0.3865,  1.0964,  ..., -0.1429, -0.2639, -0.9335],\n",
      "        [-0.5062,  0.0720, -0.4783,  ...,  0.6766,  0.3803, -1.1164],\n",
      "        [-1.1538,  0.4936, -0.1474,  ..., -0.2068,  0.4995, -0.2245],\n",
      "        ...,\n",
      "        [ 0.1677,  0.5278, -0.6930,  ...,  0.0062, -1.3283,  0.4940],\n",
      "        [-0.2847, -0.9581, -0.9160,  ...,  1.2157,  1.3638, -1.2442],\n",
      "        [ 0.3444, -0.6735, -1.0433,  ..., -0.2856,  1.0156, -0.2470]],\n",
      "       device='cuda:0'), 'model.layers.8.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.8.self_attn.v_proj.pre_layer.weight': tensor([[ 0.0256,  0.0150,  0.0029,  ..., -0.0203,  0.0029, -0.0245],\n",
      "        [ 0.0189, -0.0293, -0.0098,  ..., -0.0054, -0.0067,  0.0013],\n",
      "        [ 0.0012, -0.0066,  0.0003,  ...,  0.0164,  0.0132,  0.0003],\n",
      "        ...,\n",
      "        [ 0.0078,  0.0056,  0.0082,  ...,  0.0095, -0.0060, -0.0065],\n",
      "        [ 0.0339,  0.0160, -0.0083,  ..., -0.0239, -0.0120, -0.0066],\n",
      "        [ 0.0096,  0.0124,  0.0070,  ...,  0.0052, -0.0014, -0.0188]],\n",
      "       device='cuda:0'), 'model.layers.8.self_attn.v_proj.adapter.adapter_A': tensor([[-0.7639,  0.8097, -0.0172,  ..., -0.1257,  0.5920, -1.2685],\n",
      "        [ 1.5821, -0.5032,  1.2160,  ...,  0.9224,  0.3271, -4.1453],\n",
      "        [ 0.2492, -2.2057, -1.2439,  ...,  0.0673,  0.3573,  0.2404],\n",
      "        ...,\n",
      "        [ 1.3665,  1.0176,  1.0415,  ..., -1.1609, -0.6828, -1.5017],\n",
      "        [-0.3090,  0.8962,  0.6306,  ..., -0.9232,  1.5474,  1.6789],\n",
      "        [ 0.4232,  0.4731, -0.0383,  ..., -0.3233, -1.5885, -0.2109]],\n",
      "       device='cuda:0'), 'model.layers.8.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.8.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0166,  0.0113,  0.0045,  ..., -0.0072,  0.0010,  0.0111],\n",
      "        [ 0.0303, -0.0208,  0.0293,  ...,  0.0070, -0.0123, -0.0005],\n",
      "        [ 0.0011,  0.0060,  0.0087,  ..., -0.0021,  0.0011,  0.0066],\n",
      "        ...,\n",
      "        [-0.0278, -0.0118,  0.0267,  ...,  0.0128, -0.0232, -0.0069],\n",
      "        [-0.0171,  0.0193,  0.0041,  ..., -0.0258,  0.0036, -0.0045],\n",
      "        [ 0.0278,  0.0056, -0.0258,  ..., -0.0031,  0.0026,  0.0140]],\n",
      "       device='cuda:0'), 'model.layers.8.self_attn.o_proj.adapter.adapter_A': tensor([[-1.1342,  1.2250, -1.1344,  ...,  1.8019,  0.7111,  0.6129],\n",
      "        [ 2.1379, -0.3627,  0.5554,  ..., -1.2502, -0.2400, -0.1242],\n",
      "        [ 0.7115,  0.3851, -0.5775,  ...,  0.4774,  1.4750, -1.3651],\n",
      "        ...,\n",
      "        [ 0.4628, -1.8707, -1.6280,  ..., -0.1964, -0.1563, -0.3857],\n",
      "        [ 1.3940, -0.7366,  1.0894,  ..., -0.1933, -1.7290,  0.8471],\n",
      "        [-1.3237, -0.3733, -0.7071,  ...,  1.3655,  0.7090, -0.1874]],\n",
      "       device='cuda:0'), 'model.layers.8.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.8.mlp.gate_proj.weight': tensor([[ 0.0071, -0.0028,  0.0303,  ..., -0.0106,  0.0059, -0.0168],\n",
      "        [ 0.0125, -0.0393,  0.0005,  ..., -0.0221, -0.0096, -0.0178],\n",
      "        [ 0.0094, -0.0056,  0.0091,  ...,  0.0376,  0.0083, -0.0013],\n",
      "        ...,\n",
      "        [-0.0024,  0.0072,  0.0171,  ...,  0.0381, -0.0131,  0.0019],\n",
      "        [-0.0366, -0.0206,  0.0011,  ..., -0.0102,  0.0508, -0.0050],\n",
      "        [-0.0069, -0.0320,  0.0077,  ...,  0.0164, -0.0198,  0.0050]],\n",
      "       device='cuda:0'), 'model.layers.8.mlp.up_proj.pre_layer.weight': tensor([[-0.0225,  0.0164,  0.0193,  ..., -0.0220,  0.0192,  0.0444],\n",
      "        [ 0.0184,  0.0166, -0.0045,  ..., -0.0059,  0.0020,  0.0126],\n",
      "        [-0.0050,  0.0454, -0.0006,  ...,  0.0004, -0.0115,  0.0036],\n",
      "        ...,\n",
      "        [ 0.0153, -0.0021, -0.0005,  ..., -0.0256,  0.0216, -0.0178],\n",
      "        [ 0.0041, -0.0247,  0.0007,  ..., -0.0259,  0.0026, -0.0079],\n",
      "        [-0.0260, -0.0145, -0.0035,  ..., -0.0266,  0.0072, -0.0102]],\n",
      "       device='cuda:0'), 'model.layers.8.mlp.up_proj.adapter.adapter_A': tensor([[-2.3999,  0.4316,  2.5093,  ..., -0.8487, -0.0192,  0.3753],\n",
      "        [-1.9094, -1.1703,  0.3982,  ..., -0.1031, -1.6904,  0.3021],\n",
      "        [-0.9101, -0.6085, -1.1701,  ..., -0.0652,  0.6642,  0.7857],\n",
      "        ...,\n",
      "        [-2.4673,  1.3906, -0.3500,  ..., -1.2605, -1.0282, -0.0852],\n",
      "        [ 1.0922, -0.5697, -0.0437,  ...,  0.1446, -0.8485,  0.5636],\n",
      "        [-1.0856,  0.0311,  1.7756,  ..., -1.1307, -0.3562,  0.3022]],\n",
      "       device='cuda:0'), 'model.layers.8.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.8.mlp.down_proj.pre_layer.weight': tensor([[-0.0055,  0.0021, -0.0072,  ...,  0.0189, -0.0079, -0.0393],\n",
      "        [-0.0018,  0.0104,  0.0261,  ...,  0.0008, -0.0147, -0.0195],\n",
      "        [ 0.0099, -0.0021,  0.0041,  ...,  0.0002, -0.0045, -0.0059],\n",
      "        ...,\n",
      "        [-0.0255, -0.0152,  0.0171,  ..., -0.0330, -0.0085, -0.0155],\n",
      "        [ 0.0161, -0.0095,  0.0150,  ..., -0.0034, -0.0209,  0.0435],\n",
      "        [ 0.0214, -0.0131,  0.0280,  ..., -0.0231, -0.0131,  0.0359]],\n",
      "       device='cuda:0'), 'model.layers.8.mlp.down_proj.adapter.adapter_A': tensor([[ 0.4010, -0.9611,  1.3531,  ...,  0.3883,  0.4072, -1.8444],\n",
      "        [ 1.4031, -0.7778, -0.2624,  ...,  0.4044,  1.2269, -1.1630],\n",
      "        [-0.3120, -0.0547,  1.1560,  ...,  0.3710,  0.5424, -0.8338],\n",
      "        ...,\n",
      "        [ 0.6117,  1.1747,  1.4978,  ...,  0.2512, -0.4391,  0.4304],\n",
      "        [-0.5905, -1.5230,  1.3398,  ...,  0.5095, -0.0246, -1.6242],\n",
      "        [-1.1638, -0.6097, -0.2192,  ...,  1.1148,  0.3647,  1.0144]],\n",
      "       device='cuda:0'), 'model.layers.8.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.8.input_layernorm.weight': tensor([0.5000, 0.5508, 0.3047,  ..., 0.5195, 0.4922, 0.4727], device='cuda:0'), 'model.layers.8.post_attention_layernorm.weight': tensor([0.3535, 0.3574, 0.3320,  ..., 0.3535, 0.3359, 0.3555], device='cuda:0'), 'model.layers.9.self_attn.q_proj.pre_layer.weight': tensor([[-0.0075, -0.0156, -0.0019,  ...,  0.0041,  0.0217,  0.0139],\n",
      "        [-0.0325, -0.0243, -0.0010,  ..., -0.0188,  0.0242,  0.0332],\n",
      "        [-0.0039,  0.0305, -0.0060,  ...,  0.0124, -0.0312, -0.0240],\n",
      "        ...,\n",
      "        [ 0.0315, -0.0356,  0.0139,  ..., -0.0111,  0.0107, -0.0231],\n",
      "        [ 0.0398, -0.0664,  0.0106,  ..., -0.0227,  0.0198,  0.0356],\n",
      "        [-0.0269,  0.0317, -0.0327,  ..., -0.0115,  0.0157, -0.0151]],\n",
      "       device='cuda:0'), 'model.layers.9.self_attn.q_proj.adapter.adapter_A': tensor([[-0.2221,  0.3481, -0.6217,  ..., -0.6084,  1.3630,  1.1191],\n",
      "        [ 1.8429, -0.6823, -1.7290,  ..., -0.4774, -1.0343, -0.1363],\n",
      "        [-0.0412, -0.3050,  1.6092,  ..., -0.4984,  1.9683,  0.8960],\n",
      "        ...,\n",
      "        [-0.4439, -1.1463,  2.5175,  ..., -0.4301, -0.0604,  0.1369],\n",
      "        [-1.1044, -2.4221, -0.1397,  ..., -0.3627,  0.4089, -0.6630],\n",
      "        [ 0.2983,  1.3676,  0.2706,  ..., -0.2241, -0.1163, -0.4600]],\n",
      "       device='cuda:0'), 'model.layers.9.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.9.self_attn.k_proj.pre_layer.weight': tensor([[-0.0435, -0.0391, -0.0025,  ...,  0.0134, -0.0219, -0.0096],\n",
      "        [ 0.0007,  0.0425,  0.0273,  ..., -0.0135,  0.0172,  0.0017],\n",
      "        [-0.0304,  0.0119,  0.0117,  ...,  0.0047, -0.0231, -0.0220],\n",
      "        ...,\n",
      "        [-0.0295,  0.0212,  0.0520,  ..., -0.0020,  0.0030,  0.0139],\n",
      "        [ 0.0033,  0.0214,  0.0272,  ...,  0.0153,  0.0059, -0.0127],\n",
      "        [-0.0391,  0.0332, -0.0454,  ..., -0.0299,  0.0466, -0.0164]],\n",
      "       device='cuda:0'), 'model.layers.9.self_attn.k_proj.adapter.adapter_A': tensor([[-2.3087e-01, -9.7997e-02, -4.1731e-01,  ...,  8.7272e-01,\n",
      "          7.2419e-01, -5.8025e-01],\n",
      "        [-9.5309e-01,  1.2045e+00,  4.1945e-01,  ..., -1.2135e+00,\n",
      "         -1.6015e+00,  4.3041e-01],\n",
      "        [-6.5262e-01,  1.8899e-01,  1.3409e+00,  ...,  4.6091e-01,\n",
      "          2.2725e-01, -8.8517e-02],\n",
      "        ...,\n",
      "        [ 3.0579e-01,  4.9514e-02,  1.7186e+00,  ...,  6.5614e-01,\n",
      "         -5.5413e-02, -1.3246e+00],\n",
      "        [-6.5689e-01,  1.2518e+00,  9.4556e-01,  ...,  8.6834e-01,\n",
      "          6.9340e-01, -6.7171e-01],\n",
      "        [ 6.8054e-01,  9.1883e-01, -2.2185e+00,  ...,  9.9419e-02,\n",
      "         -3.2797e-01, -1.0867e-03]], device='cuda:0'), 'model.layers.9.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.9.self_attn.v_proj.pre_layer.weight': tensor([[ 0.0183, -0.0124,  0.0127,  ..., -0.0071, -0.0214, -0.0096],\n",
      "        [-0.0109,  0.0020,  0.0058,  ...,  0.0125,  0.0019,  0.0038],\n",
      "        [ 0.0108,  0.0194,  0.0366,  ..., -0.0026,  0.0062,  0.0031],\n",
      "        ...,\n",
      "        [-0.0189, -0.0157,  0.0137,  ...,  0.0142,  0.0081, -0.0018],\n",
      "        [ 0.0072, -0.0251, -0.0003,  ...,  0.0283, -0.0058,  0.0006],\n",
      "        [-0.0110, -0.0120, -0.0068,  ...,  0.0146,  0.0051,  0.0039]],\n",
      "       device='cuda:0'), 'model.layers.9.self_attn.v_proj.adapter.adapter_A': tensor([[ 0.5915,  0.1162,  0.8150,  ...,  0.8324,  0.2606,  1.0949],\n",
      "        [-0.7209,  0.6067,  0.5282,  ...,  1.6013, -0.2890, -2.3136],\n",
      "        [-0.8057,  0.1702,  0.4604,  ...,  1.1079,  0.9996, -1.8929],\n",
      "        ...,\n",
      "        [-0.2757, -0.5823, -0.4673,  ...,  2.8948,  1.0066, -1.5561],\n",
      "        [-1.5281,  0.3370, -0.3710,  ...,  0.2527, -1.4564, -0.2775],\n",
      "        [ 1.8413, -0.0948, -0.7819,  ..., -0.4873,  1.3450, -0.7949]],\n",
      "       device='cuda:0'), 'model.layers.9.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.9.self_attn.o_proj.pre_layer.weight': tensor([[ 1.3306e-02,  2.0294e-03,  3.0884e-02,  ..., -6.6528e-03,\n",
      "          2.7100e-02, -1.3199e-03],\n",
      "        [ 7.6904e-03,  9.2506e-05,  1.5198e-02,  ..., -2.0599e-03,\n",
      "          8.1787e-03, -2.1851e-02],\n",
      "        [ 3.6774e-03,  6.5002e-03,  1.0376e-02,  ..., -1.2024e-02,\n",
      "         -2.4109e-03,  1.7242e-03],\n",
      "        ...,\n",
      "        [-1.0620e-02,  1.9287e-02, -1.6235e-02,  ..., -2.8442e-02,\n",
      "          8.7280e-03, -1.4404e-02],\n",
      "        [-1.3367e-02,  9.8877e-03,  1.2817e-03,  ..., -5.7373e-03,\n",
      "         -7.3547e-03, -8.4839e-03],\n",
      "        [-1.2695e-02, -2.6398e-03,  2.0905e-03,  ..., -6.0730e-03,\n",
      "          8.6060e-03, -1.7944e-02]], device='cuda:0'), 'model.layers.9.self_attn.o_proj.adapter.adapter_A': tensor([[-0.8564, -1.7498,  0.3987,  ...,  0.8684,  0.3101, -0.5388],\n",
      "        [-1.1334,  0.2017,  0.6565,  ...,  1.4331,  0.6332, -0.6220],\n",
      "        [ 0.3583,  1.6646,  2.2036,  ..., -0.2895,  0.9963,  0.0720],\n",
      "        ...,\n",
      "        [-0.5479, -0.4407, -0.4446,  ..., -2.5110,  0.7092,  0.0635],\n",
      "        [ 0.0515, -0.5819, -1.6399,  ...,  2.7696,  0.2718,  0.6486],\n",
      "        [-0.2811,  0.3494, -1.3370,  ...,  1.1808, -0.2715,  1.1378]],\n",
      "       device='cuda:0'), 'model.layers.9.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.9.mlp.gate_proj.weight': tensor([[ 0.0198,  0.0342,  0.0089,  ...,  0.0349,  0.0618,  0.0354],\n",
      "        [ 0.0112,  0.0058, -0.0002,  ..., -0.0049,  0.0015, -0.0070],\n",
      "        [ 0.0043, -0.0017,  0.0096,  ..., -0.0298,  0.0135,  0.0165],\n",
      "        ...,\n",
      "        [-0.0287, -0.0211, -0.0126,  ..., -0.0123, -0.0227,  0.0381],\n",
      "        [ 0.0072, -0.0148, -0.0126,  ...,  0.0247, -0.0474,  0.0155],\n",
      "        [-0.0009,  0.0312, -0.0034,  ..., -0.0165, -0.0104,  0.0327]],\n",
      "       device='cuda:0'), 'model.layers.9.mlp.up_proj.pre_layer.weight': tensor([[-0.0315, -0.0110, -0.0009,  ..., -0.0255, -0.0017, -0.0381],\n",
      "        [-0.0156, -0.0115,  0.0026,  ...,  0.0254, -0.0028,  0.0036],\n",
      "        [-0.0148,  0.0047, -0.0051,  ..., -0.0075, -0.0023, -0.0029],\n",
      "        ...,\n",
      "        [ 0.0020,  0.0012,  0.0138,  ...,  0.0092,  0.0282, -0.0195],\n",
      "        [ 0.0018, -0.0247,  0.0047,  ...,  0.0106,  0.0008,  0.0273],\n",
      "        [ 0.0325,  0.0110, -0.0071,  ..., -0.0017, -0.0140,  0.0040]],\n",
      "       device='cuda:0'), 'model.layers.9.mlp.up_proj.adapter.adapter_A': tensor([[ 0.1013,  1.7040, -0.6813,  ..., -0.2317,  1.1228,  0.0969],\n",
      "        [-0.7582,  0.7215,  0.0557,  ..., -0.8995,  0.3937, -1.4476],\n",
      "        [-2.3435,  0.0169,  0.5023,  ..., -0.4389, -0.8530,  0.5479],\n",
      "        ...,\n",
      "        [-1.3758,  1.4265, -1.1992,  ..., -1.8769, -3.3896, -0.3847],\n",
      "        [-1.0420, -0.5764,  1.1906,  ..., -0.2104,  0.7859, -0.2014],\n",
      "        [ 1.2258,  1.0611,  0.7864,  ...,  2.4590, -1.2934, -0.8283]],\n",
      "       device='cuda:0'), 'model.layers.9.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.9.mlp.down_proj.pre_layer.weight': tensor([[-0.0181, -0.0031, -0.0168,  ...,  0.0020,  0.0051, -0.0162],\n",
      "        [-0.0278,  0.0075, -0.0101,  ..., -0.0208,  0.0135, -0.0227],\n",
      "        [-0.0048,  0.0048, -0.0030,  ...,  0.0060, -0.0044, -0.0042],\n",
      "        ...,\n",
      "        [-0.0308,  0.0067,  0.0097,  ...,  0.0060,  0.0133,  0.0060],\n",
      "        [ 0.0104, -0.0101,  0.0002,  ..., -0.0129, -0.0119, -0.0095],\n",
      "        [-0.0306,  0.0203,  0.0137,  ..., -0.0109, -0.0072, -0.0217]],\n",
      "       device='cuda:0'), 'model.layers.9.mlp.down_proj.adapter.adapter_A': tensor([[ 1.7321, -0.9988, -0.4431,  ...,  1.3679,  0.9569,  0.4734],\n",
      "        [ 1.6191,  0.0369, -2.2526,  ..., -2.0024,  1.5064,  2.7788],\n",
      "        [ 0.2559, -0.0568, -1.2177,  ..., -0.1419, -0.5300,  1.9621],\n",
      "        ...,\n",
      "        [-0.0826,  0.1867,  0.8360,  ..., -0.5128,  0.4657,  2.2428],\n",
      "        [ 0.2076, -0.1281,  1.4108,  ...,  0.3672,  0.6519,  0.4986],\n",
      "        [ 1.0218,  1.6403, -0.8319,  ..., -2.9902,  0.6969, -0.0301]],\n",
      "       device='cuda:0'), 'model.layers.9.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.9.input_layernorm.weight': tensor([0.4844, 0.4746, 0.2656,  ..., 0.4844, 0.4883, 0.4727], device='cuda:0'), 'model.layers.9.post_attention_layernorm.weight': tensor([0.3789, 0.3691, 0.3379,  ..., 0.3730, 0.3496, 0.3789], device='cuda:0'), 'model.layers.10.self_attn.q_proj.pre_layer.weight': tensor([[-0.0084, -0.0281, -0.0035,  ..., -0.0064, -0.0063,  0.0082],\n",
      "        [ 0.0107,  0.0352, -0.0237,  ..., -0.0095,  0.0309,  0.0330],\n",
      "        [ 0.0054,  0.0017,  0.0239,  ...,  0.0060,  0.0151, -0.0053],\n",
      "        ...,\n",
      "        [ 0.0747,  0.0045,  0.0058,  ..., -0.0201,  0.0143, -0.0576],\n",
      "        [-0.0620, -0.0299, -0.0118,  ...,  0.0062, -0.0055, -0.0094],\n",
      "        [-0.0222, -0.0142, -0.0135,  ..., -0.0374, -0.0205,  0.0050]],\n",
      "       device='cuda:0'), 'model.layers.10.self_attn.q_proj.adapter.adapter_A': tensor([[ 0.8296,  0.7819,  0.1261,  ..., -1.1122, -1.3919,  0.2651],\n",
      "        [-0.7514,  0.2181, -0.7485,  ...,  0.5961,  0.0737,  2.4234],\n",
      "        [-0.5981, -1.8142, -1.4051,  ..., -1.0598, -1.0356, -0.5735],\n",
      "        ...,\n",
      "        [-1.5374, -0.0225, -0.7593,  ...,  1.9453,  2.8062,  0.4136],\n",
      "        [-0.9327,  0.8815, -1.2653,  ...,  2.4026, -0.1762,  1.5337],\n",
      "        [ 1.2321,  1.0610, -0.1258,  ..., -0.3123, -0.6187, -0.4749]],\n",
      "       device='cuda:0'), 'model.layers.10.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.10.self_attn.k_proj.pre_layer.weight': tensor([[ 0.0554,  0.0052,  0.0278,  ...,  0.0189,  0.0267, -0.0199],\n",
      "        [ 0.0684, -0.0049,  0.0366,  ..., -0.0334,  0.0026,  0.0432],\n",
      "        [ 0.0118,  0.0012,  0.0162,  ...,  0.0023, -0.0082,  0.0317],\n",
      "        ...,\n",
      "        [-0.0447,  0.0510, -0.0109,  ...,  0.0084,  0.0195,  0.0156],\n",
      "        [ 0.0100, -0.0427,  0.0322,  ..., -0.0369, -0.0206,  0.0198],\n",
      "        [ 0.0220, -0.0322, -0.0103,  ..., -0.0237, -0.0752, -0.0737]],\n",
      "       device='cuda:0'), 'model.layers.10.self_attn.k_proj.adapter.adapter_A': tensor([[ 0.7133,  2.6724,  0.4938,  ..., -0.2963, -1.0044,  1.8452],\n",
      "        [-1.6593, -1.2712,  0.8768,  ..., -0.3537, -0.3795,  0.7518],\n",
      "        [-0.7228, -0.4281,  0.0794,  ..., -0.0837, -1.4656, -1.2000],\n",
      "        ...,\n",
      "        [-0.3178, -0.5882,  0.1860,  ..., -0.8127, -0.0298, -1.9757],\n",
      "        [-0.1364, -0.1772, -0.1873,  ...,  0.2694, -2.5787, -0.2629],\n",
      "        [-2.3453, -0.1302, -1.0246,  ...,  0.7789,  0.3150, -0.2286]],\n",
      "       device='cuda:0'), 'model.layers.10.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.10.self_attn.v_proj.pre_layer.weight': tensor([[-8.9722e-03,  6.1417e-04, -8.3984e-02,  ...,  3.0670e-03,\n",
      "          9.0332e-03, -6.8970e-03],\n",
      "        [ 5.3711e-03, -4.2343e-04,  3.9551e-02,  ...,  8.1787e-03,\n",
      "          5.1260e-05, -1.0315e-02],\n",
      "        [-9.0942e-03,  1.1444e-03,  1.4709e-02,  ...,  1.5106e-03,\n",
      "         -2.8839e-03, -8.5449e-03],\n",
      "        ...,\n",
      "        [ 3.6926e-03,  9.5215e-03, -4.9438e-03,  ..., -1.1963e-02,\n",
      "         -3.0975e-03,  1.2302e-04],\n",
      "        [-4.6387e-03,  3.2654e-03, -1.1292e-02,  ...,  2.0264e-02,\n",
      "         -8.2397e-03,  3.1738e-02],\n",
      "        [ 1.4893e-02, -4.5166e-03,  4.0283e-03,  ...,  2.5146e-02,\n",
      "         -7.8735e-03, -1.1963e-02]], device='cuda:0'), 'model.layers.10.self_attn.v_proj.adapter.adapter_A': tensor([[-0.5656, -1.1077, -0.7370,  ...,  0.9256, -0.2286,  0.6458],\n",
      "        [-0.5679, -0.8872,  0.5865,  ...,  0.3810,  0.1407,  1.0210],\n",
      "        [ 0.2538,  1.4601,  0.5438,  ..., -1.2791,  1.1879,  0.1871],\n",
      "        ...,\n",
      "        [-1.5910,  0.7773, -0.6870,  ...,  0.6239, -1.0041,  0.1950],\n",
      "        [ 0.6292,  2.6927, -0.3814,  ..., -1.2775, -0.9200,  1.4518],\n",
      "        [-0.0051,  0.8131, -0.1696,  ..., -0.6572, -1.5033,  0.0046]],\n",
      "       device='cuda:0'), 'model.layers.10.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.10.self_attn.o_proj.pre_layer.weight': tensor([[-1.2390e-02, -1.2146e-02,  2.2461e-02,  ...,  9.0790e-04,\n",
      "          9.5215e-03, -1.0864e-02],\n",
      "        [ 3.2196e-03,  1.4587e-02, -1.0254e-02,  ...,  7.0801e-03,\n",
      "         -1.8799e-02, -1.9897e-02],\n",
      "        [ 9.0332e-02, -2.7588e-02, -2.8076e-02,  ..., -3.4485e-03,\n",
      "          2.5330e-03,  1.5991e-02],\n",
      "        ...,\n",
      "        [-1.3489e-02,  1.4648e-02,  4.9438e-03,  ..., -1.0376e-02,\n",
      "          1.7212e-02,  8.7261e-05],\n",
      "        [ 2.8839e-03,  5.4932e-04, -2.0294e-03,  ..., -3.9368e-03,\n",
      "          6.8054e-03,  2.8320e-02],\n",
      "        [ 5.0659e-03,  1.2390e-02, -2.7924e-03,  ...,  1.0010e-02,\n",
      "          1.3428e-02,  6.9275e-03]], device='cuda:0'), 'model.layers.10.self_attn.o_proj.adapter.adapter_A': tensor([[ 0.1755,  1.2002, -0.1552,  ..., -0.7230, -0.9933,  1.4588],\n",
      "        [-0.3282,  0.8682, -1.1178,  ..., -1.2241, -0.4524, -1.1701],\n",
      "        [ 0.6635, -0.5322, -1.4670,  ..., -0.6647, -1.2841, -0.5078],\n",
      "        ...,\n",
      "        [ 0.3309, -1.3711,  0.1269,  ...,  0.2876, -1.0732,  0.1303],\n",
      "        [-1.3053,  0.6599, -0.1270,  ..., -0.4195,  0.5061,  0.8836],\n",
      "        [-0.7347, -1.6373, -0.6328,  ...,  1.0016,  0.5104,  0.4354]],\n",
      "       device='cuda:0'), 'model.layers.10.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.10.mlp.gate_proj.weight': tensor([[ 1.0315e-02, -1.5442e-02,  1.0437e-02,  ...,  1.3809e-03,\n",
      "         -2.1851e-02, -2.9541e-02],\n",
      "        [ 1.6235e-02,  6.8359e-03, -6.5430e-02,  ..., -2.7275e-04,\n",
      "          4.1016e-02,  1.2146e-02],\n",
      "        [ 1.9043e-02,  4.4632e-04, -7.3242e-03,  ...,  4.1809e-03,\n",
      "         -1.9653e-02, -2.0264e-02],\n",
      "        ...,\n",
      "        [ 9.7275e-04,  2.2583e-02,  3.6621e-02,  ...,  1.6113e-02,\n",
      "         -2.6703e-03,  1.1414e-02],\n",
      "        [ 2.8442e-02, -7.5073e-03, -2.0386e-02,  ..., -5.9204e-03,\n",
      "          4.6631e-02, -2.0264e-02],\n",
      "        [ 3.5095e-03,  1.2695e-02, -1.5378e-05,  ...,  8.3618e-03,\n",
      "          2.5146e-02, -1.9043e-02]], device='cuda:0'), 'model.layers.10.mlp.up_proj.pre_layer.weight': tensor([[-0.0393, -0.0193, -0.0226,  ...,  0.0140, -0.0244, -0.0312],\n",
      "        [ 0.0129, -0.0026, -0.0100,  ...,  0.0179, -0.0220,  0.0347],\n",
      "        [-0.0203, -0.0403,  0.0119,  ..., -0.0294,  0.0078, -0.0264],\n",
      "        ...,\n",
      "        [-0.0135, -0.0203,  0.0030,  ...,  0.0140,  0.0189, -0.0141],\n",
      "        [ 0.0276,  0.0029,  0.0057,  ...,  0.0154,  0.0327,  0.0327],\n",
      "        [ 0.0011,  0.0171, -0.0118,  ...,  0.0044, -0.0068, -0.0269]],\n",
      "       device='cuda:0'), 'model.layers.10.mlp.up_proj.adapter.adapter_A': tensor([[-0.0408,  0.0556, -1.1568,  ...,  1.0935, -0.7219, -1.1570],\n",
      "        [ 0.1990,  0.2902, -0.4939,  ..., -0.1182,  1.7135,  0.2395],\n",
      "        [-0.3192, -1.0499, -1.5355,  ..., -1.1201, -1.3298,  2.1274],\n",
      "        ...,\n",
      "        [ 1.0200, -0.3150,  0.5804,  ...,  0.5529, -1.5116,  0.6201],\n",
      "        [ 0.0890, -0.3957,  0.8621,  ...,  0.0965, -0.1082,  0.5973],\n",
      "        [-0.0402, -0.5841,  0.7334,  ...,  1.2203, -0.1260, -0.0959]],\n",
      "       device='cuda:0'), 'model.layers.10.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.10.mlp.down_proj.pre_layer.weight': tensor([[-0.0236,  0.0332,  0.0090,  ..., -0.0165,  0.0203, -0.0115],\n",
      "        [ 0.0032, -0.0131, -0.0400,  ...,  0.0221, -0.0184,  0.0308],\n",
      "        [ 0.0232, -0.0166, -0.0128,  ...,  0.0216, -0.0101, -0.0027],\n",
      "        ...,\n",
      "        [-0.0077,  0.0079, -0.0131,  ...,  0.0234,  0.0010,  0.0019],\n",
      "        [-0.0275, -0.0221, -0.0211,  ..., -0.0015,  0.0254, -0.0050],\n",
      "        [ 0.0130,  0.0108, -0.0330,  ...,  0.0176,  0.0239, -0.0081]],\n",
      "       device='cuda:0'), 'model.layers.10.mlp.down_proj.adapter.adapter_A': tensor([[ 0.9959,  0.9342,  1.7620,  ...,  0.1214,  0.8664,  0.4243],\n",
      "        [ 0.4552,  0.5100,  0.1226,  ..., -0.7941, -0.5406,  1.3254],\n",
      "        [ 0.0382,  1.0628,  1.5606,  ..., -0.6098,  1.7110, -0.1782],\n",
      "        ...,\n",
      "        [-1.5630, -0.3669,  0.9091,  ...,  0.3477,  1.4939, -0.6980],\n",
      "        [-2.1711, -1.3981, -1.4838,  ..., -0.0980, -0.3791, -1.3640],\n",
      "        [ 1.4877, -0.3824,  0.9978,  ..., -0.9046,  2.0471, -1.0494]],\n",
      "       device='cuda:0'), 'model.layers.10.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.10.input_layernorm.weight': tensor([0.5195, 0.5469, 0.4316,  ..., 0.5195, 0.5625, 0.4941], device='cuda:0'), 'model.layers.10.post_attention_layernorm.weight': tensor([0.4160, 0.4141, 0.3438,  ..., 0.4238, 0.3984, 0.4219], device='cuda:0'), 'model.layers.11.self_attn.q_proj.pre_layer.weight': tensor([[-0.0114,  0.0430, -0.0025,  ..., -0.0155,  0.0154,  0.0210],\n",
      "        [ 0.0175, -0.0254,  0.0106,  ...,  0.0420,  0.0623,  0.0102],\n",
      "        [ 0.0037,  0.0214,  0.0228,  ...,  0.0698, -0.0155, -0.0212],\n",
      "        ...,\n",
      "        [-0.0245,  0.0211, -0.0168,  ...,  0.0033, -0.0232, -0.0131],\n",
      "        [-0.0148,  0.0334,  0.0149,  ..., -0.0033, -0.0134, -0.0183],\n",
      "        [ 0.0151,  0.0376,  0.0073,  ...,  0.0183, -0.0447,  0.0625]],\n",
      "       device='cuda:0'), 'model.layers.11.self_attn.q_proj.adapter.adapter_A': tensor([[ 2.4493e+00, -1.4501e-01, -6.7505e-01,  ..., -8.4697e-02,\n",
      "          2.0918e-01,  1.4995e+00],\n",
      "        [-8.5366e-01, -2.5620e-01, -3.3445e-02,  ...,  1.2788e+00,\n",
      "         -2.2686e-01, -1.9834e+00],\n",
      "        [ 1.6057e+00, -6.8258e-01,  6.6455e-01,  ...,  3.2113e-01,\n",
      "         -4.3272e-01, -8.8068e-01],\n",
      "        ...,\n",
      "        [-5.8060e-01, -1.8427e+00,  1.2905e+00,  ..., -9.6484e-01,\n",
      "         -2.7522e-01, -1.2364e-01],\n",
      "        [ 1.0303e-01,  6.5886e-01, -1.3952e+00,  ..., -1.4286e-03,\n",
      "          7.1304e-01, -9.5953e-01],\n",
      "        [ 1.0049e+00,  3.8359e-01, -3.7855e-01,  ...,  1.2087e-01,\n",
      "          2.3157e-01,  1.4010e+00]], device='cuda:0'), 'model.layers.11.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.11.self_attn.k_proj.pre_layer.weight': tensor([[-0.0156,  0.0141,  0.0225,  ...,  0.0073,  0.0036,  0.0019],\n",
      "        [ 0.0269, -0.0344, -0.0161,  ..., -0.0464,  0.0532, -0.0164],\n",
      "        [ 0.0510,  0.0535, -0.0200,  ...,  0.0117, -0.0200,  0.0250],\n",
      "        ...,\n",
      "        [-0.0042, -0.0099,  0.0177,  ...,  0.0083,  0.0199, -0.0298],\n",
      "        [-0.0027, -0.0442, -0.0112,  ...,  0.0562, -0.0216,  0.0244],\n",
      "        [-0.0025,  0.0099, -0.0366,  ..., -0.0742, -0.0084, -0.0096]],\n",
      "       device='cuda:0'), 'model.layers.11.self_attn.k_proj.adapter.adapter_A': tensor([[ 1.1731,  2.0455, -0.2442,  ..., -0.0236,  0.7057, -0.6022],\n",
      "        [ 0.1974, -0.1739,  0.9821,  ..., -0.3267, -0.5571,  0.0447],\n",
      "        [ 1.4685,  1.3161, -1.1066,  ..., -0.7039, -1.4799,  1.2187],\n",
      "        ...,\n",
      "        [ 0.8773,  0.7434, -1.9532,  ...,  1.8131, -0.3221,  0.0876],\n",
      "        [ 1.2220,  1.5411, -0.0446,  ...,  0.9625,  0.5023,  1.1271],\n",
      "        [-0.6220, -0.6493,  0.2015,  ..., -1.7038, -0.7241, -1.0352]],\n",
      "       device='cuda:0'), 'model.layers.11.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.11.self_attn.v_proj.pre_layer.weight': tensor([[ 6.9275e-03,  2.3041e-03, -5.0964e-03,  ..., -4.2534e-04,\n",
      "         -3.7689e-03,  9.2163e-03],\n",
      "        [ 1.0193e-02,  5.7983e-03, -1.2695e-02,  ..., -1.6846e-02,\n",
      "          2.6123e-02, -1.9409e-02],\n",
      "        [-1.1230e-02,  3.0365e-03, -1.7456e-02,  ...,  2.4780e-02,\n",
      "         -1.5625e-02, -2.2888e-04],\n",
      "        ...,\n",
      "        [ 2.1515e-03,  5.7678e-03,  2.9541e-02,  ..., -3.0884e-02,\n",
      "          1.1749e-03,  1.1475e-02],\n",
      "        [-2.9206e-06,  3.1128e-02,  6.5918e-03,  ...,  3.8147e-03,\n",
      "          1.0376e-02, -2.7344e-02],\n",
      "        [ 1.1230e-02, -7.2937e-03,  7.8735e-03,  ...,  1.1841e-02,\n",
      "          1.3367e-02, -1.1536e-02]], device='cuda:0'), 'model.layers.11.self_attn.v_proj.adapter.adapter_A': tensor([[ 0.2192, -0.5894,  0.6195,  ...,  1.1500,  0.5277,  0.7521],\n",
      "        [-0.8982, -2.3668, -1.5417,  ...,  0.2462,  1.1860, -1.3931],\n",
      "        [ 0.3979,  1.0292, -1.3240,  ...,  2.2224, -1.3178,  1.4006],\n",
      "        ...,\n",
      "        [-1.0928, -0.0209,  1.0308,  ...,  1.3789, -0.0371, -3.5636],\n",
      "        [ 0.1624,  0.0992, -1.0060,  ..., -1.3491,  0.0642,  0.2285],\n",
      "        [-0.0341,  1.1850, -1.6711,  ...,  0.6593,  0.7168, -0.4200]],\n",
      "       device='cuda:0'), 'model.layers.11.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.11.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0339,  0.0186,  0.0042,  ...,  0.0016,  0.0225, -0.0162],\n",
      "        [ 0.0033,  0.0171, -0.0173,  ..., -0.0032, -0.0048, -0.0138],\n",
      "        [ 0.0102,  0.0146, -0.0039,  ...,  0.0054,  0.0018,  0.0327],\n",
      "        ...,\n",
      "        [-0.0193,  0.0018,  0.0164,  ..., -0.0108, -0.0182,  0.0039],\n",
      "        [-0.0113, -0.0165,  0.0017,  ...,  0.0074,  0.0051, -0.0027],\n",
      "        [-0.0071, -0.0115, -0.0104,  ..., -0.0126, -0.0024,  0.0055]],\n",
      "       device='cuda:0'), 'model.layers.11.self_attn.o_proj.adapter.adapter_A': tensor([[ 1.9799,  1.5151,  0.6302,  ..., -0.2581, -0.8459, -1.1545],\n",
      "        [ 2.1464, -0.7214,  0.6108,  ..., -0.3786,  0.9015,  1.6118],\n",
      "        [-0.3113,  0.4575, -0.6934,  ..., -0.3668, -0.6574, -1.6834],\n",
      "        ...,\n",
      "        [ 1.1600,  0.3073,  1.0766,  ..., -0.2831, -0.4848,  0.3788],\n",
      "        [-0.1768,  1.0258,  1.1350,  ...,  0.1740,  1.6598, -0.9854],\n",
      "        [ 0.9367, -1.8683,  0.2847,  ..., -0.6211, -0.6895,  2.1745]],\n",
      "       device='cuda:0'), 'model.layers.11.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.11.mlp.gate_proj.weight': tensor([[-2.7954e-02, -1.9043e-02,  1.8311e-02,  ...,  1.9287e-02,\n",
      "          1.7822e-02, -2.1973e-02],\n",
      "        [ 9.9659e-05,  2.4170e-02,  4.5776e-03,  ...,  2.8442e-02,\n",
      "          9.3994e-03,  2.9541e-02],\n",
      "        [-2.6855e-02,  4.1504e-02, -1.2573e-02,  ...,  1.6724e-02,\n",
      "         -4.9133e-03,  3.3936e-02],\n",
      "        ...,\n",
      "        [ 5.5542e-03, -6.6223e-03, -4.0894e-03,  ..., -2.4414e-02,\n",
      "         -2.1118e-02, -2.1973e-02],\n",
      "        [-8.4305e-04,  1.5747e-02,  3.6865e-02,  ..., -5.7678e-03,\n",
      "          1.2573e-02, -1.8799e-02],\n",
      "        [-4.8828e-02, -8.7357e-04, -1.2512e-02,  ..., -5.0354e-03,\n",
      "         -2.0508e-02, -2.4414e-02]], device='cuda:0'), 'model.layers.11.mlp.up_proj.pre_layer.weight': tensor([[-0.0075, -0.0356, -0.0007,  ..., -0.0298,  0.0212,  0.0134],\n",
      "        [-0.0145,  0.0085,  0.0201,  ..., -0.0127, -0.0277,  0.0090],\n",
      "        [ 0.0092,  0.0098, -0.0146,  ...,  0.0029, -0.0248,  0.0112],\n",
      "        ...,\n",
      "        [ 0.0093,  0.0125, -0.0030,  ..., -0.0135,  0.0347,  0.0028],\n",
      "        [ 0.0018, -0.0168, -0.0381,  ...,  0.0002, -0.0018, -0.0226],\n",
      "        [ 0.0182,  0.0067, -0.0275,  ..., -0.0220, -0.0032,  0.0153]],\n",
      "       device='cuda:0'), 'model.layers.11.mlp.up_proj.adapter.adapter_A': tensor([[-0.2795,  0.2273, -0.0409,  ...,  0.4024, -0.6766,  1.5562],\n",
      "        [-1.4535,  0.8618,  0.6337,  ...,  0.0328, -0.9419,  0.9694],\n",
      "        [ 0.8254,  0.6935,  0.0847,  ...,  0.2691, -2.1312,  0.0801],\n",
      "        ...,\n",
      "        [-0.2941,  0.7489, -0.9059,  ...,  0.6095, -1.0396, -1.6431],\n",
      "        [-2.4240, -0.0096,  0.1453,  ..., -1.5073,  0.9250,  0.0342],\n",
      "        [ 1.8846, -0.4794, -1.1721,  ...,  0.3137,  0.0699, -0.1358]],\n",
      "       device='cuda:0'), 'model.layers.11.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.11.mlp.down_proj.pre_layer.weight': tensor([[ 0.0125,  0.0167,  0.0118,  ..., -0.0183, -0.0457, -0.0009],\n",
      "        [-0.0225, -0.0344, -0.0115,  ...,  0.0002, -0.0172,  0.0282],\n",
      "        [ 0.0322,  0.0009,  0.0014,  ...,  0.0062,  0.0027,  0.0156],\n",
      "        ...,\n",
      "        [-0.0179, -0.0072,  0.0092,  ...,  0.0107, -0.0208,  0.0046],\n",
      "        [-0.0140, -0.0197, -0.0099,  ...,  0.0015,  0.0099, -0.0186],\n",
      "        [-0.0270, -0.0244,  0.0388,  ..., -0.0016, -0.0134, -0.0099]],\n",
      "       device='cuda:0'), 'model.layers.11.mlp.down_proj.adapter.adapter_A': tensor([[ 0.0299, -1.6430, -0.8196,  ..., -0.8730, -0.4497,  1.9025],\n",
      "        [ 0.5427, -1.1754, -1.2127,  ..., -0.3876,  0.7341, -0.9023],\n",
      "        [ 0.0535, -0.5736,  0.8634,  ..., -0.2684, -0.7998,  0.6543],\n",
      "        ...,\n",
      "        [-0.3094,  1.0756, -0.3594,  ...,  0.5243, -0.0651,  0.5168],\n",
      "        [-0.5386,  0.0680, -0.0978,  ...,  0.3632, -2.5226, -1.4526],\n",
      "        [-1.1213, -0.2181,  0.1410,  ..., -1.4313, -0.5440, -0.7935]],\n",
      "       device='cuda:0'), 'model.layers.11.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.11.input_layernorm.weight': tensor([0.5000, 0.4844, 0.3926,  ..., 0.5000, 0.4688, 0.4785], device='cuda:0'), 'model.layers.11.post_attention_layernorm.weight': tensor([0.4727, 0.4531, 0.3184,  ..., 0.4668, 0.4395, 0.4609], device='cuda:0'), 'model.layers.12.self_attn.q_proj.pre_layer.weight': tensor([[ 0.0023,  0.0012, -0.0007,  ..., -0.0072,  0.0131,  0.0062],\n",
      "        [-0.0048,  0.0024, -0.0028,  ..., -0.0025, -0.0104, -0.0057],\n",
      "        [-0.0063,  0.0052, -0.0094,  ...,  0.0148, -0.0281, -0.0065],\n",
      "        ...,\n",
      "        [ 0.0391,  0.0053, -0.0216,  ..., -0.0033, -0.0093, -0.0255],\n",
      "        [-0.0303,  0.0378, -0.0417,  ..., -0.0195, -0.0234,  0.0043],\n",
      "        [-0.0125,  0.0679,  0.0220,  ...,  0.0110, -0.0115, -0.0334]],\n",
      "       device='cuda:0'), 'model.layers.12.self_attn.q_proj.adapter.adapter_A': tensor([[ 0.0321, -0.0662, -0.2538,  ...,  1.1498,  2.2899,  0.6748],\n",
      "        [ 1.5852,  0.6921,  0.1890,  ...,  0.7330,  1.5800,  0.1979],\n",
      "        [ 0.0331, -0.3320, -1.4601,  ...,  0.3934,  1.2651, -1.3367],\n",
      "        ...,\n",
      "        [-0.0718, -1.5955, -0.1341,  ..., -0.3413,  1.0121,  0.2333],\n",
      "        [-1.0099, -0.0192,  0.1897,  ..., -0.8663, -0.6235, -0.4658],\n",
      "        [-1.0944, -0.0269,  2.0736,  ..., -0.1673, -0.1662,  0.6859]],\n",
      "       device='cuda:0'), 'model.layers.12.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.12.self_attn.k_proj.pre_layer.weight': tensor([[-0.0259,  0.0078, -0.0032,  ..., -0.0048, -0.0304,  0.0115],\n",
      "        [ 0.0057, -0.0315,  0.0018,  ..., -0.0025,  0.0009,  0.0150],\n",
      "        [-0.0181,  0.0087, -0.0092,  ..., -0.0178,  0.0288, -0.0161],\n",
      "        ...,\n",
      "        [ 0.0245,  0.0167,  0.0064,  ...,  0.0146,  0.0095, -0.0007],\n",
      "        [-0.0115, -0.0190, -0.0108,  ...,  0.0076,  0.0166, -0.0070],\n",
      "        [ 0.0074,  0.0116, -0.0096,  ...,  0.0297, -0.0275, -0.0189]],\n",
      "       device='cuda:0'), 'model.layers.12.self_attn.k_proj.adapter.adapter_A': tensor([[-1.3323,  0.4805,  0.6556,  ...,  0.3003, -2.0738, -1.0341],\n",
      "        [-0.5379, -1.3507,  0.3663,  ...,  0.4065,  0.6343,  2.7313],\n",
      "        [ 1.4774,  1.0751,  0.9337,  ...,  0.9859, -1.1691, -0.1950],\n",
      "        ...,\n",
      "        [-1.8329, -0.8241, -0.9635,  ...,  1.2534,  0.6038,  1.9888],\n",
      "        [-1.5076, -0.3318, -0.3649,  ...,  0.8231,  0.1501, -0.3368],\n",
      "        [-1.0174,  0.3271, -0.8377,  ..., -1.0191,  0.0713,  0.7423]],\n",
      "       device='cuda:0'), 'model.layers.12.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.12.self_attn.v_proj.pre_layer.weight': tensor([[ 0.0079,  0.0288, -0.0015,  ...,  0.0026, -0.0005, -0.0040],\n",
      "        [-0.0036, -0.0033, -0.0124,  ...,  0.0044,  0.0081,  0.0112],\n",
      "        [-0.0223, -0.0048, -0.0034,  ...,  0.0012,  0.0112, -0.0177],\n",
      "        ...,\n",
      "        [ 0.0066,  0.0201,  0.0165,  ..., -0.0030,  0.0176,  0.0009],\n",
      "        [ 0.0247,  0.0104, -0.0220,  ..., -0.0003,  0.0023,  0.0164],\n",
      "        [-0.0140,  0.0038, -0.0311,  ...,  0.0015, -0.0068, -0.0085]],\n",
      "       device='cuda:0'), 'model.layers.12.self_attn.v_proj.adapter.adapter_A': tensor([[-0.1121, -0.1226,  0.7824,  ..., -0.4457,  0.1640, -0.2797],\n",
      "        [ 1.8701, -1.5584,  2.4910,  ..., -1.2999, -0.5869,  0.0948],\n",
      "        [-0.2060, -1.6586, -0.5556,  ..., -1.5102,  1.1588, -1.2391],\n",
      "        ...,\n",
      "        [ 0.2307,  0.6295, -0.3626,  ...,  1.4461,  0.8770,  0.8217],\n",
      "        [-0.1003,  0.0265,  0.2636,  ...,  2.7232, -0.7380, -1.2967],\n",
      "        [-0.8595,  0.5085, -0.3871,  ..., -0.7775,  0.4197, -0.3423]],\n",
      "       device='cuda:0'), 'model.layers.12.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.12.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0151,  0.0017,  0.0072,  ..., -0.0039,  0.0056,  0.0100],\n",
      "        [-0.0098, -0.0097, -0.0081,  ..., -0.0162,  0.0019,  0.0100],\n",
      "        [-0.0049,  0.0087,  0.0006,  ...,  0.0059,  0.0023,  0.0065],\n",
      "        ...,\n",
      "        [ 0.0090, -0.0025,  0.0038,  ..., -0.0161, -0.0082, -0.0074],\n",
      "        [-0.0051, -0.0064,  0.0003,  ...,  0.0023, -0.0007, -0.0187],\n",
      "        [ 0.0065, -0.0037, -0.0019,  ..., -0.0036,  0.0116, -0.0021]],\n",
      "       device='cuda:0'), 'model.layers.12.self_attn.o_proj.adapter.adapter_A': tensor([[ 1.5473,  0.9004,  1.2696,  ...,  0.9033,  0.3286,  0.6250],\n",
      "        [ 0.2322, -0.5024,  0.7192,  ...,  0.5014, -1.3126,  0.2258],\n",
      "        [-1.3693,  0.5174,  0.9692,  ...,  1.0229,  1.0856,  0.6011],\n",
      "        ...,\n",
      "        [ 1.4750, -0.0171, -1.6588,  ..., -0.1760,  2.2925, -0.1698],\n",
      "        [ 0.3729, -0.5960, -0.2745,  ..., -0.7079,  0.0932, -0.4657],\n",
      "        [ 1.0831,  0.8691,  0.1101,  ..., -0.4236, -0.6829, -0.6688]],\n",
      "       device='cuda:0'), 'model.layers.12.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.12.mlp.gate_proj.weight': tensor([[ 0.0079,  0.0564,  0.0103,  ..., -0.0053, -0.0085, -0.0130],\n",
      "        [ 0.0150, -0.0123, -0.0161,  ..., -0.0033,  0.0127,  0.0003],\n",
      "        [ 0.0038,  0.0405, -0.0035,  ..., -0.0216, -0.0503,  0.0183],\n",
      "        ...,\n",
      "        [-0.0018,  0.0041, -0.0087,  ...,  0.0138,  0.0117, -0.0308],\n",
      "        [ 0.0056, -0.0178, -0.0034,  ..., -0.0277, -0.0007,  0.0160],\n",
      "        [ 0.0150,  0.0166, -0.0051,  ..., -0.0089, -0.0096, -0.0100]],\n",
      "       device='cuda:0'), 'model.layers.12.mlp.up_proj.pre_layer.weight': tensor([[-0.0081,  0.0221, -0.0292,  ..., -0.0223,  0.0282,  0.0184],\n",
      "        [-0.0083, -0.0190, -0.0206,  ..., -0.0215, -0.0205, -0.0060],\n",
      "        [-0.0176, -0.0044, -0.0205,  ...,  0.0106, -0.0051, -0.0109],\n",
      "        ...,\n",
      "        [-0.0200, -0.0037, -0.0315,  ...,  0.0082, -0.0292,  0.0024],\n",
      "        [-0.0192,  0.0168, -0.0347,  ...,  0.0022,  0.0125, -0.0115],\n",
      "        [ 0.0229,  0.0250,  0.0145,  ..., -0.0115, -0.0344, -0.0073]],\n",
      "       device='cuda:0'), 'model.layers.12.mlp.up_proj.adapter.adapter_A': tensor([[ 0.8014,  1.6609, -0.8983,  ..., -1.8311,  0.4344,  0.9345],\n",
      "        [ 1.2522, -0.7048, -0.0207,  ...,  1.7989, -1.4048,  0.6709],\n",
      "        [-0.5028, -0.5237, -0.1824,  ...,  1.2606,  0.1061,  1.8199],\n",
      "        ...,\n",
      "        [-1.0966,  0.0562, -0.6699,  ..., -0.7172,  1.9581, -0.9877],\n",
      "        [-1.6346, -0.5129,  0.9794,  ...,  1.5048,  0.2161,  1.6676],\n",
      "        [-0.1360, -1.4139,  0.7015,  ...,  0.7569,  0.8699, -1.0781]],\n",
      "       device='cuda:0'), 'model.layers.12.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.12.mlp.down_proj.pre_layer.weight': tensor([[-3.1662e-04,  3.3417e-03, -3.7842e-03,  ...,  1.4038e-03,\n",
      "          4.4678e-02, -1.9043e-02],\n",
      "        [ 7.3433e-05, -1.8082e-03,  1.8555e-02,  ..., -2.2339e-02,\n",
      "         -1.3428e-02, -3.4485e-03],\n",
      "        [-1.8845e-03, -1.8433e-02,  9.2773e-03,  ...,  1.0147e-03,\n",
      "          3.9673e-03, -1.0376e-02],\n",
      "        ...,\n",
      "        [ 2.3315e-02, -1.0193e-02,  1.9165e-02,  ...,  2.6855e-02,\n",
      "          1.0071e-03, -1.3672e-02],\n",
      "        [-1.3367e-02,  8.8501e-03,  2.0508e-02,  ...,  1.3184e-02,\n",
      "         -2.5391e-02, -8.7280e-03],\n",
      "        [-2.5757e-02,  3.8147e-03, -8.1787e-03,  ...,  6.2561e-03,\n",
      "         -4.8218e-03, -4.3945e-03]], device='cuda:0'), 'model.layers.12.mlp.down_proj.adapter.adapter_A': tensor([[ 0.0944,  0.2952,  0.9554,  ...,  0.3265,  0.0447, -0.0597],\n",
      "        [-0.7857, -0.5068, -0.7518,  ...,  0.5478,  1.5570,  0.5169],\n",
      "        [-0.3112, -1.1097,  2.0887,  ...,  0.6314, -2.1397, -0.1036],\n",
      "        ...,\n",
      "        [ 0.1014,  0.9615,  2.8488,  ...,  0.9638, -0.3621, -0.6606],\n",
      "        [ 0.3993,  0.6317,  0.3362,  ..., -0.6762,  0.1251,  2.4797],\n",
      "        [-1.0969,  0.5940, -0.5540,  ...,  0.1725,  0.9390, -0.9217]],\n",
      "       device='cuda:0'), 'model.layers.12.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.12.input_layernorm.weight': tensor([0.5000, 0.4824, 0.5000,  ..., 0.4688, 0.4980, 0.4434], device='cuda:0'), 'model.layers.12.post_attention_layernorm.weight': tensor([0.4844, 0.4824, 0.3496,  ..., 0.4805, 0.4707, 0.4785], device='cuda:0'), 'model.layers.13.self_attn.q_proj.pre_layer.weight': tensor([[-0.0164,  0.0123,  0.0073,  ...,  0.0008,  0.0161,  0.0089],\n",
      "        [ 0.0093,  0.0210,  0.0013,  ...,  0.0356, -0.0100,  0.0166],\n",
      "        [-0.0164,  0.0008, -0.0097,  ..., -0.0171,  0.0117, -0.0047],\n",
      "        ...,\n",
      "        [-0.0061, -0.0566,  0.0059,  ...,  0.0063,  0.0332,  0.0286],\n",
      "        [ 0.0400,  0.0591,  0.0120,  ..., -0.0396,  0.0874,  0.0008],\n",
      "        [-0.0030,  0.0142,  0.0496,  ..., -0.0013,  0.0737, -0.0469]],\n",
      "       device='cuda:0'), 'model.layers.13.self_attn.q_proj.adapter.adapter_A': tensor([[-1.7450, -0.4426, -0.4010,  ...,  1.0147,  0.4953, -0.3185],\n",
      "        [ 1.0336,  0.4449, -0.3910,  ...,  2.1422,  0.5510, -0.6313],\n",
      "        [ 0.2603,  0.7314,  0.7222,  ...,  0.8784,  0.3463, -1.1291],\n",
      "        ...,\n",
      "        [-0.2372,  0.8472,  0.1846,  ..., -0.0443,  0.3567, -1.1818],\n",
      "        [-1.4187, -1.0898, -0.6997,  ..., -0.4943, -0.9165, -0.5126],\n",
      "        [-0.6113,  1.5218,  0.4640,  ...,  0.0993,  0.1973,  0.7847]],\n",
      "       device='cuda:0'), 'model.layers.13.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.13.self_attn.k_proj.pre_layer.weight': tensor([[ 0.0183, -0.0228, -0.0205,  ..., -0.0046,  0.0047, -0.0022],\n",
      "        [-0.0041, -0.0125,  0.0126,  ...,  0.0286,  0.0126, -0.0175],\n",
      "        [ 0.0173, -0.0100, -0.0356,  ...,  0.0114,  0.0024, -0.0203],\n",
      "        ...,\n",
      "        [-0.0208,  0.0066, -0.0074,  ...,  0.0435,  0.0042, -0.0002],\n",
      "        [ 0.0125,  0.0135,  0.0267,  ...,  0.0166,  0.0078,  0.0154],\n",
      "        [-0.0278,  0.0260, -0.0240,  ...,  0.0166, -0.0239,  0.0008]],\n",
      "       device='cuda:0'), 'model.layers.13.self_attn.k_proj.adapter.adapter_A': tensor([[ 0.1048, -0.6690,  1.1631,  ..., -0.3185,  1.4448,  1.6925],\n",
      "        [ 0.6951,  1.0988,  1.0889,  ...,  0.5291,  0.0100,  1.5704],\n",
      "        [ 0.2631, -0.3248,  1.1227,  ...,  0.8034,  1.6660, -1.3248],\n",
      "        ...,\n",
      "        [ 0.2879, -0.2985,  2.0551,  ...,  0.0404, -2.4669, -0.0043],\n",
      "        [-1.0677,  1.2041, -1.9902,  ...,  0.6239, -0.5474,  0.5507],\n",
      "        [ 1.9681, -0.8506, -1.3229,  ..., -0.5953, -0.3011,  1.0267]],\n",
      "       device='cuda:0'), 'model.layers.13.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.13.self_attn.v_proj.pre_layer.weight': tensor([[ 0.0210, -0.0114,  0.0898,  ..., -0.0085,  0.0039,  0.0098],\n",
      "        [-0.0109, -0.0154,  0.0222,  ..., -0.0061, -0.0096,  0.0109],\n",
      "        [ 0.0131, -0.0036,  0.0243,  ..., -0.0272,  0.0156, -0.0036],\n",
      "        ...,\n",
      "        [ 0.0006, -0.0004,  0.0084,  ..., -0.0197, -0.0175,  0.0049],\n",
      "        [-0.0041,  0.0095, -0.0053,  ..., -0.0049, -0.0177, -0.0264],\n",
      "        [ 0.0239,  0.0090,  0.0085,  ..., -0.0042, -0.0298,  0.0047]],\n",
      "       device='cuda:0'), 'model.layers.13.self_attn.v_proj.adapter.adapter_A': tensor([[-1.5868, -1.9126, -0.6360,  ...,  0.1356,  0.4378,  1.2700],\n",
      "        [-0.3647, -0.1018, -0.5935,  ..., -0.3325, -0.3156,  1.5696],\n",
      "        [ 1.1326,  0.7378,  0.1813,  ...,  1.2367, -0.7272,  0.6345],\n",
      "        ...,\n",
      "        [ 1.0992, -1.6724,  1.2510,  ...,  0.8906,  1.2003,  1.6031],\n",
      "        [ 1.3389,  0.0354, -0.0694,  ..., -0.1518,  0.3431, -1.2022],\n",
      "        [-0.3793,  1.5334, -0.1930,  ..., -2.0438, -0.1761,  1.8525]],\n",
      "       device='cuda:0'), 'model.layers.13.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.13.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0051, -0.0288,  0.0281,  ..., -0.0037,  0.0025,  0.0339],\n",
      "        [ 0.0056, -0.0199,  0.0044,  ..., -0.0014, -0.0114,  0.0034],\n",
      "        [-0.0147,  0.0120, -0.0101,  ...,  0.0110, -0.0106,  0.0017],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0134,  0.0232,  ..., -0.0233,  0.0031, -0.0098],\n",
      "        [ 0.0232,  0.0201,  0.0052,  ..., -0.0159, -0.0164, -0.0305],\n",
      "        [ 0.0630, -0.0099,  0.0173,  ..., -0.0181, -0.0287,  0.0065]],\n",
      "       device='cuda:0'), 'model.layers.13.self_attn.o_proj.adapter.adapter_A': tensor([[ 1.1073,  0.1324,  1.0418,  ...,  0.4684, -0.0427,  0.1431],\n",
      "        [ 0.9510, -0.4048,  0.5310,  ...,  0.4660, -0.1876, -0.6118],\n",
      "        [-1.1076,  0.2910,  0.9475,  ...,  0.0122,  0.5799,  2.3941],\n",
      "        ...,\n",
      "        [ 0.9321,  0.9955,  1.2413,  ...,  0.1594,  0.3972,  2.4202],\n",
      "        [ 1.0625, -0.0920, -1.0717,  ..., -1.6617, -0.1756,  1.1245],\n",
      "        [-0.8447, -2.0969, -1.6765,  ...,  1.7259,  1.9842,  0.7102]],\n",
      "       device='cuda:0'), 'model.layers.13.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.13.mlp.gate_proj.weight': tensor([[-0.0110, -0.0249,  0.0135,  ...,  0.0339,  0.0132, -0.0032],\n",
      "        [ 0.0034,  0.0012, -0.0093,  ..., -0.0186, -0.0183, -0.0405],\n",
      "        [-0.0430, -0.0231, -0.0092,  ...,  0.0055, -0.0087, -0.0064],\n",
      "        ...,\n",
      "        [ 0.0096,  0.0422,  0.0287,  ...,  0.0075, -0.0121,  0.0041],\n",
      "        [-0.0052,  0.0021, -0.0237,  ..., -0.0058, -0.0231,  0.0131],\n",
      "        [ 0.0457, -0.0119,  0.0303,  ...,  0.0217,  0.0439, -0.0317]],\n",
      "       device='cuda:0'), 'model.layers.13.mlp.up_proj.pre_layer.weight': tensor([[-8.3618e-03,  1.1353e-02,  4.1016e-02,  ..., -1.8677e-02,\n",
      "          2.2339e-02,  1.2878e-02],\n",
      "        [-4.8340e-02,  7.2937e-03, -5.7373e-03,  ...,  3.1494e-02,\n",
      "         -1.2451e-02,  3.3264e-03],\n",
      "        [-1.1658e-02, -6.4697e-03, -2.3804e-03,  ..., -1.8555e-02,\n",
      "          8.9722e-03,  2.0386e-02],\n",
      "        ...,\n",
      "        [-5.4321e-03,  2.9144e-03, -1.0742e-02,  ..., -1.2589e-03,\n",
      "         -1.7334e-02,  1.9531e-02],\n",
      "        [ 1.0193e-02, -5.9605e-05,  6.3477e-03,  ...,  3.8757e-03,\n",
      "          7.8125e-03, -2.1118e-02],\n",
      "        [-5.5237e-03, -2.7222e-02, -2.1515e-03,  ..., -1.7822e-02,\n",
      "          6.9885e-03,  4.7874e-04]], device='cuda:0'), 'model.layers.13.mlp.up_proj.adapter.adapter_A': tensor([[ 1.1727,  1.9888,  1.4140,  ...,  0.4903,  0.5757, -1.9099],\n",
      "        [-1.5788,  0.5213, -1.3473,  ..., -1.9012, -0.0749,  1.7434],\n",
      "        [ 2.4264, -0.2125,  1.5086,  ..., -0.5714, -0.0644, -0.8077],\n",
      "        ...,\n",
      "        [ 0.2798,  0.1535, -0.0288,  ..., -1.3063,  0.5100, -2.1139],\n",
      "        [-0.1578,  0.9295, -0.3800,  ..., -0.0521, -1.0483, -0.8369],\n",
      "        [-1.3660, -1.3785,  0.0495,  ...,  0.1012,  0.7857,  0.2670]],\n",
      "       device='cuda:0'), 'model.layers.13.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.13.mlp.down_proj.pre_layer.weight': tensor([[-0.0122,  0.0308, -0.0086,  ...,  0.0096, -0.0039, -0.0080],\n",
      "        [-0.0033, -0.0111,  0.0037,  ..., -0.0247,  0.0074, -0.0201],\n",
      "        [ 0.0034,  0.0049, -0.0210,  ..., -0.0134, -0.0136, -0.0132],\n",
      "        ...,\n",
      "        [-0.0366, -0.0161,  0.0016,  ..., -0.0070,  0.0099,  0.0128],\n",
      "        [-0.0165, -0.0117, -0.0010,  ..., -0.0176, -0.0242, -0.0082],\n",
      "        [-0.0117,  0.0242,  0.0026,  ...,  0.0121, -0.0015,  0.0474]],\n",
      "       device='cuda:0'), 'model.layers.13.mlp.down_proj.adapter.adapter_A': tensor([[ 0.4466, -1.5316,  0.5495,  ...,  0.2919,  0.8112,  0.3852],\n",
      "        [ 1.6912,  0.8012,  0.1618,  ...,  1.3981,  1.2386, -2.7807],\n",
      "        [-1.0317, -0.6401, -0.9998,  ..., -1.5115,  0.7048, -1.0014],\n",
      "        ...,\n",
      "        [ 0.5377,  1.7475, -0.9606,  ..., -1.6899,  0.6179, -0.5883],\n",
      "        [ 0.2659,  0.5421, -0.5455,  ...,  0.1782, -0.1828, -0.7671],\n",
      "        [-0.3387,  0.2973,  0.0589,  ...,  1.3774, -1.4393,  0.2114]],\n",
      "       device='cuda:0'), 'model.layers.13.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.13.input_layernorm.weight': tensor([0.5938, 0.4824, 0.5508,  ..., 0.5039, 0.4824, 0.4668], device='cuda:0'), 'model.layers.13.post_attention_layernorm.weight': tensor([0.4902, 0.4863, 0.3594,  ..., 0.4805, 0.4805, 0.4883], device='cuda:0'), 'model.layers.14.self_attn.q_proj.pre_layer.weight': tensor([[-0.0002,  0.0225,  0.0082,  ...,  0.0339,  0.0137,  0.0076],\n",
      "        [-0.0066,  0.0081,  0.0317,  ..., -0.0099, -0.0188, -0.0130],\n",
      "        [ 0.0022,  0.0070,  0.0212,  ...,  0.0251,  0.0209,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0195, -0.0090,  0.0123,  ..., -0.0034, -0.0008, -0.0015],\n",
      "        [ 0.0220,  0.0132, -0.0061,  ...,  0.0327, -0.0388,  0.0144],\n",
      "        [ 0.0121,  0.0139, -0.0286,  ...,  0.0126,  0.0077, -0.0391]],\n",
      "       device='cuda:0'), 'model.layers.14.self_attn.q_proj.adapter.adapter_A': tensor([[-1.0840,  0.6322, -1.7540,  ...,  0.1676, -0.4407, -0.1963],\n",
      "        [ 0.9564, -1.8673,  0.8647,  ..., -1.5837, -0.2425,  0.0960],\n",
      "        [ 1.7857,  2.1700,  1.2662,  ...,  0.4080, -0.8012,  0.8171],\n",
      "        ...,\n",
      "        [-0.4550, -0.6499,  1.1930,  ..., -0.2113,  1.5432,  0.9937],\n",
      "        [ 0.6175, -0.3070,  2.1435,  ..., -0.8690, -1.6870, -0.5366],\n",
      "        [ 0.0703, -0.6124, -0.7188,  ..., -0.0438, -0.0635, -0.0064]],\n",
      "       device='cuda:0'), 'model.layers.14.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.14.self_attn.k_proj.pre_layer.weight': tensor([[ 0.0014,  0.0195,  0.0124,  ...,  0.0070, -0.0247,  0.0011],\n",
      "        [-0.0104,  0.0220,  0.0449,  ...,  0.0058, -0.0065,  0.0060],\n",
      "        [ 0.0181, -0.0320, -0.0540,  ..., -0.0287, -0.0115,  0.0108],\n",
      "        ...,\n",
      "        [-0.0315, -0.0215,  0.0019,  ...,  0.0236,  0.0007, -0.0214],\n",
      "        [-0.0079, -0.0175, -0.0311,  ..., -0.0067,  0.0059,  0.0070],\n",
      "        [-0.0004,  0.0045,  0.0149,  ..., -0.0094,  0.0098, -0.0103]],\n",
      "       device='cuda:0'), 'model.layers.14.self_attn.k_proj.adapter.adapter_A': tensor([[ 1.1703, -1.0168, -0.9237,  ...,  1.0640, -1.4363, -0.6773],\n",
      "        [ 0.5953,  0.3486,  0.4180,  ...,  0.8665, -0.6080, -1.4341],\n",
      "        [-1.4642,  0.1756,  0.4313,  ...,  0.2695, -0.1313,  1.0439],\n",
      "        ...,\n",
      "        [-0.7256, -1.1491, -0.3135,  ...,  0.1616, -0.7456,  1.0661],\n",
      "        [-0.4054, -0.5894, -0.1098,  ..., -0.6055, -1.2916,  0.4873],\n",
      "        [ 0.1874,  1.4121,  1.3493,  ..., -1.8381,  1.6125,  0.2253]],\n",
      "       device='cuda:0'), 'model.layers.14.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.14.self_attn.v_proj.pre_layer.weight': tensor([[-0.0129, -0.0693, -0.0006,  ...,  0.0244,  0.0100, -0.0198],\n",
      "        [ 0.0298,  0.0203, -0.0184,  ..., -0.0060,  0.0258, -0.0175],\n",
      "        [ 0.0266, -0.0308,  0.0315,  ...,  0.0127, -0.0160, -0.0415],\n",
      "        ...,\n",
      "        [-0.0082,  0.0058,  0.0938,  ...,  0.0141,  0.0149,  0.0109],\n",
      "        [-0.0220,  0.0031, -0.1367,  ..., -0.0295, -0.0308, -0.0164],\n",
      "        [-0.0015,  0.0019,  0.1035,  ..., -0.0236, -0.0232,  0.0203]],\n",
      "       device='cuda:0'), 'model.layers.14.self_attn.v_proj.adapter.adapter_A': tensor([[ 1.8103, -0.8755,  1.3239,  ..., -0.0881, -0.4290,  0.6460],\n",
      "        [ 1.6830,  0.4722, -1.3198,  ..., -0.8160, -0.2607,  0.3420],\n",
      "        [-0.8777, -1.7750, -0.3605,  ...,  1.0585, -0.3393,  0.1279],\n",
      "        ...,\n",
      "        [ 0.8006, -0.5685,  0.3773,  ..., -1.0086,  0.0562,  0.1997],\n",
      "        [ 0.4597, -0.1895, -0.3012,  ..., -0.1420,  1.6399,  0.3360],\n",
      "        [-0.4052, -0.7072,  0.8243,  ...,  0.4682,  0.0437, -1.1089]],\n",
      "       device='cuda:0'), 'model.layers.14.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.14.self_attn.o_proj.pre_layer.weight': tensor([[ 1.5991e-02, -1.1658e-02,  1.1841e-02,  ...,  3.3855e-05,\n",
      "          9.1171e-04, -7.8125e-03],\n",
      "        [ 1.0071e-02,  6.6833e-03,  1.5869e-02,  ...,  1.7334e-02,\n",
      "          9.4604e-03, -1.9531e-02],\n",
      "        [-3.8757e-03,  1.6479e-03,  1.3733e-02,  ...,  2.0996e-02,\n",
      "          1.5869e-02, -7.1716e-03],\n",
      "        ...,\n",
      "        [-3.3691e-02,  3.2959e-03, -7.8735e-03,  ...,  4.9561e-02,\n",
      "          4.9805e-02, -1.8188e-02],\n",
      "        [ 1.0498e-02, -4.1992e-02, -5.5542e-03,  ...,  2.6367e-02,\n",
      "         -3.1738e-02,  6.1340e-03],\n",
      "        [ 7.4158e-03, -2.0996e-02, -1.4038e-02,  ..., -4.4250e-03,\n",
      "         -1.0986e-02, -1.9775e-02]], device='cuda:0'), 'model.layers.14.self_attn.o_proj.adapter.adapter_A': tensor([[ 0.6950, -0.4113,  1.4033,  ..., -0.0156, -0.7565,  1.2561],\n",
      "        [ 0.6944, -0.3602,  1.0553,  ...,  0.1025,  1.1864, -0.3199],\n",
      "        [-0.2377, -1.1665,  0.2670,  ..., -3.0389, -2.3679, -0.4050],\n",
      "        ...,\n",
      "        [-0.9156,  0.9311, -0.8473,  ..., -0.4171,  0.9920, -0.5918],\n",
      "        [-1.1138,  0.5306,  0.2101,  ..., -0.0400, -0.3314, -0.2239],\n",
      "        [ 1.8560,  0.2515, -0.6771,  ...,  1.2549, -1.0733, -0.1785]],\n",
      "       device='cuda:0'), 'model.layers.14.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.14.mlp.gate_proj.weight': tensor([[ 0.0415, -0.0109, -0.0003,  ...,  0.0151,  0.0111,  0.0035],\n",
      "        [ 0.0050, -0.0109, -0.0090,  ..., -0.0148,  0.0095, -0.0171],\n",
      "        [ 0.0103, -0.0052,  0.0193,  ..., -0.0281, -0.0034,  0.0033],\n",
      "        ...,\n",
      "        [ 0.0050, -0.0208, -0.0112,  ..., -0.0342, -0.0176, -0.0376],\n",
      "        [ 0.0008, -0.0044, -0.0190,  ..., -0.0101, -0.0080, -0.0112],\n",
      "        [ 0.0053, -0.0091, -0.0262,  ..., -0.0155, -0.0140, -0.0140]],\n",
      "       device='cuda:0'), 'model.layers.14.mlp.up_proj.pre_layer.weight': tensor([[ 0.0413, -0.0128,  0.0186,  ...,  0.0072,  0.0216,  0.0140],\n",
      "        [-0.0332, -0.0035,  0.0038,  ..., -0.0376, -0.0030, -0.0093],\n",
      "        [-0.0045, -0.0155,  0.0066,  ..., -0.0120,  0.0045, -0.0145],\n",
      "        ...,\n",
      "        [ 0.0066, -0.0217,  0.0010,  ..., -0.0159, -0.0249, -0.0147],\n",
      "        [ 0.0029, -0.0010,  0.0014,  ...,  0.0260,  0.0071,  0.0187],\n",
      "        [ 0.0082,  0.0096,  0.0400,  ..., -0.0171, -0.0107, -0.0108]],\n",
      "       device='cuda:0'), 'model.layers.14.mlp.up_proj.adapter.adapter_A': tensor([[ 0.0169, -1.4524,  0.6525,  ..., -0.5204,  1.2790,  0.5107],\n",
      "        [ 0.3182,  0.0399,  1.0275,  ...,  0.3598, -0.7877,  0.4558],\n",
      "        [ 0.2611,  0.2596,  0.0226,  ..., -0.6113,  0.3923, -0.7513],\n",
      "        ...,\n",
      "        [-0.1909, -0.7609,  0.5417,  ...,  0.0957, -0.2879,  0.2489],\n",
      "        [ 0.8375,  0.5852, -0.5888,  ..., -0.2228, -0.5464, -0.2517],\n",
      "        [ 0.0628, -1.6812, -0.4505,  ...,  0.6142,  0.8241, -0.7448]],\n",
      "       device='cuda:0'), 'model.layers.14.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.14.mlp.down_proj.pre_layer.weight': tensor([[-0.0430,  0.0095, -0.0010,  ...,  0.0107,  0.0195,  0.0101],\n",
      "        [ 0.0161,  0.0093,  0.0142,  ...,  0.0053, -0.0107, -0.0123],\n",
      "        [ 0.0311,  0.0030,  0.0075,  ...,  0.0091,  0.0232, -0.0101],\n",
      "        ...,\n",
      "        [ 0.0060, -0.0310,  0.0117,  ...,  0.0043,  0.0119,  0.0247],\n",
      "        [ 0.0432,  0.0176, -0.0096,  ...,  0.0186,  0.0140,  0.0352],\n",
      "        [ 0.0203,  0.0140,  0.0080,  ...,  0.0302,  0.0356, -0.0052]],\n",
      "       device='cuda:0'), 'model.layers.14.mlp.down_proj.adapter.adapter_A': tensor([[ 1.2112,  0.9624, -0.3778,  ..., -0.8869,  0.5689, -1.6879],\n",
      "        [-0.5371, -0.3931,  1.1686,  ...,  0.5390,  0.0613, -0.6921],\n",
      "        [ 0.4123, -1.3725, -0.2907,  ..., -0.8106, -0.5384, -0.4791],\n",
      "        ...,\n",
      "        [-0.5348,  1.9087, -2.2979,  ..., -0.0273, -1.3451, -0.5852],\n",
      "        [ 0.9910,  0.2268,  2.2499,  ..., -1.2333, -1.5235,  1.8956],\n",
      "        [ 0.4684,  3.0727,  1.2281,  ..., -0.3408, -1.1704,  2.3106]],\n",
      "       device='cuda:0'), 'model.layers.14.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.14.input_layernorm.weight': tensor([0.4297, 0.3984, 0.6055,  ..., 0.4199, 0.5039, 0.3945], device='cuda:0'), 'model.layers.14.post_attention_layernorm.weight': tensor([0.5039, 0.5078, 0.4102,  ..., 0.4961, 0.4980, 0.5195], device='cuda:0'), 'model.layers.15.self_attn.q_proj.pre_layer.weight': tensor([[-0.0051, -0.0527,  0.0123,  ..., -0.0167, -0.0061,  0.0156],\n",
      "        [ 0.0036,  0.0010, -0.0227,  ...,  0.0090, -0.0043,  0.0060],\n",
      "        [ 0.0016,  0.0032, -0.0195,  ..., -0.0104,  0.0092,  0.0046],\n",
      "        ...,\n",
      "        [ 0.0074,  0.0284,  0.0289,  ...,  0.0039,  0.0170,  0.0479],\n",
      "        [ 0.0151,  0.0243, -0.0096,  ..., -0.0019,  0.0030, -0.0282],\n",
      "        [ 0.0527, -0.0175, -0.0081,  ..., -0.0601, -0.0845,  0.0277]],\n",
      "       device='cuda:0'), 'model.layers.15.self_attn.q_proj.adapter.adapter_A': tensor([[ 1.5524, -0.5863,  0.8955,  ..., -0.1851, -0.0933, -0.9220],\n",
      "        [ 0.6786,  0.8042,  1.7043,  ..., -0.0310, -1.7410, -0.6570],\n",
      "        [ 0.7027, -0.7908, -0.6486,  ...,  1.1413, -1.9044, -0.4425],\n",
      "        ...,\n",
      "        [ 0.1130, -0.1548, -1.6725,  ...,  0.8870, -0.0964, -1.9370],\n",
      "        [ 0.3782,  0.3397,  0.8696,  ...,  0.1801, -0.3992, -0.0440],\n",
      "        [-1.2767,  0.9270, -0.5191,  ...,  1.5612,  0.5371, -0.5355]],\n",
      "       device='cuda:0'), 'model.layers.15.self_attn.q_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.15.self_attn.k_proj.pre_layer.weight': tensor([[-0.0237, -0.0356, -0.0320,  ...,  0.0295, -0.0166,  0.0820],\n",
      "        [-0.0305,  0.0132,  0.0203,  ...,  0.0040,  0.0005, -0.0398],\n",
      "        [-0.0010, -0.0483, -0.0051,  ...,  0.0223, -0.0027,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0062, -0.0142,  0.0134,  ...,  0.0025, -0.0146,  0.0017],\n",
      "        [ 0.0011,  0.0028,  0.0229,  ...,  0.0042, -0.0033, -0.0018],\n",
      "        [ 0.0132,  0.0204,  0.0287,  ...,  0.0065, -0.0113,  0.0035]],\n",
      "       device='cuda:0'), 'model.layers.15.self_attn.k_proj.adapter.adapter_A': tensor([[-0.0854,  0.3940,  0.4270,  ..., -0.0475, -0.3227, -1.0524],\n",
      "        [-0.1520, -0.7295, -1.2376,  ..., -0.7385, -0.2388, -1.4413],\n",
      "        [ 1.0685, -0.1863,  1.3673,  ..., -0.4709, -2.0199,  0.9663],\n",
      "        ...,\n",
      "        [-0.1667,  1.7306,  1.6608,  ...,  1.8843,  0.5826,  0.1429],\n",
      "        [-0.8597, -0.8380,  2.0064,  ...,  1.4957, -0.2161,  1.1534],\n",
      "        [ 0.6742, -1.1879,  1.9600,  ...,  1.7726, -1.2009,  1.2620]],\n",
      "       device='cuda:0'), 'model.layers.15.self_attn.k_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.15.self_attn.v_proj.pre_layer.weight': tensor([[ 0.0283, -0.0092, -0.0027,  ...,  0.0354, -0.0327, -0.0466],\n",
      "        [ 0.0112, -0.0177, -0.0048,  ..., -0.0029,  0.0016, -0.0031],\n",
      "        [-0.0488, -0.0039,  0.0040,  ..., -0.0143,  0.0435, -0.0145],\n",
      "        ...,\n",
      "        [ 0.0086, -0.0283,  0.0164,  ..., -0.0156, -0.0103,  0.0137],\n",
      "        [ 0.0249, -0.0029, -0.0352,  ...,  0.0347,  0.0141, -0.0225],\n",
      "        [ 0.0227,  0.0183,  0.0168,  ..., -0.0093, -0.0120, -0.0070]],\n",
      "       device='cuda:0'), 'model.layers.15.self_attn.v_proj.adapter.adapter_A': tensor([[-1.1513e+00, -2.7562e-01,  4.1045e-01,  ..., -3.2334e+00,\n",
      "          1.3651e-01,  9.2989e-01],\n",
      "        [-9.4797e-01,  1.2235e-03, -7.0540e-01,  ..., -4.5817e-01,\n",
      "         -7.6429e-02,  7.9899e-01],\n",
      "        [-4.5813e-01,  6.8600e-01,  2.4394e+00,  ...,  3.7781e-01,\n",
      "          2.4924e-01, -1.4892e+00],\n",
      "        ...,\n",
      "        [ 1.0382e-01, -1.9652e+00,  3.4564e-01,  ..., -4.5521e-02,\n",
      "          1.1004e+00,  1.4293e+00],\n",
      "        [-1.1590e+00, -3.8831e-01,  6.0211e-01,  ..., -1.1204e+00,\n",
      "         -1.0757e+00, -1.5820e+00],\n",
      "        [-6.6555e-01, -4.3907e-01,  1.2794e+00,  ..., -8.6533e-01,\n",
      "         -1.9320e+00,  2.6401e+00]], device='cuda:0'), 'model.layers.15.self_attn.v_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.15.self_attn.o_proj.pre_layer.weight': tensor([[ 0.0135, -0.0101, -0.0161,  ..., -0.0115,  0.0298,  0.0033],\n",
      "        [ 0.0194,  0.0026, -0.0009,  ...,  0.0220,  0.0266,  0.0256],\n",
      "        [-0.0061,  0.0175, -0.0214,  ...,  0.0298, -0.0815, -0.0576],\n",
      "        ...,\n",
      "        [ 0.0143, -0.0120,  0.0066,  ...,  0.0154,  0.0079, -0.0032],\n",
      "        [ 0.0146,  0.0206,  0.0284,  ..., -0.0287, -0.0010,  0.0096],\n",
      "        [-0.0062, -0.0231, -0.0013,  ...,  0.0021,  0.0146, -0.0205]],\n",
      "       device='cuda:0'), 'model.layers.15.self_attn.o_proj.adapter.adapter_A': tensor([[-2.1144,  0.9244, -0.7575,  ..., -0.1989,  0.0923, -0.7565],\n",
      "        [-0.2547,  0.4795, -0.5315,  ..., -0.1380, -1.3388, -1.2024],\n",
      "        [-0.6986, -0.8232,  0.8400,  ..., -0.6119, -1.7736,  1.2706],\n",
      "        ...,\n",
      "        [-0.6870,  0.5014, -0.1203,  ...,  1.4308,  0.9540,  0.6788],\n",
      "        [-1.0839, -0.5811, -1.8165,  ...,  1.4622,  0.3482, -0.5677],\n",
      "        [-1.1007,  0.0312, -1.5887,  ..., -0.4026,  1.2694, -1.7699]],\n",
      "       device='cuda:0'), 'model.layers.15.self_attn.o_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.15.mlp.gate_proj.weight': tensor([[ 0.0083,  0.0311, -0.0153,  ..., -0.0156, -0.0120,  0.0211],\n",
      "        [ 0.0178, -0.0124, -0.0054,  ..., -0.0070, -0.0030, -0.0187],\n",
      "        [ 0.0034, -0.0120,  0.0131,  ...,  0.0260,  0.0159,  0.0027],\n",
      "        ...,\n",
      "        [ 0.0128,  0.0101, -0.0085,  ..., -0.0171, -0.0168,  0.0049],\n",
      "        [ 0.0231,  0.0023,  0.0349,  ..., -0.0020,  0.0036, -0.0022],\n",
      "        [-0.0092, -0.0121,  0.0299,  ...,  0.0103, -0.0115, -0.0186]],\n",
      "       device='cuda:0'), 'model.layers.15.mlp.up_proj.pre_layer.weight': tensor([[-0.0072, -0.0129, -0.0186,  ..., -0.0303,  0.0135,  0.0008],\n",
      "        [-0.0023, -0.0280,  0.0198,  ...,  0.0225, -0.0159, -0.0070],\n",
      "        [ 0.0011, -0.0001,  0.0159,  ..., -0.0400, -0.0171,  0.0092],\n",
      "        ...,\n",
      "        [-0.0039, -0.0216,  0.0054,  ...,  0.0011, -0.0044,  0.0337],\n",
      "        [ 0.0130,  0.0106,  0.0178,  ..., -0.0011, -0.0227,  0.0021],\n",
      "        [-0.0537,  0.0288,  0.0063,  ..., -0.0014, -0.0265,  0.0040]],\n",
      "       device='cuda:0'), 'model.layers.15.mlp.up_proj.adapter.adapter_A': tensor([[-0.7891, -0.0570,  1.2974,  ...,  2.2521, -1.1660, -0.8754],\n",
      "        [-2.1281, -1.1276,  1.1005,  ..., -0.1185, -2.2419, -0.1839],\n",
      "        [-0.6148, -2.4198,  2.3392,  ..., -0.0173, -1.8416,  0.7332],\n",
      "        ...,\n",
      "        [-0.2412,  0.6087,  0.1711,  ..., -0.8087, -0.0752, -0.5703],\n",
      "        [-1.4390,  0.1143,  2.5779,  ..., -0.9847,  0.7407,  0.0349],\n",
      "        [ 0.3017, -1.5845,  0.2909,  ...,  1.1780, -1.5072, -0.5613]],\n",
      "       device='cuda:0'), 'model.layers.15.mlp.up_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.15.mlp.down_proj.pre_layer.weight': tensor([[ 0.0287, -0.0024, -0.0045,  ..., -0.0267,  0.0254, -0.0027],\n",
      "        [-0.0288,  0.0078,  0.0109,  ..., -0.0082, -0.0022, -0.0027],\n",
      "        [-0.0017, -0.0120, -0.0239,  ..., -0.0082,  0.0017,  0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0005,  0.0234,  ..., -0.0105,  0.0095,  0.0266],\n",
      "        [-0.0032,  0.0006, -0.0170,  ..., -0.0082,  0.0094, -0.0188],\n",
      "        [ 0.0186,  0.0155,  0.0076,  ..., -0.0156,  0.0056,  0.0452]],\n",
      "       device='cuda:0'), 'model.layers.15.mlp.down_proj.adapter.adapter_A': tensor([[ 0.6343,  1.1301, -1.7284,  ...,  0.4579,  1.4084, -0.1542],\n",
      "        [-0.4717,  0.3839, -1.3288,  ..., -0.0289,  1.9145, -0.5297],\n",
      "        [ 0.2375,  0.0472, -0.1858,  ...,  0.9886,  2.3549, -0.5572],\n",
      "        ...,\n",
      "        [-0.4652,  1.0901, -0.1434,  ...,  1.1520,  0.7743,  0.8599],\n",
      "        [ 0.5747, -0.5778,  0.3728,  ..., -0.0397, -0.1119,  1.5873],\n",
      "        [ 0.8910, -1.5723, -0.5864,  ..., -0.7938, -0.0463, -0.6919]],\n",
      "       device='cuda:0'), 'model.layers.15.mlp.down_proj.adapter.adapter_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'model.layers.15.input_layernorm.weight': tensor([0.4434, 0.4395, 0.8203,  ..., 0.4492, 0.5117, 0.4180], device='cuda:0'), 'model.layers.15.post_attention_layernorm.weight': tensor([0.5195, 0.5039, 0.4551,  ..., 0.5273, 0.5000, 0.5234], device='cuda:0'), 'model.norm.weight': tensor([2.4531, 2.2500, 1.5391,  ..., 2.5156, 2.4062, 2.5000], device='cuda:0'), 'lm_head.weight': tensor([[ 3.1281e-03,  1.7822e-02,  2.0996e-02,  ..., -5.2185e-03,\n",
      "         -4.1992e-02, -3.3447e-02],\n",
      "        [ 2.3682e-02, -2.2949e-02,  1.9897e-02,  ..., -9.4604e-03,\n",
      "         -2.2125e-03, -3.9551e-02],\n",
      "        [ 1.4465e-02,  1.0559e-02,  9.8267e-03,  ...,  6.8359e-03,\n",
      "         -1.1597e-02,  5.7983e-03],\n",
      "        ...,\n",
      "        [-1.0580e-06,  1.0620e-02, -1.9043e-02,  ...,  1.3885e-03,\n",
      "         -1.7700e-03,  9.7046e-03],\n",
      "        [-1.3635e-06,  1.0620e-02, -1.9043e-02,  ...,  1.3885e-03,\n",
      "         -1.7700e-03,  9.7046e-03],\n",
      "        [-1.1921e-06,  1.0620e-02, -1.9043e-02,  ...,  1.3885e-03,\n",
      "         -1.7700e-03,  9.7046e-03]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16],\n",
      "         [17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]])\n",
      "Shape: torch.Size([2, 3, 4])\n",
      "\n",
      "Reshaped tensor:\n",
      "tensor([[ 1,  2,  3,  4, 13, 14, 15, 16],\n",
      "        [ 5,  6,  7,  8, 17, 18, 19, 20],\n",
      "        [ 9, 10, 11, 12, 21, 22, 23, 24]])\n",
      "Shape: torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#    (2, 3, 4)    1  24\n",
    "tensor = torch.arange(1, 2 * 3 * 4 + 1).reshape(2, 3, 4)\n",
    "\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "print(\"Shape:\", tensor.shape)\n",
    "\n",
    "#     (3, 2 * 4)  (3, 8)\n",
    "reshaped_tensor = tensor.permute(1, 0, 2).reshape(3, 2 * 4)\n",
    "\n",
    "print(\"\\nReshaped tensor:\")\n",
    "print(reshaped_tensor)\n",
    "print(\"Shape:\", reshaped_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrad_norms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1485\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1481\u001b[0m     wl\u001b[38;5;241m.\u001b[39m_get_logger()\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in wandb.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# Need to build delay into this sentry capture because our exit hooks\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;66;03m# mess with sentry's ability to send out errors before the program ends.\u001b[39;00m\n\u001b[0;32m-> 1485\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/analytics/sentry.py:156\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception(exc)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# but hopefully it's not too bad\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1471\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1468\u001b[0m         _monkeypatch_tensorboard()\n\u001b[1;32m   1469\u001b[0m         init_telemetry\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mtensorboard_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wl:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:789\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self, settings, config)\u001b[0m\n\u001b[1;32m    787\u001b[0m     service \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl\u001b[38;5;241m.\u001b[39mensure_service()\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msending inform_init request\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 789\u001b[0m     \u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minform_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m     service \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py:144\u001b[0m, in \u001b[0;36mServiceConnection.inform_init\u001b[0;34m(self, settings, run_id)\u001b[0m\n\u001b[1;32m    142\u001b[0m request\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mCopyFrom(settings)\n\u001b[1;32m    143\u001b[0m request\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mstream_id \u001b[38;5;241m=\u001b[39m run_id\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43minform_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:212\u001b[0m, in \u001b[0;36mSockClient.send\u001b[0;34m(self, inform_init, inform_start, inform_attach, inform_finish, inform_teardown)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munmatched\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init('grad_norms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weave.trace.weave_client.WeaveClient at 0x7ec960dcefe0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "weave.init('grad_norms') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Start a new wandb run to track this script.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Set the wandb entity where your project will be logged (generally your team name).\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy-awesome-team-name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Set the wandb project where this run will be logged.\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy-awesome-project\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Track hyperparameters and run metadata.\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchitecture\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCNN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCIFAR-100\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Simulate training.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1485\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1481\u001b[0m     wl\u001b[38;5;241m.\u001b[39m_get_logger()\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in wandb.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# Need to build delay into this sentry capture because our exit hooks\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;66;03m# mess with sentry's ability to send out errors before the program ends.\u001b[39;00m\n\u001b[0;32m-> 1485\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/analytics/sentry.py:156\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception(exc)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# but hopefully it's not too bad\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1471\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1468\u001b[0m         _monkeypatch_tensorboard()\n\u001b[1;32m   1469\u001b[0m         init_telemetry\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mtensorboard_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wl:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:789\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self, settings, config)\u001b[0m\n\u001b[1;32m    787\u001b[0m     service \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl\u001b[38;5;241m.\u001b[39mensure_service()\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msending inform_init request\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 789\u001b[0m     \u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minform_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m     service \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py:144\u001b[0m, in \u001b[0;36mServiceConnection.inform_init\u001b[0;34m(self, settings, run_id)\u001b[0m\n\u001b[1;32m    142\u001b[0m request\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mCopyFrom(settings)\n\u001b[1;32m    143\u001b[0m request\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mstream_id \u001b[38;5;241m=\u001b[39m run_id\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43minform_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:212\u001b[0m, in \u001b[0;36mSockClient.send\u001b[0;34m(self, inform_init, inform_start, inform_attach, inform_finish, inform_teardown)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munmatched\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"my-awesome-team-name\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"my-awesome-project\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"CIFAR-100\",\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Simulate training.\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
    "    loss = 2**-epoch + random.random() / epoch + offset\n",
    "\n",
    "    # Log metrics to wandb.\n",
    "    run.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# Finish the run and upload any remaining data.\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm tensor(127.9937)\n",
      "Kaiming tensor(1.6211)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import init\n",
    "import math\n",
    "\n",
    "rows, cols = 8, 2048\n",
    "\n",
    "U = torch.randn(rows, cols)\n",
    "\n",
    "V = torch.empty(rows, cols)\n",
    "init.kaiming_uniform_(V, a=math.sqrt(5))\n",
    "\n",
    "# print(\" U ( ):\")\n",
    "# print(U)\n",
    "\n",
    "# print(\"\\n V (Kaiming Uniform):\")\n",
    "# print(V)\n",
    "\n",
    "print('Norm', torch.norm(U))\n",
    "print('Kaiming', torch.norm(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
