{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 13:11:00.759581: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-15 13:11:00.774162: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739614260.791204 3924877 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739614260.796231 3924877 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-15 13:11:00.814914: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from lib import Datasets\n",
    "from datasets import load_dataset\n",
    "import copy\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Sequence, List, Literal\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -100\n",
    "\n",
    "# PROMPT = (\n",
    "#         \"Below is an instruction that describes a task. \"\n",
    "#         \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "#         \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "#     )\n",
    "\n",
    "PROMPT = (\n",
    "        \"### Task:\\n{instruction}\\n\\n### Solution:\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1, target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'down_proj'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# name = \"meta-llama/Llama-2-7b-hf\"\n",
    "# name = \"distilgpt2\"\n",
    "name = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForCausalLM.from_pretrained(name, torch_dtype=torch.float16, device_map='balanced')\n",
    "\n",
    "# model = get_peft_model(model, peft_config)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --data_path meta-math/MetaMathQA \\\n",
    "# --dataset_field query response \\\n",
    "    \n",
    "# python -u train_model.py \\\n",
    "#     --model_name_or_path $BASE_MODEL \\\n",
    "#     --output_dir $OUTPUT \\\n",
    "#     --corda_mode False \\\n",
    "#     --lora_r 128 \\\n",
    "#     --data_path meta-math/MetaMathQA \\\n",
    "#     --dataset_split \"train[:100000]\" \\\n",
    "#     --dataset_field query response \\\n",
    "#     --num_train_epochs 1 \\\n",
    "#     --per_device_train_batch_size 1 \\\n",
    "#     --gradient_accumulation_steps 128 \\\n",
    "#     --save_strategy \"steps\" \\\n",
    "#     --save_steps 100 \\\n",
    "#     --save_total_limit 1 \\\n",
    "#     --learning_rate 2e-5 \\\n",
    "#     --weight_decay 0. \\\n",
    "#     --warmup_ratio 0.03 \\\n",
    "#     --lr_scheduler_type \"cosine\" \\\n",
    "#     --logging_steps 1 \\\n",
    "#     --bf16 True \\\n",
    "#     --tf32 True \\\n",
    "#     --report_to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "    \"\"\"Tokenize a list of strings.\"\"\"\n",
    "    tokenized_list = [\n",
    "        tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            # padding='max_length',\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "        for text in strings\n",
    "    ]\n",
    "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "    input_ids_lens = labels_lens = [\n",
    "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "    ]\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=labels,\n",
    "        input_ids_lens=input_ids_lens,\n",
    "        labels_lens=labels_lens,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    sources: Sequence[str],\n",
    "    targets: Sequence[str],\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    ") -> Dict:\n",
    "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
    "    examples = [s + t for s, t in zip(sources, targets)]\n",
    "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "    input_ids = examples_tokenized[\"input_ids\"]\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "    \n",
    "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "        # print(len(label), source_len)\n",
    "        # label[:source_len] = IGNORE_INDEX\n",
    "        a = 5\n",
    "        \n",
    "    return dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "def train_tokenize_function(examples, tokenizer, query, response):\n",
    "    sources = [PROMPT.format_map(dict(instruction=instruction)) for instruction in examples[query]]\n",
    "    targets = [f\"{output}{tokenizer.eos_token}\" for output in examples[response]]\n",
    "    data_dict = preprocess(sources, targets, tokenizer)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9530cf4725e40ba85bb2adabf1881b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        name,\n",
    "        model_max_length=1024,\n",
    "        padding_side=\"right\",\n",
    "        use_fast=True,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "raw_train_datasets = load_dataset(\"meta-math/MetaMathQA\", split='train[:10]')\n",
    "\n",
    "train_dataset = raw_train_datasets.map(\n",
    "        train_tokenize_function,\n",
    "        batched=True,\n",
    "        batch_size=3000,\n",
    "        num_proc=10, # 32\n",
    "        remove_columns=raw_train_datasets.column_names,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on train dataset\",\n",
    "        fn_kwargs={\"tokenizer\": tokenizer, \"query\": \"query\", \"response\": \"response\"}\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = [torch.tensor(x) for x in input_ids]\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = [torch.tensor(x) for x in labels]\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./logs/abrakkk',          \n",
    "    num_train_epochs=1,                   \n",
    "    per_device_train_batch_size=1,       \n",
    "    per_device_eval_batch_size=1,       \n",
    "    gradient_accumulation_steps=1,\n",
    "    eval_accumulation_steps=10,\n",
    "    learning_rate=2e-5,               \n",
    "    weight_decay=0.0,                   \n",
    "    warmup_ratio=0.03,                   \n",
    "    lr_scheduler_type=\"cosine\",          \n",
    "    logging_steps=1,                       \n",
    "    fp16=True,\n",
    "    report_to=\"tensorboard\",              \n",
    "    logging_dir='./logs/abra',                 \n",
    "    # use_cpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "data_module = dict(train_dataset=train_dataset, data_collator=data_collator)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "metric = load('accuracy')\n",
    "\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "# Load the accuracy metric\n",
    "metric = load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    predictions = np.argmax(predictions, axis=2).flatten()\n",
    "    \n",
    "    labels = labels.flatten()\n",
    "    \n",
    "    mask = labels != -100\n",
    "    \n",
    "    return metric.compute(predictions=predictions[mask], references=labels[mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(model=model, tokenizer=tokenizer, args=script_args, **data_module)\n",
    "\n",
    "# trainer = Trainer(model=model, args=training_args, **data_module)\n",
    "\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, compute_metrics=compute_metrics, **data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_dataset': Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 10\n",
      "}), 'data_collator': DataCollatorForSupervisedDataset(tokenizer=PreTrainedTokenizerFast(name_or_path='meta-llama/Llama-3.2-1B', vocab_size=128000, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>', 'pad_token': '<|end_of_text|>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128004: AddedToken(\"<|finetune_right_pad_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128005: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128008: AddedToken(\"<|eom_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128010: AddedToken(\"<|python_tag|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128011: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128012: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128013: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128014: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128015: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128016: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128017: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128018: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128019: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128020: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128021: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128022: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128023: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128024: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128025: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128026: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128027: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128028: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128029: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128030: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128031: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128032: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128033: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128034: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128035: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128036: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128037: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128038: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128039: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128040: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128041: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128042: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128043: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128044: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128045: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128046: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128047: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128048: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128049: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128050: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128051: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128052: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128053: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128054: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128055: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128056: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128057: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128058: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128059: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128060: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128061: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128062: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128063: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128064: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128065: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128066: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128067: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128068: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128069: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128070: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128071: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128072: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128073: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128074: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128075: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128076: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128077: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128078: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128079: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128080: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128081: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128082: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128083: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128084: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128085: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128086: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128087: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128088: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128089: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128090: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128091: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128092: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128093: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128094: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128095: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128096: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128097: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128098: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128099: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128100: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128101: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128102: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128103: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128104: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128105: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128106: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128107: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128108: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128109: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128110: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128111: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128112: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128113: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128114: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128115: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128116: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128117: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128118: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128119: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128120: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128121: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128122: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128123: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128124: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128125: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128126: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128127: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128128: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128129: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128130: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128131: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128132: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128133: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128134: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128135: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128136: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128137: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128138: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128139: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128140: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128141: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128142: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128143: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128144: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128145: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128146: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128147: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128148: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128149: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128150: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128151: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128152: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128153: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128154: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128155: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128156: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128157: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128158: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128159: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128160: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128161: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128162: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128163: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128164: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128165: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128166: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128167: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128168: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128169: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128170: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128171: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128172: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128173: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128174: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128175: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128176: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128177: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128178: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128179: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128180: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128181: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128182: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128183: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128184: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128185: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128186: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128187: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128188: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128189: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128190: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128191: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128192: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128193: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128194: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128195: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128196: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128197: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128198: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128199: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128200: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128201: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128202: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128203: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128204: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128205: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128206: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128207: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128208: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128209: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128210: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128211: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128212: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128213: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128214: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128215: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128216: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128217: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128218: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128219: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128220: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128221: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128222: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128223: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128224: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128225: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128226: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128227: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128228: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128229: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128230: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128231: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128232: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128233: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128234: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128235: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128236: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128237: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128238: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128239: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128240: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128241: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128242: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128243: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128244: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128245: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128246: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128247: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128248: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128249: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128250: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128251: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128252: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128253: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128254: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128255: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "))}\n"
     ]
    }
   ],
   "source": [
    "print(data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# # pl = pipeline(\n",
    "# #     \"text-generation\",\n",
    "# #     model=model,\n",
    "# #     tokenizer=tokenizer,\n",
    "# #     torch_dtype=torch.float16\n",
    "# # )\n",
    "\n",
    "# # with torch.inference_mode(), torch.cuda.amp.autocast():\n",
    "# #     print(pl('Hello ', max_new_tokens=16,))\n",
    "\n",
    "# pl = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     torch_dtype=torch.float16\n",
    "# )\n",
    "\n",
    "# with torch.inference_mode(), torch.cuda.amp.autocast():\n",
    "#     print(pl('Hello ', max_new_tokens=16, do_sample=False, temperature=None, top_p=None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_model_preparation_time': 0.0006, 'eval_accuracy': 0.0, 'eval_runtime': 35.5647, 'eval_samples_per_second': 0.281, 'eval_steps_per_second': 0.281}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "# model.eval()\n",
    "# model.config.use_cache = True\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate(eval_dataset=trainer.train_dataset)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128000, 14711, 5546, 512, 6600, 47383, 323, 13142, 527, 19301, 5219, 389, 279, 6485, 11277, 13, 13142, 41011, 279, 1486, 400, 16, 10, 17, 72, 13244, 2895, 47383, 41011, 400, 12, 16, 21905, 13244, 2650, 3117, 10980, 527, 2895, 47383, 323, 13142, 596, 3585, 1980, 14711, 12761, 75145, 6138, 1990, 1403, 3585, 5035, 87, 62, 16, 7509, 62, 16, 15437, 323, 5035, 87, 62, 17, 7509, 62, 17, 15437, 304, 279, 6485, 11277, 374, 2728, 555, 279, 15150, 59060, 27986, 97165, 87, 62, 17, 6695, 62, 16, 30876, 17, 13666, 88, 62, 17, 12303, 62, 16, 30876, 17, 32816, 627, 644, 420, 1162, 11, 13142, 596, 1486, 374, 5035, 16, 11, 17, 15437, 323, 2895, 47383, 596, 1486, 374, 400, 4172, 16, 11, 16, 15437, 627, 4516, 279, 6138, 1990, 872, 3585, 374, 59060, 27986, 90, 56034, 16, 52456, 16, 97959, 17, 10, 1209, 16, 52456, 17, 97959, 17, 92, 35533, 27986, 90, 4172, 17, 30876, 17, 10, 4172, 16, 30876, 17, 92, 35533, 27986, 90, 19, 10, 16, 92, 35533, 27986, 90, 20, 32816, 627, 55915, 11, 2895, 47383, 323, 13142, 596, 3585, 527, 59060, 80175, 36802, 27986, 90, 20, 3500, 3, 8316, 10980, 627, 791, 4320, 374, 25, 1144, 27986, 90, 20, 92, 128001], [128000, 14711, 5546, 512, 3923, 374, 279, 2860, 2853, 315, 23395, 7241, 369, 682, 59139, 4311, 389, 279, 9141, 2128, 11, 13126, 430, 1855, 2851, 7612, 264, 400, 914, 37212, 11, 264, 400, 868, 13, 508, 6857, 315, 36876, 11, 323, 264, 6857, 315, 40086, 33705, 520, 400, 21, 13, 1490, 1980, 14711, 12761, 25, 4959, 2851, 7612, 264, 400, 914, 37212, 11, 264, 400, 868, 13, 508, 6857, 315, 36876, 11, 323, 264, 6857, 315, 40086, 33705, 520, 400, 21, 13, 1490, 627, 4516, 279, 2860, 2853, 369, 1855, 2851, 374, 400, 914, 489, 400, 868, 13, 508, 489, 400, 21, 13, 1490, 284, 400, 2618, 627, 12834, 1070, 527, 59139, 4311, 389, 279, 9141, 2128, 11, 279, 2860, 2853, 369, 682, 315, 1124, 374, 220, 845, 353, 400, 2618, 284, 400, 23644, 627, 827, 220, 23644, 198, 791, 4320, 374, 25, 220, 23644, 128001], [128000, 14711, 5546, 512, 18674, 3427, 41778, 220, 717, 48669, 369, 813, 13219, 596, 15553, 13, 9641, 1101, 41778, 220, 19, 48669, 11, 719, 30912, 865, 1418, 8748, 369, 279, 4717, 311, 1212, 13, 2684, 527, 220, 868, 48669, 2163, 13, 3639, 374, 279, 907, 315, 9987, 3977, 865, 1980, 14711, 12761, 25, 1271, 11886, 420, 3575, 11, 584, 1205, 311, 8417, 279, 907, 315, 865, 11, 902, 11105, 279, 1396, 315, 48669, 9641, 30912, 1418, 8748, 369, 279, 4717, 311, 1212, 627, 10267, 596, 1464, 1523, 279, 2038, 2728, 512, 2903, 315, 48669, 41778, 555, 18842, 25, 220, 717, 198, 2903, 315, 48669, 41778, 555, 9641, 25, 220, 19, 198, 2903, 315, 48669, 2163, 25, 220, 868, 198, 1687, 649, 743, 709, 279, 24524, 439, 11263, 512, 2903, 315, 48669, 41778, 555, 18842, 489, 5742, 315, 48669, 41778, 555, 9641, 482, 5742, 315, 48669, 35661, 555, 9641, 284, 5742, 315, 48669, 2163, 198, 717, 489, 220, 19, 482, 865, 284, 220, 868, 198, 10267, 596, 40821, 323, 11886, 369, 865, 512, 845, 482, 865, 284, 220, 868, 198, 1271, 43223, 865, 11, 584, 33356, 220, 845, 505, 2225, 11314, 315, 279, 24524, 512, 845, 482, 865, 482, 220, 845, 284, 220, 868, 482, 220, 845, 198, 6695, 284, 482, 16, 198, 24901, 11, 584, 31370, 2225, 11314, 315, 279, 24524, 555, 482, 16, 311, 11886, 369, 865, 512, 87, 284, 220, 16, 198, 791, 907, 315, 865, 374, 220, 16, 627, 827, 220, 16, 198, 791, 4320, 374, 25, 220, 16, 128001], [128000, 14711, 5546, 512, 12281, 400, 4645, 1721, 62, 18, 3, 311, 264, 2385, 220, 605, 7698, 382, 14711, 12761, 22444, 4645, 1721, 62, 18, 284, 220, 16, 1144, 51953, 220, 18, 61, 19, 489, 220, 15, 1144, 51953, 220, 18, 61, 18, 489, 220, 16, 1144, 51953, 220, 18, 61, 17, 489, 220, 15, 1144, 51953, 220, 18, 61, 16, 489, 220, 16, 1144, 51953, 220, 18, 61, 15, 284, 220, 5932, 489, 220, 24, 489, 220, 16, 284, 1144, 80175, 90, 5925, 32816, 627, 791, 4320, 374, 25, 220, 5925, 128001], [128000, 14711, 5546, 512, 50, 361, 4375, 304, 264, 8803, 323, 1475, 220, 966, 4520, 11, 264, 5780, 1364, 71945, 19159, 220, 966, 43732, 315, 39962, 13, 2650, 1690, 43732, 315, 39962, 649, 865, 5780, 8356, 304, 220, 23, 4207, 5380, 2746, 584, 1440, 279, 4320, 311, 279, 3485, 3488, 374, 220, 11738, 11, 1148, 374, 279, 907, 315, 9987, 3977, 865, 1980, 14711, 12761, 25, 1687, 1440, 430, 1475, 220, 966, 4520, 11, 264, 5780, 19159, 220, 966, 43732, 315, 39962, 627, 12834, 1070, 527, 220, 1399, 4520, 304, 459, 6596, 11, 323, 220, 23, 4207, 304, 2860, 11, 279, 2860, 1396, 315, 4520, 374, 220, 1399, 353, 220, 23, 284, 220, 11738, 4520, 627, 2746, 264, 5780, 19159, 220, 966, 43732, 315, 39962, 1475, 220, 966, 4520, 11, 1243, 304, 220, 11738, 4520, 11, 433, 690, 8356, 320, 11738, 14, 966, 8, 353, 220, 966, 284, 220, 11738, 43732, 315, 39962, 627, 1687, 527, 2728, 430, 279, 2860, 1396, 315, 43732, 315, 39962, 9124, 374, 220, 11738, 11, 779, 584, 649, 3350, 25, 220, 11738, 284, 220, 11738, 353, 865, 627, 12792, 6714, 2225, 11314, 555, 220, 11738, 11, 584, 636, 25, 865, 284, 220, 16, 627, 791, 907, 315, 865, 374, 220, 16, 627, 827, 220, 16, 198, 791, 4320, 374, 25, 220, 16, 128001], [128000, 14711, 5546, 512, 9126, 374, 12096, 46362, 311, 94123, 264, 502, 3857, 315, 5754, 13, 578, 5754, 690, 387, 220, 1049, 15, 7693, 1317, 323, 220, 508, 7693, 7029, 13, 9062, 11092, 1096, 315, 46362, 690, 3504, 220, 4728, 9518, 7693, 315, 5754, 13, 1442, 1855, 11092, 1096, 7194, 865, 11, 323, 1070, 596, 264, 220, 508, 4, 6763, 3827, 11, 1268, 1790, 690, 4488, 1205, 311, 2343, 369, 46362, 5380, 2746, 584, 1440, 279, 4320, 311, 279, 3485, 3488, 374, 220, 10617, 15, 11, 1148, 374, 279, 907, 315, 9987, 3977, 865, 1980, 14711, 12761, 75145, 3158, 315, 279, 5754, 374, 279, 3160, 56016, 555, 279, 2430, 25, 220, 1049, 15, 353, 220, 508, 284, 220, 1272, 11, 931, 9518, 7693, 627, 4959, 11092, 1096, 315, 46362, 690, 3504, 220, 4728, 9518, 7693, 315, 5754, 11, 779, 4488, 690, 1205, 220, 1272, 11, 931, 611, 220, 4728, 284, 220, 1135, 11092, 33785, 315, 46362, 627, 791, 2853, 315, 1855, 11092, 1096, 374, 865, 11441, 627, 791, 2860, 2853, 315, 279, 46362, 2085, 6763, 3827, 374, 220, 1135, 353, 865, 11441, 627, 791, 6763, 3827, 374, 220, 508, 4, 315, 279, 2860, 2853, 11, 779, 279, 6763, 3827, 3392, 374, 220, 15, 13, 17, 353, 320, 1135, 353, 865, 8, 284, 220, 605, 353, 865, 11441, 627, 791, 2860, 2853, 2737, 6763, 3827, 374, 279, 2694, 315, 279, 2853, 2085, 6763, 3827, 323, 279, 6763, 3827, 3392, 25, 220, 1135, 353, 865, 489, 220, 605, 353, 865, 284, 220, 1399, 353, 865, 11441, 627, 1687, 527, 2728, 430, 279, 2860, 2853, 374, 400, 10617, 15, 11, 779, 584, 649, 3350, 25, 220, 1399, 353, 865, 284, 400, 10617, 15, 627, 12792, 6714, 2225, 11314, 555, 220, 1399, 11, 584, 636, 25, 865, 284, 400, 2075, 627, 791, 907, 315, 865, 374, 400, 2075, 627, 827, 220, 2075, 198, 791, 4320, 374, 25, 220, 2075, 128001], [128000, 14711, 5546, 512, 36, 16023, 753, 5679, 50542, 220, 5495, 16701, 26, 433, 50542, 865, 3115, 439, 1790, 439, 42521, 753, 5679, 13, 220, 32255, 11, 1148, 374, 279, 4785, 315, 279, 12875, 5380, 2746, 584, 1440, 279, 4320, 311, 279, 3485, 3488, 374, 220, 5332, 11, 1148, 374, 279, 907, 315, 9987, 3977, 865, 1980, 14711, 12761, 25, 1687, 1440, 430, 45043, 596, 5679, 50542, 220, 5495, 16701, 627, 1687, 1101, 1440, 430, 45043, 596, 5679, 50542, 865, 3115, 439, 1790, 439, 42521, 596, 5679, 11, 902, 3445, 42521, 596, 5679, 50542, 220, 5495, 11009, 16701, 627, 791, 2860, 4785, 315, 279, 12875, 374, 279, 2694, 315, 279, 4785, 315, 45043, 596, 5679, 323, 279, 4785, 315, 42521, 596, 5679, 25, 220, 5495, 489, 220, 5495, 11009, 627, 1687, 527, 2728, 430, 279, 2860, 4785, 315, 279, 12875, 374, 220, 5332, 16701, 11, 779, 584, 649, 3350, 25, 220, 5495, 489, 220, 5495, 11009, 284, 220, 5332, 627, 50, 20222, 369, 865, 11, 584, 636, 25, 865, 284, 220, 22, 627, 791, 907, 315, 865, 374, 220, 22, 627, 827, 220, 22, 198, 791, 4320, 374, 25, 220, 22, 128001], [128000, 14711, 5546, 512, 791, 6424, 315, 98104, 706, 220, 3443, 10632, 13, 3861, 11999, 315, 279, 6424, 596, 10632, 527, 4251, 13, 3861, 18172, 315, 279, 2536, 16237, 10632, 617, 264, 40511, 13, 2650, 1690, 315, 279, 2536, 16237, 10632, 656, 539, 617, 264, 40511, 1980, 14711, 12761, 25, 4054, 11999, 315, 279, 6424, 596, 10632, 527, 4251, 11, 779, 1070, 527, 220, 3443, 14, 19, 284, 220, 1041, 4251, 10632, 627, 791, 9861, 2536, 16237, 10632, 527, 220, 3443, 482, 220, 1041, 284, 220, 3101, 10632, 627, 4054, 18172, 315, 279, 2536, 16237, 10632, 617, 264, 40511, 11, 779, 1070, 527, 220, 3101, 14, 20, 284, 220, 1399, 2536, 16237, 10632, 449, 264, 40511, 627, 55915, 11, 279, 1396, 315, 2536, 16237, 10632, 2085, 264, 40511, 374, 220, 3101, 482, 220, 1399, 284, 220, 8273, 627, 827, 220, 8273, 198, 791, 4320, 374, 25, 220, 8273, 128001], [128000, 14711, 5546, 512, 45320, 1385, 400, 81, 3, 323, 400, 82, 3, 13592, 65683, 989, 13, 3277, 400, 81, 3, 374, 400, 4364, 15, 4884, 400, 82, 3, 374, 400, 15, 13, 1758, 2475, 3639, 374, 279, 907, 315, 400, 82, 3, 994, 400, 81, 3, 374, 400, 8273, 15, 3, 30, 17855, 701, 4320, 439, 264, 12395, 311, 279, 24379, 16579, 17323, 382, 14711, 12761, 25, 2746, 400, 81, 3, 323, 400, 82, 3, 13592, 65683, 989, 11, 1243, 584, 1440, 430, 400, 81, 1144, 51953, 274, 284, 597, 3, 369, 1063, 6926, 400, 74, 3, 627, 1687, 527, 2728, 430, 994, 400, 81, 3, 374, 400, 4364, 15, 55976, 400, 82, 3, 374, 400, 15, 13, 1758, 13244, 2100, 584, 649, 743, 709, 279, 24524, 512, 3, 4364, 15, 1144, 51953, 220, 15, 13, 1758, 284, 597, 26101, 50, 6517, 7922, 11, 584, 1505, 430, 400, 74, 284, 220, 12819, 3, 627, 7184, 584, 649, 1005, 420, 907, 315, 400, 74, 3, 311, 11886, 369, 400, 82, 3, 994, 400, 81, 3, 374, 400, 8273, 15, 3, 512, 3, 8273, 15, 1144, 51953, 274, 284, 220, 12819, 26101, 12792, 6714, 2225, 11314, 555, 400, 8273, 15, 55976, 584, 1505, 430, 400, 82, 284, 1144, 80175, 90, 15, 13, 10005, 32816, 311, 279, 24379, 16579, 17323, 627, 791, 4320, 374, 25, 220, 15, 13, 10005, 128001], [128000, 14711, 5546, 512, 56830, 11021, 220, 23, 6603, 922, 10099, 11, 220, 21, 6603, 922, 16335, 3634, 11, 323, 220, 18, 6603, 922, 28788, 311, 2567, 1461, 13326, 927, 279, 25425, 13, 9062, 2363, 2853, 400, 21, 13, 2650, 1790, 1550, 20851, 8493, 389, 279, 6603, 1980, 14711, 12761, 25, 56830, 11021, 264, 2860, 315, 220, 23, 489, 220, 21, 489, 220, 18, 284, 220, 1114, 6603, 627, 4959, 2363, 2853, 400, 21, 11, 779, 20851, 7543, 264, 2860, 315, 220, 1114, 865, 400, 21, 284, 400, 4278, 389, 279, 6603, 627, 827, 220, 4278, 198, 791, 4320, 374, 25, 220, 4278, 128001]]\n"
     ]
    }
   ],
   "source": [
    "print(data_module['train_dataset']['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "146\n",
      "253\n",
      "93\n",
      "218\n",
      "316\n",
      "192\n",
      "149\n",
      "228\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "for e in trainer.train_dataset:\n",
    "    print(len(e['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
