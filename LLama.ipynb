{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 22:38:30.398727: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-14 22:38:30.414483: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739561910.431564 3686126 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739561910.436679 3686126 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-14 22:38:30.455628: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from lib import Datasets\n",
    "from datasets import load_dataset\n",
    "import copy\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Sequence, List, Literal\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -100\n",
    "\n",
    "# PROMPT = (\n",
    "#         \"Below is an instruction that describes a task. \"\n",
    "#         \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "#         \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "#     )\n",
    "\n",
    "PROMPT = (\n",
    "        \"### Task:\\n{instruction}\\n\\n### Solution:\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dabcb953394ffaad9aecb735eeebaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1, target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'down_proj'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = \"meta-llama/Llama-2-7b-hf\"\n",
    "# name = \"distilgpt2\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForCausalLM.from_pretrained(name, torch_dtype=torch.float16, device_map='auto')\n",
    "\n",
    "# model = get_peft_model(model, peft_config)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --data_path meta-math/MetaMathQA \\\n",
    "# --dataset_field query response \\\n",
    "    \n",
    "# python -u train_model.py \\\n",
    "#     --model_name_or_path $BASE_MODEL \\\n",
    "#     --output_dir $OUTPUT \\\n",
    "#     --corda_mode False \\\n",
    "#     --lora_r 128 \\\n",
    "#     --data_path meta-math/MetaMathQA \\\n",
    "#     --dataset_split \"train[:100000]\" \\\n",
    "#     --dataset_field query response \\\n",
    "#     --num_train_epochs 1 \\\n",
    "#     --per_device_train_batch_size 1 \\\n",
    "#     --gradient_accumulation_steps 128 \\\n",
    "#     --save_strategy \"steps\" \\\n",
    "#     --save_steps 100 \\\n",
    "#     --save_total_limit 1 \\\n",
    "#     --learning_rate 2e-5 \\\n",
    "#     --weight_decay 0. \\\n",
    "#     --warmup_ratio 0.03 \\\n",
    "#     --lr_scheduler_type \"cosine\" \\\n",
    "#     --logging_steps 1 \\\n",
    "#     --bf16 True \\\n",
    "#     --tf32 True \\\n",
    "#     --report_to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "    \"\"\"Tokenize a list of strings.\"\"\"\n",
    "    tokenized_list = [\n",
    "        tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            # padding=\"longest\",\n",
    "            padding='max_length',\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "        for text in strings\n",
    "    ]\n",
    "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "    input_ids_lens = labels_lens = [\n",
    "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "    ]\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=labels,\n",
    "        input_ids_lens=input_ids_lens,\n",
    "        labels_lens=labels_lens,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    sources: Sequence[str],\n",
    "    targets: Sequence[str],\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    ") -> Dict:\n",
    "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
    "    examples = [s + t for s, t in zip(sources, targets)]\n",
    "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "    input_ids = examples_tokenized[\"input_ids\"]\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "    \n",
    "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "        # print(len(label), source_len)\n",
    "        # label[:source_len] = IGNORE_INDEX\n",
    "        a = 5\n",
    "        \n",
    "    return dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "def train_tokenize_function(examples, tokenizer, query, response):\n",
    "    sources = [PROMPT.format_map(dict(instruction=instruction)) for instruction in examples[query]]\n",
    "    targets = [f\"{output}{tokenizer.eos_token}\" for output in examples[response]]\n",
    "    data_dict = preprocess(sources, targets, tokenizer)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        name,\n",
    "        model_max_length=30,\n",
    "        padding_side=\"right\",\n",
    "        use_fast=True,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "raw_train_datasets = load_dataset(\"meta-math/MetaMathQA\", split='train[:100]')\n",
    "\n",
    "train_dataset = raw_train_datasets.map(\n",
    "        train_tokenize_function,\n",
    "        batched=True,\n",
    "        batch_size=3000,\n",
    "        num_proc=16, # 32\n",
    "        remove_columns=raw_train_datasets.column_names,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on train dataset\",\n",
    "        fn_kwargs={\"tokenizer\": tokenizer, \"query\": \"query\", \"response\": \"response\"}\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = [torch.tensor(x) for x in input_ids]\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = [torch.tensor(x) for x in labels]\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./logs/abrakkk',          \n",
    "    num_train_epochs=1,                   \n",
    "    per_device_train_batch_size=1,       \n",
    "    per_device_eval_batch_size=1,       \n",
    "    gradient_accumulation_steps=1,   \n",
    "    learning_rate=2e-5,               \n",
    "    weight_decay=0.0,                   \n",
    "    warmup_ratio=0.03,                   \n",
    "    lr_scheduler_type=\"cosine\",          \n",
    "    logging_steps=1,                       \n",
    "    fp16=True,\n",
    "    report_to=\"tensorboard\",              \n",
    "    logging_dir='./logs/abra',                 \n",
    "    # use_cpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "data_module = dict(train_dataset=train_dataset, data_collator=data_collator)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "metric = load('accuracy')\n",
    "\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "# Load the accuracy metric\n",
    "metric = load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    predictions = np.argmax(predictions, axis=2).flatten()\n",
    "    \n",
    "    labels = labels.flatten()\n",
    "    \n",
    "    mask = labels != -100\n",
    "    \n",
    "    return metric.compute(predictions=predictions[mask], references=labels[mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(model=model, tokenizer=tokenizer, args=script_args, **data_module)\n",
    "\n",
    "# trainer = Trainer(model=model, args=training_args, **data_module)\n",
    "trainer = Trainer(model=model, args=training_args, compute_metrics=compute_metrics, **data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_dataset': Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 100\n",
      "}), 'data_collator': DataCollatorForSupervisedDataset(tokenizer=LlamaTokenizerFast(name_or_path='meta-llama/Llama-2-7b-hf', vocab_size=32000, model_max_length=30, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "))}\n"
     ]
    }
   ],
   "source": [
    "print(data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1/100 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# model.eval()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# model.config.use_cache = True\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# trainer.train()\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:4073\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4070\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4072\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4073\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4074\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   4077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   4078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4083\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:4287\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4284\u001b[0m         all_inputs\u001b[38;5;241m.\u001b[39madd(inputs_decode)\n\u001b[1;32m   4285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4286\u001b[0m     \u001b[38;5;66;03m# Pad labels here, preparing for preprocess_logits_for_metrics in next logits block.\u001b[39;00m\n\u001b[0;32m-> 4287\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4289\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/accelerator.py:2600\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2568\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2570\u001b[0m \u001b[38;5;124;03m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py:408\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    410\u001b[0m         operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py:678\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    675\u001b[0m     new_tensor[indices] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py:126\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py:658\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    655\u001b[0m     dim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tensor\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# Gather all sizes\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    659\u001b[0m sizes \u001b[38;5;241m=\u001b[39m gather(size)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "# model.eval()\n",
    "# model.config.use_cache = True\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate(eval_dataset=trainer.train_dataset)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 835, 9330, 29901, 13, 29954, 945, 347, 322, 11131, 526, 23906, 3694, 373, 278, 4280, 10694, 29889, 11131, 3060, 15806, 278, 1298, 395, 29896, 29974, 29906, 29875, 1504, 402], [1, 835, 9330, 29901, 13, 5618, 338, 278, 3001, 3438, 310, 10596, 5832, 21083, 363, 599, 4832, 9404, 10769, 373, 278, 5733, 3815, 29892, 13858, 393, 1269, 4847, 6858, 263], [1, 835, 9330, 29901, 13, 29928, 9383, 289, 12535, 29871, 29896, 29906, 274, 6926, 363, 670, 9883, 29915, 29879, 12060, 3250, 29889, 18935, 884, 289, 12535, 29871, 29946, 274, 6926], [1, 835, 9330, 29901, 13, 18455, 395, 29896, 29900, 29896, 29900, 29896, 29918, 29941, 29938, 304, 263, 2967, 29871, 29896, 29900, 6043, 29889, 13, 13, 2277, 29937, 24380, 17178, 29896], [1, 835, 9330, 29901, 13, 29903, 434, 1736, 297, 263, 12529, 322, 1432, 29871, 29941, 29900, 6233, 29892, 263, 4933, 1183, 975, 344, 267, 13880, 29871, 29941, 29900, 508, 29879], [1, 835, 9330, 29901, 13, 9802, 338, 1321, 5414, 408, 561, 1997, 304, 282, 1351, 263, 716, 4004, 310, 6520, 29889, 450, 6520, 674, 367, 29871, 29906, 29900, 29900, 29900], [1, 835, 9330, 29901, 13, 29923, 3703, 30010, 29879, 11203, 591, 1141, 29879, 29871, 29953, 29941, 24261, 29936, 372, 591, 1141, 29879, 921, 3064, 408, 1568, 408, 16560, 30010, 29879], [1, 835, 9330, 29901, 13, 1576, 4726, 310, 3741, 675, 756, 29871, 29946, 29900, 29900, 17774, 29889, 3118, 11582, 310, 278, 4726, 29915, 29879, 17774, 526, 4796, 29889, 3118, 18615], [1, 835, 9330, 29901, 13, 22930, 1907, 395, 29878, 29938, 322, 395, 29879, 29938, 13100, 297, 874, 873, 29889, 1932, 395, 29878, 29938, 338, 395, 29896, 29906, 29900, 29900, 8209], [1, 835, 9330, 29901, 13, 29928, 1351, 18093, 29871, 29947, 8277, 1048, 15006, 29892, 29871, 29953, 8277, 1048, 11420, 2913, 29892, 322, 29871, 29941, 8277, 1048, 22983, 304, 3013, 1075], [1, 835, 9330, 29901, 13, 27065, 403, 29871, 29947, 13931, 491, 779, 1154, 29912, 29896, 1157, 29947, 1836, 29938, 13, 13, 2277, 29937, 24380, 29901, 29928, 3640, 292, 491, 263], [1, 835, 9330, 29901, 13, 5618, 338, 395, 29871, 29953, 320, 4563, 1060, 448, 29871, 29906, 448, 29871, 29947, 718, 29871, 29906, 320, 3822, 29871, 29947, 15485, 13, 3644, 591], [1, 835, 9330, 29901, 13, 1576, 3291, 2427, 29916, 29892, 343, 1262, 9875, 297, 445, 1591, 3804, 373, 263, 7812, 1196, 29889, 450, 1298, 2427, 29906, 29947, 29892, 260, 1262], [1, 835, 9330, 29901, 13, 7976, 326, 2696, 29915, 29879, 4098, 368, 11118, 338, 395, 29953, 29900, 639, 4098, 29889, 3600, 4098, 368, 11118, 11664, 491, 17058, 10151, 746, 540], [1, 835, 9330, 29901, 13, 20606, 29872, 779, 29881, 16183, 29912, 29896, 29946, 1157, 29896, 29896, 4311, 13, 13, 2277, 29937, 24380, 29901, 4535, 29881, 16183, 29912, 29896, 29946, 1157], [1, 835, 9330, 29901, 13, 8439, 526, 29871, 29953, 14000, 322, 29871, 29947, 12544, 297, 278, 3762, 1708, 29889, 960, 1716, 11825, 310, 1269, 26397, 14333, 278, 5730, 406, 29892], [1, 835, 9330, 29901, 13, 3644, 11648, 756, 263, 3058, 5253, 310, 6909, 29892, 11886, 756, 29871, 29945, 3064, 393, 5253, 29889, 960, 896, 505, 263, 3001, 310, 395, 29896], [1, 835, 9330, 29901, 13, 29924, 9345, 756, 20591, 263, 3001, 310, 395, 29896, 29953, 29900, 297, 281, 1179, 445, 4723, 29889, 940, 4520, 278, 281, 1179, 363, 670, 937], [1, 835, 9330, 29901, 13, 29909, 29871, 29906, 29953, 29899, 26763, 19308, 1766, 25206, 756, 921, 1423, 9748, 2768, 372, 29889, 450, 937, 338, 697, 17967, 515, 278, 1369, 1196], [1, 835, 9330, 29901, 13, 29924, 335, 1927, 29915, 29879, 16823, 6296, 3271, 921, 289, 810, 310, 12060, 3250, 298, 1446, 29889, 7806, 19548, 756, 29871, 29896, 29945, 298, 1446], [1, 835, 9330, 29901, 13, 3644, 12936, 29872, 17630, 338, 5279, 29871, 29906, 29945, 2440, 2030, 322, 3230, 29873, 1384, 338, 29871, 29941, 2440, 9642, 1135, 12936, 29872, 17630, 29892], [1, 835, 9330, 29901, 13, 12542, 278, 395, 29906, 320, 3706, 29871, 29906, 29938, 4636, 779, 2762, 29912, 29924, 1042, 1316, 393, 779, 2762, 29912, 29924, 29913, 320, 463, 29912], [1, 835, 9330, 29901, 13, 29943, 573, 577, 4684, 29892, 28684, 7254, 29892, 17354, 29892, 4628, 29892, 2654, 29892, 322, 3708, 552, 526, 297, 263, 7482, 556, 29889, 512, 920], [1, 835, 9330, 29901, 13, 3644, 5011, 25100, 304, 7400, 472, 263, 6210, 310, 29871, 29953, 29900, 286, 561, 322, 278, 5418, 338, 29871, 29941, 29953, 29900, 7800, 29892, 411], [1, 835, 9330, 29901, 13, 5328, 1784, 1422, 18240, 526, 727, 304, 6755, 29871, 29941, 4332, 2708, 515, 263, 3815, 310, 29871, 29896, 29896, 2305, 29973, 13, 13, 2277, 29937], [1, 835, 9330, 29901, 13, 7675, 29895, 338, 3907, 298, 1117, 2007, 414, 322, 540, 10753, 304, 19417, 963, 304, 1207, 395, 29945, 29900, 29889, 29871, 4976, 338, 269, 7807], [1, 835, 9330, 29901, 13, 8809, 436, 6043, 395, 29876, 29938, 17150, 278, 5855, 395, 29900, 320, 3797, 302, 529, 29871, 29896, 29929, 29938, 322, 395, 29941, 29947, 29945, 29955], [1, 835, 9330, 29901, 13, 5618, 338, 278, 3619, 11959, 310, 278, 10362, 26224, 3652, 779, 1154, 8499, 29941, 1157, 29945, 29913, 448, 320, 1154, 29912, 29945, 1157, 29941, 29913], [1, 835, 9330, 29901, 13, 5618, 338, 278, 2533, 310, 599, 6374, 6043, 1819, 310, 395, 29876, 29938, 363, 607, 779, 1154, 29912, 29876, 29974, 29953, 1157, 29876, 1042, 338], [1, 835, 9330, 29901, 13, 4806, 505, 393, 395, 29906, 29874, 718, 29871, 29896, 353, 29871, 29896, 29938, 322, 395, 29890, 448, 263, 353, 29871, 29896, 7449, 1724, 338, 278], [1, 835, 9330, 29901, 13, 3644, 940, 9345, 756, 263, 3058, 1353, 310, 15889, 297, 902, 4333, 29892, 5774, 756, 2211, 3064, 408, 1784, 15889, 29892, 322, 8081, 756, 4832], [1, 835, 9330, 29901, 13, 29903, 370, 1099, 338, 6257, 902, 937, 1629, 310, 12755, 393, 21544, 395, 29941, 29900, 29892, 29900, 29900, 29900, 29889, 2296, 756, 7160, 395, 29896], [1, 835, 9330, 29901, 13, 3644, 18299, 1754, 29871, 29946, 29929, 11982, 16416, 267, 322, 476, 2486, 29876, 1754, 29871, 29946, 29955, 901, 11982, 16416, 267, 1135, 18299, 29892, 322], [1, 835, 9330, 29901, 13, 29909, 6534, 29871, 29953, 29899, 29879, 2618, 762, 338, 29081, 29889, 29871, 960, 306, 9679, 395, 29876, 1628, 769, 306, 5401, 395, 29876, 29985, 29906], [1, 835, 9330, 29901, 13, 29934, 13910, 29892, 5310, 29892, 322, 751, 262, 1270, 599, 15010, 14956, 29889, 5310, 15010, 29871, 29947, 14956, 29889, 751, 262, 1270, 15010, 29871, 29906], [1, 835, 9330, 29901, 13, 29954, 1099, 756, 1023, 9124, 15303, 29889, 7806, 3633, 756, 263, 12616, 310, 278, 17346, 297, 29782, 29915, 29879, 3633, 29889, 960, 29782, 29915, 29879], [1, 835, 9330, 29901, 13, 11639, 3732, 29871, 29953, 24231, 21046, 363, 263, 289, 1296, 14686, 29889, 29871, 940, 269, 10071, 1269, 15327, 363, 395, 29896, 29889, 29945, 322, 1269], [1, 835, 9330, 29901, 13, 10401, 263, 1353, 338, 13931, 491, 29871, 29955, 29892, 278, 21162, 338, 29871, 29906, 29889, 1724, 338, 278, 21162, 746, 2211, 3064, 278, 1353, 26134], [1, 835, 9330, 29901, 13, 29928, 16677, 289, 6926, 3023, 260, 764, 29879, 411, 29871, 29906, 29945, 330, 5621, 29890, 949, 29879, 297, 1269, 260, 764, 322, 2211, 260, 764], [1, 835, 9330, 29901, 13, 2831, 3271, 1287, 29892, 4358, 6946, 756, 29871, 29896, 29945, 5844, 4828, 29892, 29871, 29953, 5264, 11898, 4828, 29892, 322, 921, 10466, 4828, 29889, 940], [1, 835, 9330, 29901, 13, 2951, 27822, 29892, 21343, 15873, 297, 670, 8955, 363, 29871, 29953, 29900, 6233, 472, 263, 6554, 310, 29871, 29896, 1813, 1432, 29871, 29941, 29900, 6233], [1, 835, 9330, 29901, 13, 9598, 3845, 756, 263, 5447, 15678, 297, 670, 16423, 393, 338, 5279, 29871, 29896, 29947, 29900, 22831, 15655, 29889, 2193, 338, 29871, 29945, 29900, 29995], [1, 835, 9330, 29901, 13, 797, 263, 4723, 29892, 29871, 29946, 29945, 29900, 18647, 26603, 1549, 263, 304, 645, 1045, 720, 29889, 29008, 1017, 24413, 3512, 1549, 278, 304, 645], [1, 835, 9330, 29901, 13, 29907, 932, 29884, 617, 8226, 3438, 395, 29906, 29892, 29871, 7612, 734, 294, 3438, 921, 29892, 5777, 1725, 301, 1131, 267, 3438, 395, 29896, 29889], [1, 835, 9330, 29901, 13, 3644, 315, 744, 29890, 756, 29871, 29941, 24231, 12736, 368, 11700, 322, 19122, 347, 756, 4203, 408, 1784, 12736, 368, 11700, 408, 315, 744, 29890], [1, 835, 9330, 29901, 13, 6716, 9853, 310, 21046, 6858, 29871, 29946, 2723, 567, 310, 1652, 473, 322, 29871, 29896, 29889, 29945, 2723, 567, 310, 26438, 29889, 29871, 29946, 29946], [1, 835, 9330, 29901, 13, 29949, 17843, 423, 4846, 4667, 29871, 29896, 29900, 9709, 11335, 29889, 1913, 18556, 884, 4076, 4667, 8951, 278, 1353, 310, 9709, 11335, 19802, 423, 4846], [1, 835, 9330, 29901, 13, 3644, 4976, 289, 6926, 1023, 260, 764, 29879, 310, 21046, 639, 2462, 363, 263, 3001, 310, 29871, 29953, 3841, 29892, 322, 540, 321, 1446, 697], [1, 835, 9330, 29901, 13, 29928, 3857, 10753, 304, 15649, 13851, 22095, 363, 599, 278, 29871, 29946, 29900, 4344, 472, 902, 1887, 4344, 29915, 29879, 3271, 29889, 450, 3271, 756], [1, 835, 9330, 29901, 13, 3644, 263, 5073, 708, 3787, 269, 10071, 2211, 4072, 310, 282, 3977, 2719, 448, 282, 3977, 2719, 411, 604, 294, 414, 363, 395, 29900, 29889], [1, 835, 9330, 29901, 13, 29909, 3752, 737, 29892, 1522, 17417, 29892, 322, 1704, 1100, 864, 304, 19417, 1009, 29808, 472, 278, 9999, 29889, 1976, 335, 737, 756, 29871, 29941], [1, 835, 9330, 29901, 13, 29928, 8846, 347, 18093, 29871, 29941, 7013, 8149, 363, 3969, 29887, 4357, 29892, 278, 937, 7013, 1989, 338, 29871, 29953, 4679, 468, 25402, 29892, 278], [1, 835, 9330, 29901, 13, 9928, 3100, 756, 263, 4333, 310, 29871, 29906, 29946, 12785, 310, 10812, 3158, 13994, 29889, 2296, 5239, 1283, 263, 12616, 310, 963, 472, 278, 3300], [1, 835, 9330, 29901, 13, 5618, 338, 278, 21162, 746, 278, 2533, 310, 395, 29896, 29991, 718, 29871, 29906, 29991, 718, 29871, 29941, 29991, 718, 320, 9572, 718, 29871, 29946], [1, 835, 9330, 29901, 13, 797, 278, 6306, 395, 29906, 29916, 29985, 29906, 718, 29871, 29953, 29916, 718, 29871, 29896, 29896, 29938, 13384, 408, 395, 29874, 29898, 29916, 448, 298], [1, 835, 9330, 29901, 13, 29923, 4387, 403, 278, 10362, 26224, 3652, 29901, 6118, 1154, 29912, 29896, 1157, 29941, 10869, 1154, 29912, 29896, 1157, 29953, 10869, 1154, 29912, 29896, 1157], [1, 835, 9330, 29901, 13, 29924, 293, 1989, 322, 20179, 526, 2534, 263, 17793, 304, 1074, 1058, 508, 1065, 2820, 1009, 2908, 278, 1556, 29889, 3118, 931, 2820, 278, 2908], [1, 835, 9330, 29901, 13, 797, 263, 2323, 2462, 29892, 372, 1153, 1312, 363, 1784, 6199, 29889, 3645, 29871, 29906, 3358, 304, 29871, 29946, 3358, 29892, 372, 1153, 1312, 472], [1, 835, 9330, 29901, 13, 7083, 15457, 1321, 952, 29871, 29896, 3405, 371, 363, 395, 29946, 29889, 29900, 29900, 1432, 7250, 29892, 29871, 29945, 3841, 263, 4723, 29889, 259, 29941], [1, 835, 9330, 29901, 13, 3644, 278, 11959, 310, 319, 304, 350, 304, 315, 338, 29871, 29906, 29901, 29896, 29901, 29946, 29892, 825, 338, 278, 995, 310, 313, 29941, 29909], [1, 835, 9330, 29901, 13, 29909, 2022, 27942, 287, 385, 5253, 310, 6909, 363, 263, 1629, 472, 385, 4066, 6554, 310, 29871, 29896, 29906, 15543, 960, 278, 3001, 4066, 338], [1, 835, 9330, 29901, 13, 10401, 395, 29896, 29900, 29900, 29900, 998, 29896, 29900, 29900, 1042, 338, 17832, 29892, 920, 1784, 24786, 1101, 278, 8236, 29871, 29896, 297, 278, 9819], [1, 835, 9330, 29901, 13, 9760, 2022, 10902, 278, 1591, 411, 385, 1060, 373, 278, 2462, 29898, 29879, 29897, 540, 29914, 11360, 723, 451, 367, 2221, 304, 14333, 263, 11781], [1, 835, 9330, 29901, 13, 11639, 1321, 952, 29871, 29941, 260, 29899, 845, 381, 1372, 393, 3438, 395, 29916, 1269, 29889, 29871, 940, 884, 1321, 952, 395, 29945, 29900, 297], [1, 835, 9330, 29901, 13, 23495, 280, 395, 29911, 29938, 756, 967, 4818, 472, 1298, 395, 29911, 6278, 29906, 29892, 29953, 4935, 27927, 395, 29911, 29938, 338, 25312, 4822, 278], [1, 835, 9330, 29901, 13, 29909, 3500, 9010, 5447, 674, 6548, 921, 6900, 297, 278, 937, 1629, 29889, 29871, 512, 278, 1473, 1629, 29892, 372, 674, 6548, 29871, 29945, 29900], [1, 835, 9330, 29901, 13, 5328, 1784, 1584, 3694, 526, 7621, 1135, 29871, 29906, 29900, 29906, 322, 3109, 1135, 29871, 29946, 29900, 29945, 29973, 13, 13, 2277, 29937, 24380, 29901], [1, 835, 9330, 29901, 13, 29909, 18197, 16423, 30010, 29879, 7689, 682, 1358, 1788, 6057, 8951, 263, 2462, 2645, 278, 12528, 7250, 322, 11005, 6199, 29889, 739, 19922, 278, 16423], [1, 835, 9330, 29901, 13, 8179, 433, 805, 1975, 29871, 29896, 29900, 6233, 528, 279, 2238, 292, 902, 889, 1607, 322, 921, 3064, 393, 5253, 310, 931, 1236, 14067, 18655], [1, 835, 9330, 29901, 13, 6362, 837, 457, 278, 878, 1070, 16402, 310, 29871, 29906, 29955, 878, 7207, 29871, 29906, 29947, 29889, 9133, 680, 596, 1234, 408, 385, 6043, 1546], [1, 835, 9330, 29901, 13, 13555, 773, 7689, 682, 793, 373, 902, 11315, 29892, 1067, 6046, 29892, 322, 282, 1691, 29892, 16816, 264, 750, 29871, 29941, 28145, 1135, 4203, 310], [1, 835, 9330, 29901, 13, 29470, 4947, 29871, 29941, 610, 9292, 16892, 1691, 29889, 29871, 450, 937, 29871, 29906, 3438, 395, 29896, 29945, 29900, 1269, 322, 278, 4654, 3438, 29871], [1, 835, 9330, 29901, 13, 797, 263, 330, 17179, 4402, 29892, 727, 526, 1023, 3064, 408, 1784, 12944, 1135, 14263, 5144, 29889, 1128, 1784, 12944, 5144, 526, 727, 565, 727], [1, 835, 9330, 29901, 13, 13711, 20336, 1602, 2247, 540, 10753, 304, 1369, 8471, 1283, 278, 2982, 29889, 29871, 940, 1321, 952, 29871, 29941, 29900, 23931, 310, 2982, 363, 395], [1, 835, 9330, 29901, 13, 29902, 3703, 756, 29871, 29906, 29900, 17629, 29889, 23052, 756, 8951, 408, 1784, 17629, 408, 16560, 29889, 1128, 1784, 17629, 437, 896, 505, 19148, 29973], [1, 835, 9330, 29901, 13, 1576, 7472, 9109, 5253, 310, 274, 3470, 29872, 457, 366, 508, 29151, 639, 2462, 338, 29871, 29945, 29900, 29900, 286, 29887, 29889, 960, 1269, 5864], [1, 835, 9330, 29901, 13, 3644, 727, 526, 12919, 29871, 29945, 29900, 29900, 6131, 297, 263, 770, 322, 1269, 1591, 756, 29871, 29906, 29914, 29945, 3064, 278, 1353, 310, 8277], [1, 835, 9330, 29901, 13, 3644, 435, 453, 20848, 29871, 29945, 4870, 29879, 310, 2654, 289, 1309, 1270, 26563, 322, 29871, 29946, 4870, 29879, 310, 13328, 289, 1309, 1270, 26563], [1, 835, 9330, 29901, 13, 3644, 395, 29906, 29874, 718, 29871, 29896, 353, 29871, 29896, 29938, 322, 395, 29890, 448, 263, 353, 29871, 29896, 1628, 825, 338, 278, 995, 310], [1, 835, 9330, 29901, 13, 3644, 5677, 6764, 750, 1023, 3064, 901, 6909, 1135, 278, 3438, 310, 278, 6601, 1434, 3907, 278, 20590, 29892, 322, 540, 18093, 278, 6601, 363], [1, 835, 9330, 29901, 13, 5618, 338, 278, 3001, 7688, 310, 263, 2254, 19849, 310, 29871, 29896, 29906, 2181, 1078, 29892, 1269, 591, 1141, 292, 29871, 29946, 4679, 468, 25402], [1, 835, 9330, 29901, 13, 27501, 713, 756, 29871, 29947, 29900, 13327, 7875, 29889, 921, 29995, 526, 12544, 322, 29871, 29946, 29900, 29995, 526, 14000, 29889, 1952, 2941, 756, 8951], [1, 835, 9330, 29901, 13, 3644, 3833, 368, 29915, 29879, 1857, 289, 370, 952, 5171, 21090, 395, 29896, 29953, 639, 7234, 322, 1183, 338, 13858, 21293, 304, 263, 716, 289], [1, 835, 9330, 29901, 13, 3644, 22838, 10398, 395, 29896, 29889, 29955, 29945, 373, 263, 13748, 322, 769, 10398, 385, 5684, 395, 29896, 29889, 29906, 29945, 29892, 322, 540, 756], [1, 835, 9330, 29901, 13, 29909, 6635, 756, 1476, 395, 29946, 29941, 29906, 648, 29929, 1042, 3519, 297, 607, 304, 10985, 1269, 310, 902, 14183, 12080, 29889, 29871, 1128, 1784], [1, 835, 9330, 29901, 13, 4819, 309, 756, 263, 19480, 4333, 540, 4188, 267, 304, 788, 304, 29889, 29871, 940, 4687, 411, 29871, 29945, 29900, 2106, 439, 13868, 670, 11825], [1, 835, 9330, 29901, 13, 20606, 29872, 779, 29881, 16183, 29912, 29896, 29953, 1157, 29945, 4311, 13, 13, 2277, 29937, 24380, 29901, 4535, 29881, 16183, 29912, 29896, 29953, 1157, 29945], [1, 835, 9330, 29901, 13, 29940, 271, 26840, 756, 901, 1135, 779, 29938, 29896, 29938, 541, 3109, 1135, 779, 29938, 29896, 29900, 29938, 7088, 310, 270, 1355, 29889, 1932, 1183], [1, 835, 9330, 29901, 13, 29909, 18148, 21118, 756, 29871, 29945, 14189, 1446, 322, 29871, 29945, 8063, 550, 29889, 17090, 599, 2832, 14722, 526, 20820, 519, 29892, 297, 920, 1784], [1, 835, 9330, 29901, 13, 29909, 14064, 278, 1008, 21090, 395, 29945, 363, 1775, 457, 29872, 16892, 1691, 29892, 395, 29955, 363, 11005, 16892, 1691, 29892, 322, 395, 29896, 29900], [1, 835, 9330, 29901, 13, 12024, 5539, 29888, 29898, 29916, 29897, 353, 13, 29905, 463, 29912, 11436, 29913, 13, 29929, 29916, 29974, 29946, 8682, 726, 29912, 361, 500, 29916, 29905], [1, 835, 9330, 29901, 13, 1576, 740, 395, 29888, 29898, 29916, 1262, 17150, 13, 29905, 29961, 29888, 29898, 3594, 29897, 353, 320, 1154, 29912, 29888, 29898, 29916, 10172, 29891, 1012], [1, 835, 9330, 29901, 13, 29909, 715, 2807, 18093, 29871, 29896, 29900, 27881, 310, 1302, 2496, 322, 29871, 29945, 901, 27881, 310, 715, 6288, 14282, 29889, 960, 1269, 11134, 3438], [1, 835, 9330, 29901, 13, 5618, 338, 278, 10150, 1353, 310, 18942, 6374, 11920, 393, 508, 367, 2533, 2168, 4208, 1728, 13461, 292, 263, 3001, 310, 29871, 29946, 29900, 29900], [1, 835, 9330, 29901, 13, 5618, 338, 278, 7621, 310, 278, 6851, 304, 278, 6306, 395, 29916, 29985, 29906, 718, 29871, 29896, 29945, 29916, 448, 29945, 29946, 29922, 29900, 15485], [1, 835, 9330, 29901, 13, 29949, 14381, 750, 395, 29929, 29892, 769, 540, 7160, 395, 29945, 515, 670, 2758, 749, 322, 10398, 395, 29946, 373, 263, 1424, 275, 915, 29872], [1, 835, 9330, 29901, 13, 855, 29884, 442, 338, 2675, 373, 263, 4891, 29899, 13509, 17487, 322, 10753, 304, 1284, 278, 5172, 342, 5782, 29889, 1551, 697, 5782, 278, 3001], [1, 835, 9330, 29901, 13, 5618, 338, 278, 10150, 3353, 1353, 3309, 29892, 297, 1644, 326, 2699, 29892, 393, 278, 4654, 2625, 310, 263, 17205, 1033, 505, 565, 1023, 310], [1, 835, 9330, 29901, 13, 797, 1797, 304, 15649, 282, 24990, 363, 8735, 322, 902, 29871, 29896, 29946, 7875, 29892, 5728, 368, 4225, 304, 1073, 920, 1784, 4646, 29879, 1183], [1, 835, 9330, 29901, 13, 29923, 4317, 284, 948, 8459, 304, 10675, 285, 2063, 297, 902, 18403, 363, 10081, 274, 1237, 639, 11134, 29889, 960, 727, 892, 29871, 29945, 29900]]\n"
     ]
    }
   ],
   "source": [
    "print(data_module['train_dataset']['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "for e in trainer.train_dataset:\n",
    "    print(len(e['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
