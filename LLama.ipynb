{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 14:59:24.628639: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-15 14:59:24.642779: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739620764.659398 3937317 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739620764.664588 3937317 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-15 14:59:24.682594: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from lib import Datasets\n",
    "from datasets import load_dataset\n",
    "import copy\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Sequence, List, Literal\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE_INDEX = -100\n",
    "\n",
    "# PROMPT = (\n",
    "#         \"Below is an instruction that describes a task. \"\n",
    "#         \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "#         \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "#     )\n",
    "\n",
    "PROMPT = (\n",
    "        \"### Task:\\n{instruction}\\n\\n### Solution:\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1, target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'down_proj'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# name = \"meta-llama/Llama-2-7b-hf\"\n",
    "name = \"meta-llama/Llama-3.2-1B\"\n",
    "# name = \"distilgpt2\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(name, torch_dtype=torch.float16, device_map='auto')\n",
    "\n",
    "# model = get_peft_model(model, peft_config)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --data_path meta-math/MetaMathQA \\\n",
    "# --dataset_field query response \\\n",
    "    \n",
    "# python -u train_model.py \\\n",
    "#     --model_name_or_path $BASE_MODEL \\\n",
    "#     --output_dir $OUTPUT \\\n",
    "#     --corda_mode False \\\n",
    "#     --lora_r 128 \\\n",
    "#     --data_path meta-math/MetaMathQA \\\n",
    "#     --dataset_split \"train[:100000]\" \\\n",
    "#     --dataset_field query response \\\n",
    "#     --num_train_epochs 1 \\\n",
    "#     --per_device_train_batch_size 1 \\\n",
    "#     --gradient_accumulation_steps 128 \\\n",
    "#     --save_strategy \"steps\" \\\n",
    "#     --save_steps 100 \\\n",
    "#     --save_total_limit 1 \\\n",
    "#     --learning_rate 2e-5 \\\n",
    "#     --weight_decay 0. \\\n",
    "#     --warmup_ratio 0.03 \\\n",
    "#     --lr_scheduler_type \"cosine\" \\\n",
    "#     --logging_steps 1 \\\n",
    "#     --bf16 True \\\n",
    "#     --tf32 True \\\n",
    "#     --report_to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "    \"\"\"Tokenize a list of strings.\"\"\"\n",
    "    tokenized_list = [\n",
    "        tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            # padding='max_length',\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "        for text in strings\n",
    "    ]\n",
    "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "    input_ids_lens = labels_lens = [\n",
    "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "    ]\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=labels,\n",
    "        input_ids_lens=input_ids_lens,\n",
    "        labels_lens=labels_lens,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    sources: Sequence[str],\n",
    "    targets: Sequence[str],\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    ") -> Dict:\n",
    "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
    "    examples = [s + t for s, t in zip(sources, targets)]\n",
    "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "    input_ids = examples_tokenized[\"input_ids\"]\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "    \n",
    "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "        # print(len(label), source_len)\n",
    "        # label[:source_len] = IGNORE_INDEX\n",
    "        a = 5\n",
    "        \n",
    "    return dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "def train_tokenize_function(examples, tokenizer, query, response):\n",
    "    sources = [PROMPT.format_map(dict(instruction=instruction)) for instruction in examples[query]]\n",
    "    targets = [f\"{output}{tokenizer.eos_token}\" for output in examples[response]]\n",
    "    data_dict = preprocess(sources, targets, tokenizer)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        name,\n",
    "        # model_max_length=300,\n",
    "        model_max_length=1024,\n",
    "        padding_side=\"right\",\n",
    "        use_fast=True,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "raw_train_datasets = load_dataset(\"meta-math/MetaMathQA\", split='train[:10]')\n",
    "# raw_train_datasets = load_dataset(\"openai/openai_humaneval\", split='test[:100]')\n",
    "# raw_train_datasets = load_dataset(\"m-a-p/CodeFeedback-Filtered-Instruction\", split='train[:100]')\n",
    "# raw_train_datasets = load_dataset(\"fxmeng/WizardLM_evol_instruct_V2_143k\", split='train[:100]')\n",
    "\n",
    "query = 'query'\n",
    "response = 'response'\n",
    "\n",
    "# query = 'prompt'\n",
    "# response = 'canonical_solution'\n",
    "\n",
    "# query = 'query'\n",
    "# response = 'answer'\n",
    "\n",
    "# query = 'human'\n",
    "# response = 'assistant'\n",
    "\n",
    "\n",
    "train_dataset = raw_train_datasets.map(\n",
    "        train_tokenize_function,\n",
    "        batched=True,\n",
    "        batch_size=3000,\n",
    "        num_proc=10, # 32\n",
    "        remove_columns=raw_train_datasets.column_names,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on train dataset\",\n",
    "        fn_kwargs={\"tokenizer\": tokenizer, \"query\": query, \"response\": response}\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = [torch.tensor(x) for x in input_ids]\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = [torch.tensor(x) for x in labels]\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./logs/abrakkk',          \n",
    "    num_train_epochs=1,                   \n",
    "    per_device_train_batch_size=1,       \n",
    "    per_device_eval_batch_size=1,       \n",
    "    gradient_accumulation_steps=1,   \n",
    "    learning_rate=2e-5,               \n",
    "    weight_decay=0.0,                   \n",
    "    warmup_ratio=0.03,                   \n",
    "    lr_scheduler_type=\"cosine\",          \n",
    "    logging_steps=1,                       \n",
    "    fp16=True,\n",
    "    report_to=\"tensorboard\",              \n",
    "    logging_dir='./logs/abra',                 \n",
    "    # use_cpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "data_module = dict(train_dataset=train_dataset, data_collator=data_collator)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "metric = load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    predictions = np.argmax(predictions, axis=2).flatten()\n",
    "    \n",
    "    labels = labels.flatten()\n",
    "    \n",
    "    mask = labels != -100\n",
    "    \n",
    "    return metric.compute(predictions=predictions[mask], references=labels[mask])\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "\n",
    "#     predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "#     mask = labels != -100\n",
    "\n",
    "#     return metric.compute(predictions=predictions[mask], references=labels[mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parshina/.local/lib/python3.10/site-packages/accelerate/accelerator.py:450: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# trainer = Trainer(model=model, tokenizer=tokenizer, args=script_args, **data_module)\n",
    "\n",
    "# trainer = Trainer(model=model, args=training_args, **data_module)\n",
    "trainer = Trainer(model=model, args=training_args, compute_metrics=compute_metrics, **data_module)\n",
    "# trainer = Trainer(model=model, args=training_args, deepspeed='./ds_config_zero3.json', compute_metrics=compute_metrics, **data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_model_preparation_time': 0.0003, 'eval_accuracy': 0.0, 'eval_runtime': 35.6805, 'eval_samples_per_second': 0.28, 'eval_steps_per_second': 0.28}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "# model.eval()\n",
    "# model.config.use_cache = True\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate(eval_dataset=trainer.train_dataset)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128000, 14711, 5546, 512, 6600, 47383, 323, 13142, 527, 19301, 5219, 389, 279, 6485, 11277, 13, 13142, 41011, 279, 1486, 400, 16, 10, 17, 72, 13244, 2895, 47383, 41011, 400, 12, 16, 21905, 13244, 2650, 3117, 10980, 527, 2895, 47383, 323, 13142, 596, 3585, 1980, 14711, 12761, 75145, 6138, 1990, 1403, 3585, 5035, 87, 62, 16, 7509, 62, 16, 15437, 323, 5035, 87, 62, 17, 7509, 62, 17, 15437, 304, 279, 6485, 11277, 374, 2728, 555, 279, 15150, 59060, 27986, 97165, 87, 62, 17, 6695, 62, 16, 30876, 17, 13666, 88, 62, 17, 12303, 62, 16, 30876, 17, 32816, 627, 644, 420, 1162, 11, 13142, 596, 1486, 374, 5035, 16, 11, 17, 15437, 323, 2895, 47383, 596, 1486, 374, 400, 4172, 16, 11, 16, 15437, 627, 4516, 279, 6138, 1990, 872, 3585, 374, 59060, 27986, 90, 56034, 16, 52456, 16, 97959, 17, 10, 1209, 16, 52456, 17, 97959, 17, 92, 35533, 27986, 90, 4172, 17, 30876, 17, 10, 4172, 16, 30876, 17, 92, 35533, 27986, 90, 19, 10, 16, 92, 35533, 27986, 90, 20, 32816, 627, 55915, 11, 2895, 47383, 323, 13142, 596, 3585, 527, 59060, 80175, 36802, 27986, 90, 20, 3500, 3, 8316, 10980, 627, 791, 4320, 374, 25, 1144, 27986, 90, 20, 92, 128001], [128000, 14711, 5546, 512, 3923, 374, 279, 2860, 2853, 315, 23395, 7241, 369, 682, 59139, 4311, 389, 279, 9141, 2128, 11, 13126, 430, 1855, 2851, 7612, 264, 400, 914, 37212, 11, 264, 400, 868, 13, 508, 6857, 315, 36876, 11, 323, 264, 6857, 315, 40086, 33705, 520, 400, 21, 13, 1490, 1980, 14711, 12761, 25, 4959, 2851, 7612, 264, 400, 914, 37212, 11, 264, 400, 868, 13, 508, 6857, 315, 36876, 11, 323, 264, 6857, 315, 40086, 33705, 520, 400, 21, 13, 1490, 627, 4516, 279, 2860, 2853, 369, 1855, 2851, 374, 400, 914, 489, 400, 868, 13, 508, 489, 400, 21, 13, 1490, 284, 400, 2618, 627, 12834, 1070, 527, 59139, 4311, 389, 279, 9141, 2128, 11, 279, 2860, 2853, 369, 682, 315, 1124, 374, 220, 845, 353, 400, 2618, 284, 400, 23644, 627, 827, 220, 23644, 198, 791, 4320, 374, 25, 220, 23644, 128001], [128000, 14711, 5546, 512, 18674, 3427, 41778, 220, 717, 48669, 369, 813, 13219, 596, 15553, 13, 9641, 1101, 41778, 220, 19, 48669, 11, 719, 30912, 865, 1418, 8748, 369, 279, 4717, 311, 1212, 13, 2684, 527, 220, 868, 48669, 2163, 13, 3639, 374, 279, 907, 315, 9987, 3977, 865, 1980, 14711, 12761, 25, 1271, 11886, 420, 3575, 11, 584, 1205, 311, 8417, 279, 907, 315, 865, 11, 902, 11105, 279, 1396, 315, 48669, 9641, 30912, 1418, 8748, 369, 279, 4717, 311, 1212, 627, 10267, 596, 1464, 1523, 279, 2038, 2728, 512, 2903, 315, 48669, 41778, 555, 18842, 25, 220, 717, 198, 2903, 315, 48669, 41778, 555, 9641, 25, 220, 19, 198, 2903, 315, 48669, 2163, 25, 220, 868, 198, 1687, 649, 743, 709, 279, 24524, 439, 11263, 512, 2903, 315, 48669, 41778, 555, 18842, 489, 5742, 315, 48669, 41778, 555, 9641, 482, 5742, 315, 48669, 35661, 555, 9641, 284, 5742, 315, 48669, 2163, 198, 717, 489, 220, 19, 482, 865, 284, 220, 868, 198, 10267, 596, 40821, 323, 11886, 369, 865, 512, 845, 482, 865, 284, 220, 868, 198, 1271, 43223, 865, 11, 584, 33356, 220, 845, 505, 2225, 11314, 315, 279, 24524, 512, 845, 482, 865, 482, 220, 845, 284, 220, 868, 482, 220, 845, 198, 6695, 284, 482, 16, 198, 24901, 11, 584, 31370, 2225, 11314, 315, 279, 24524, 555, 482, 16, 311, 11886, 369, 865, 512, 87, 284, 220, 16, 198, 791, 907, 315, 865, 374, 220, 16, 627, 827, 220, 16, 198, 791, 4320, 374, 25, 220, 16, 128001], [128000, 14711, 5546, 512, 12281, 400, 4645, 1721, 62, 18, 3, 311, 264, 2385, 220, 605, 7698, 382, 14711, 12761, 22444, 4645, 1721, 62, 18, 284, 220, 16, 1144, 51953, 220, 18, 61, 19, 489, 220, 15, 1144, 51953, 220, 18, 61, 18, 489, 220, 16, 1144, 51953, 220, 18, 61, 17, 489, 220, 15, 1144, 51953, 220, 18, 61, 16, 489, 220, 16, 1144, 51953, 220, 18, 61, 15, 284, 220, 5932, 489, 220, 24, 489, 220, 16, 284, 1144, 80175, 90, 5925, 32816, 627, 791, 4320, 374, 25, 220, 5925, 128001], [128000, 14711, 5546, 512, 50, 361, 4375, 304, 264, 8803, 323, 1475, 220, 966, 4520, 11, 264, 5780, 1364, 71945, 19159, 220, 966, 43732, 315, 39962, 13, 2650, 1690, 43732, 315, 39962, 649, 865, 5780, 8356, 304, 220, 23, 4207, 5380, 2746, 584, 1440, 279, 4320, 311, 279, 3485, 3488, 374, 220, 11738, 11, 1148, 374, 279, 907, 315, 9987, 3977, 865, 1980, 14711, 12761, 25, 1687, 1440, 430, 1475, 220, 966, 4520, 11, 264, 5780, 19159, 220, 966, 43732, 315, 39962, 627, 12834, 1070, 527, 220, 1399, 4520, 304, 459, 6596, 11, 323, 220, 23, 4207, 304, 2860, 11, 279, 2860, 1396, 315, 4520, 374, 220, 1399, 353, 220, 23, 284, 220, 11738, 4520, 627, 2746, 264, 5780, 19159, 220, 966, 43732, 315, 39962, 1475, 220, 966, 4520, 11, 1243, 304, 220, 11738, 4520, 11, 433, 690, 8356, 320, 11738, 14, 966, 8, 353, 220, 966, 284, 220, 11738, 43732, 315, 39962, 627, 1687, 527, 2728, 430, 279, 2860, 1396, 315, 43732, 315, 39962, 9124, 374, 220, 11738, 11, 779, 584, 649, 3350, 25, 220, 11738, 284, 220, 11738, 353, 865, 627, 12792, 6714, 2225, 11314, 555, 220, 11738, 11, 584, 636, 25, 865, 284, 220, 16, 627, 791, 907, 315, 865, 374, 220, 16, 627, 827, 220, 16, 198, 791, 4320, 374, 25, 220, 16, 128001], [128000, 14711, 5546, 512, 9126, 374, 12096, 46362, 311, 94123, 264, 502, 3857, 315, 5754, 13, 578, 5754, 690, 387, 220, 1049, 15, 7693, 1317, 323, 220, 508, 7693, 7029, 13, 9062, 11092, 1096, 315, 46362, 690, 3504, 220, 4728, 9518, 7693, 315, 5754, 13, 1442, 1855, 11092, 1096, 7194, 865, 11, 323, 1070, 596, 264, 220, 508, 4, 6763, 3827, 11, 1268, 1790, 690, 4488, 1205, 311, 2343, 369, 46362, 5380, 2746, 584, 1440, 279, 4320, 311, 279, 3485, 3488, 374, 220, 10617, 15, 11, 1148, 374, 279, 907, 315, 9987, 3977, 865, 1980, 14711, 12761, 75145, 3158, 315, 279, 5754, 374, 279, 3160, 56016, 555, 279, 2430, 25, 220, 1049, 15, 353, 220, 508, 284, 220, 1272, 11, 931, 9518, 7693, 627, 4959, 11092, 1096, 315, 46362, 690, 3504, 220, 4728, 9518, 7693, 315, 5754, 11, 779, 4488, 690, 1205, 220, 1272, 11, 931, 611, 220, 4728, 284, 220, 1135, 11092, 33785, 315, 46362, 627, 791, 2853, 315, 1855, 11092, 1096, 374, 865, 11441, 627, 791, 2860, 2853, 315, 279, 46362, 2085, 6763, 3827, 374, 220, 1135, 353, 865, 11441, 627, 791, 6763, 3827, 374, 220, 508, 4, 315, 279, 2860, 2853, 11, 779, 279, 6763, 3827, 3392, 374, 220, 15, 13, 17, 353, 320, 1135, 353, 865, 8, 284, 220, 605, 353, 865, 11441, 627, 791, 2860, 2853, 2737, 6763, 3827, 374, 279, 2694, 315, 279, 2853, 2085, 6763, 3827, 323, 279, 6763, 3827, 3392, 25, 220, 1135, 353, 865, 489, 220, 605, 353, 865, 284, 220, 1399, 353, 865, 11441, 627, 1687, 527, 2728, 430, 279, 2860, 2853, 374, 400, 10617, 15, 11, 779, 584, 649, 3350, 25, 220, 1399, 353, 865, 284, 400, 10617, 15, 627, 12792, 6714, 2225, 11314, 555, 220, 1399, 11, 584, 636, 25, 865, 284, 400, 2075, 627, 791, 907, 315, 865, 374, 400, 2075, 627, 827, 220, 2075, 198, 791, 4320, 374, 25, 220, 2075, 128001], [128000, 14711, 5546, 512, 36, 16023, 753, 5679, 50542, 220, 5495, 16701, 26, 433, 50542, 865, 3115, 439, 1790, 439, 42521, 753, 5679, 13, 220, 32255, 11, 1148, 374, 279, 4785, 315, 279, 12875, 5380, 2746, 584, 1440, 279, 4320, 311, 279, 3485, 3488, 374, 220, 5332, 11, 1148, 374, 279, 907, 315, 9987, 3977, 865, 1980, 14711, 12761, 25, 1687, 1440, 430, 45043, 596, 5679, 50542, 220, 5495, 16701, 627, 1687, 1101, 1440, 430, 45043, 596, 5679, 50542, 865, 3115, 439, 1790, 439, 42521, 596, 5679, 11, 902, 3445, 42521, 596, 5679, 50542, 220, 5495, 11009, 16701, 627, 791, 2860, 4785, 315, 279, 12875, 374, 279, 2694, 315, 279, 4785, 315, 45043, 596, 5679, 323, 279, 4785, 315, 42521, 596, 5679, 25, 220, 5495, 489, 220, 5495, 11009, 627, 1687, 527, 2728, 430, 279, 2860, 4785, 315, 279, 12875, 374, 220, 5332, 16701, 11, 779, 584, 649, 3350, 25, 220, 5495, 489, 220, 5495, 11009, 284, 220, 5332, 627, 50, 20222, 369, 865, 11, 584, 636, 25, 865, 284, 220, 22, 627, 791, 907, 315, 865, 374, 220, 22, 627, 827, 220, 22, 198, 791, 4320, 374, 25, 220, 22, 128001], [128000, 14711, 5546, 512, 791, 6424, 315, 98104, 706, 220, 3443, 10632, 13, 3861, 11999, 315, 279, 6424, 596, 10632, 527, 4251, 13, 3861, 18172, 315, 279, 2536, 16237, 10632, 617, 264, 40511, 13, 2650, 1690, 315, 279, 2536, 16237, 10632, 656, 539, 617, 264, 40511, 1980, 14711, 12761, 25, 4054, 11999, 315, 279, 6424, 596, 10632, 527, 4251, 11, 779, 1070, 527, 220, 3443, 14, 19, 284, 220, 1041, 4251, 10632, 627, 791, 9861, 2536, 16237, 10632, 527, 220, 3443, 482, 220, 1041, 284, 220, 3101, 10632, 627, 4054, 18172, 315, 279, 2536, 16237, 10632, 617, 264, 40511, 11, 779, 1070, 527, 220, 3101, 14, 20, 284, 220, 1399, 2536, 16237, 10632, 449, 264, 40511, 627, 55915, 11, 279, 1396, 315, 2536, 16237, 10632, 2085, 264, 40511, 374, 220, 3101, 482, 220, 1399, 284, 220, 8273, 627, 827, 220, 8273, 198, 791, 4320, 374, 25, 220, 8273, 128001], [128000, 14711, 5546, 512, 45320, 1385, 400, 81, 3, 323, 400, 82, 3, 13592, 65683, 989, 13, 3277, 400, 81, 3, 374, 400, 4364, 15, 4884, 400, 82, 3, 374, 400, 15, 13, 1758, 2475, 3639, 374, 279, 907, 315, 400, 82, 3, 994, 400, 81, 3, 374, 400, 8273, 15, 3, 30, 17855, 701, 4320, 439, 264, 12395, 311, 279, 24379, 16579, 17323, 382, 14711, 12761, 25, 2746, 400, 81, 3, 323, 400, 82, 3, 13592, 65683, 989, 11, 1243, 584, 1440, 430, 400, 81, 1144, 51953, 274, 284, 597, 3, 369, 1063, 6926, 400, 74, 3, 627, 1687, 527, 2728, 430, 994, 400, 81, 3, 374, 400, 4364, 15, 55976, 400, 82, 3, 374, 400, 15, 13, 1758, 13244, 2100, 584, 649, 743, 709, 279, 24524, 512, 3, 4364, 15, 1144, 51953, 220, 15, 13, 1758, 284, 597, 26101, 50, 6517, 7922, 11, 584, 1505, 430, 400, 74, 284, 220, 12819, 3, 627, 7184, 584, 649, 1005, 420, 907, 315, 400, 74, 3, 311, 11886, 369, 400, 82, 3, 994, 400, 81, 3, 374, 400, 8273, 15, 3, 512, 3, 8273, 15, 1144, 51953, 274, 284, 220, 12819, 26101, 12792, 6714, 2225, 11314, 555, 400, 8273, 15, 55976, 584, 1505, 430, 400, 82, 284, 1144, 80175, 90, 15, 13, 10005, 32816, 311, 279, 24379, 16579, 17323, 627, 791, 4320, 374, 25, 220, 15, 13, 10005, 128001], [128000, 14711, 5546, 512, 56830, 11021, 220, 23, 6603, 922, 10099, 11, 220, 21, 6603, 922, 16335, 3634, 11, 323, 220, 18, 6603, 922, 28788, 311, 2567, 1461, 13326, 927, 279, 25425, 13, 9062, 2363, 2853, 400, 21, 13, 2650, 1790, 1550, 20851, 8493, 389, 279, 6603, 1980, 14711, 12761, 25, 56830, 11021, 264, 2860, 315, 220, 23, 489, 220, 21, 489, 220, 18, 284, 220, 1114, 6603, 627, 4959, 2363, 2853, 400, 21, 11, 779, 20851, 7543, 264, 2860, 315, 220, 1114, 865, 400, 21, 284, 400, 4278, 389, 279, 6603, 627, 827, 220, 4278, 198, 791, 4320, 374, 25, 220, 4278, 128001]]\n"
     ]
    }
   ],
   "source": [
    "print(data_module['train_dataset']['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "146\n",
      "253\n",
      "93\n",
      "218\n",
      "316\n",
      "192\n",
      "149\n",
      "228\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "for e in trainer.train_dataset:\n",
    "    print(len(e['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
